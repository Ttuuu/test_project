<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Below is a faster and more general algorithm than in posted alternatives:</p>

<pre class="lang-py prettyprint-override"><code>import numpy as np
from collections.abc import Mapping

def deeplen(item):
    if isinstance(item, np.ndarray):
        return item.size
    try:
        list(iter(item))
    except:
        return 1
    if isinstance(item, str):
        return 1
    if isinstance(item, Mapping):
        item = item.values()
    return sum(deeplen(subitem) for subitem in item)
</code></pre>

<p><strong>Advantages</strong>:</p>

<ol>
<li><p><em>Speed</em>: <code>.size</code> for Numpy arrays is much faster than recursive-iterative <code>len</code>. Also, there isn't much performance difference between the original <code>deeplen</code> and current <code>deeplen</code> (if excluding <code>.size</code> advantage), but <code>deeplen_lbyl</code> is slowest by 40% (tested w/ <code>iters=1000</code> on <code>bignest</code>).</p></li>
<li><p><em>Generality</em>: neither <code>isinstance(, Iterable)</code> nor <code>try-iter</code> are sufficient to determine whether <code>item</code> is 'truly' iterable; some objects (e.g. TensorFlow <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L266" rel="nofollow noreferrer"><code>Tensor</code></a>) support creating <em>generators</em> but not <em>consuming</em> them without <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/map_fn.py#L47" rel="nofollow noreferrer">dedicated methods</a> for iterating. It does become a question of whose <code>len</code> we're measuring, since an arbitrarily-sized <code>Tensor</code> will count as <code>1</code> per above algorithm - if this isn't desired, then object-specific treatment is required.</p></li>
</ol>

<p>Credit to @AlexPovel for originally suggesting <code>try-iter</code> and <code>isinstance(, Mapping)</code>.</p>
    </div>