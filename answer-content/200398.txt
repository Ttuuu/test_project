<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>There is a function in the standard library to create closure for you: <a href="https://docs.python.org/3/library/functools.html#functools.partial" rel="noreferrer"><code>functools.partial</code></a>. This mean you can focus on writting your function as naturally as possible and bother of binding parameters later on.</p>

<p>As for your function:</p>

<ol>
<li>Don't explicitly increment a running index, use <a href="https://docs.python.org/3/library/functions.html#enumerate" rel="noreferrer"><code>enumerate</code></a> instead;</li>
<li>You can use <a href="https://docs.python.org/3/library/functions.html#zip" rel="noreferrer"><code>zip</code></a> to iterate over two iterables at the same time;</li>
<li>Prefer using a list-comprehension to using <code>[]</code> + <code>for</code> + <code>append</code>;</li>
<li>You can use <a href="https://docs.python.org/3/library/functions.html#next" rel="noreferrer"><code>next</code></a> on an iterator to retrieve an element and advance it outside of a <code>for</code> loop;</li>
<li>Avoid wildcard imports, they clutter the namespace and may lead to name collisions.</li>
<li>Use an <a href="http://stackoverflow.com/questions/419163/what-does-if-name-main-do"><code>if __name__ == '__main__':</code></a> guard for your top-level code.</li>
</ol>

<p>Proposed improvements</p>

<pre><code>from functools import partial

from pyspark.sql import spark, Row


def flatten_table(column_names, column_values):
    row = zip(column_names, column_values)
    _, key = next(row)  # Special casing retrieving the first column
    return [
        Row(Key=key, ColumnName=column, ColumnValue=value)
        for column, value in row
    ]


if __name__ == '__main__':
    sample = spark.read.format("csv").options(header='true', delimiter = ',').load("/FileStore/tables/sample.csv")
    sample.rdd.flatMap(partial(flatten_table, sample.columns)).toDF().show()
</code></pre>
    </div>