<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I think there is quite a lot that could be improved on in your approach.
My main piece of advice is to try and process each line in the data only once, since each line is independent you should be able to do this.</p>
<p>I'm not too familiar with pandas but it seems like there are two main areas of concern.</p>
<ol>
<li>The section where you clean up the data and filter out all the bad emails, you create a mask by executing two regexs on each line and then read through and make copies of the data frame twice using the mask. At this point you have passed over every line in the data 3 times.</li>
</ol>
<pre><code>    df = df[0].str.strip(' \t"').str.split('[,|;: \t]+', 1, expand=True).rename(columns={0: 'email', 1: 'data'}) 
    mask = (df.email.str.contains(emailreg, regex=True, na=False)) &amp; (~df.data.str.contains(asciireg, regex=True, na=False))
    df2 = df[~mask].copy()
    df = df[mask].copy()
    df2[['email', 'data']].to_csv("errorfile", sep=':', index=False, header=False, mode='a', compression='gzip')
    del df2
    del mask
</code></pre>
<ol start="2">
<li>The second section where you breakdown each email into a different file if it is valid. you go through every line in the dataframe for every possible starting letter, and copy the result over to process again. At this point you have gone through each line in the data about 40 times.</li>
</ol>
<pre><code>for x in "abcdefghijklmnopqrstuvwxyz0123456789":
    df2 = df[df.email.str.startswith(x)]
    if (df.email.size &gt; 0):
        df2[['email', 'data']].to_csv(x, sep=':', index=False, header=False, mode='a')
</code></pre>
<p>Running cProfile on the code, when it just has to read one file with 6 lines in it produces this: <code>336691 function calls (328148 primitive calls) in 0.974 seconds</code>. Nearly a second to just read and process 6 lines into different files is not good.</p>
<p>Rather than taking a pandas approach I have just written a pure python script that sketches out an alternative strategy. Doing the same test with cProfile produces <code>11228 function calls (11045 primitive calls) in 0.038 seconds</code>. It might not fit your needs exactly but you could look at it for ideas about how to tweak your script.</p>
<pre><code>import re
import logging

EMAIL_REGEX = r"^\w+(?:[-+.']\w+)*@\w+(?:[-.]\w+)*\.\w+(?:[-.]\w+)*$"
OUTPUT_FILES = "abcdefghijklmnopqrstuvwxyz0123456789"


def configure_logging():
    """
    Configure a logger for each possible email start. 
    """

    # TODO - Tweak the handlers, output formats and locations 
    # to suit your needs

    error_handler = logging.FileHandler("error.log", mode="a")
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(logging.Formatter('%(message)s'))

    for entry in OUTPUT_FILES:
        logger = logging.getLogger(entry)
        handler = logging.FileHandler(f"{entry}.log", mode="a")
        handler.setFormatter(logging.Formatter('%(message)s'))
        handler.setLevel(logging.INFO)
        logger.addHandler(handler)
        logger.addHandler(error_handler)
        logger.setLevel(logging.INFO)
    
def gather_files():
    """
    Return all the log files that need to be processed.
    """
    # TODO - replace with your own logic to find files.
    return ["test_input.csv"]

def process_log_file(log_file_path):
    """
    For each line in the log file, process it once.
    """
    with open(log_file_path, "r") as log_file:
        for line in log_file:
            process_line(line)
                
def process_line(line):
    """
    Find the email and user from a line, test if the email is valid. Log the data
    to the appropriate place.
    """

    # TODO you may wish to change to logic 
    # to decide if the line is valid or not.

    line = line.strip(' \t"\n')
    data = re.split(r'[,|;: \t]+', line, maxsplit=1)
    logger = logging.getLogger(data[0][0])
    if len(data) == 2 and re.match(EMAIL_REGEX, data[0]):
        logger.info(":".join(data))
    else:
        logger.error(line)

def main():
    """
    Processes each log file in turn.
    """
    for log_file_path in gather_files():
        process_log_file(log_file_path)

if __name__ == "__main__":
    configure_logging()
    main()

<span class="math-container">```</span>
</code></pre>
    </div>