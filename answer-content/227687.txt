<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h3>Coding Style</h3>

<p>First, I'm not a code reviewer. Your code seems to be OK though. There are some basic coding conventions in writing Python scripts, such as variable naming, commenting, docstring, and such, which I don't go through it, since I'm learning myself, and you can find it <a href="https://docs.python.org/3/" rel="nofollow noreferrer">here</a>. </p>

<h3>Implementation</h3>

<p>There are a few things that hold a basic ANN not to properly converge such as: </p>

<ul>
<li><p>IRIS dataset is a pretty small dataset, to start with; which normally one uses some 70% of a dataset for training, if supervised (which is the case here), and the rest for validation.</p></li>
<li><p>It is difficult for me to go through your mathematical debugging, but it might be a reason that the math might have some problems and the network doesn't converge. To make sure, you can test it step by step (Neuron by Neuron maybe, if you will) with a very simple training and testing dataset, much simpler than IRIS, to see if there might be some bugs. </p></li>
<li><p>If there is no bug, the architecture of ANN is another thing that would impact the convergence. I guess you might not need three layers of hiddens, and one hidden layer with maybe 10 to 30 neurons might be just OK for IRIS. Sometimes, adding too many neurons would trap the network into mathematical local minima dilemma. You might want to make sure that the Input and Output layers have the exact correct number of neurons according to the dataset. </p></li>
<li><p>There might be some related tutorials to implement ANNs from scratch, wouldn't be such a bad idea to look them up. Maybe, something with a <code>Neuron</code> class.  </p></li>
</ul>

<h3>Integration</h3>

<p>You can also apply some already built-in modules to do that, such with KNN in this case, which I'm pretty sure you know:</p>

<pre><code>from sklearn import neighbors, datasets, preprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

iris = datasets.load_iris() 
X, y = iris.data[:, :], iris.target

Xtrain, Xtest, y_train, y_test = train_test_split(X, y)
scaler = preprocessing.StandardScaler().fit(Xtrain)
Xtrain = scaler.transform(Xtrain)
Xtest = scaler.transform(Xtest)

knn = neighbors.KNeighborsClassifier(n_neighbors=4)
knn.fit(Xtrain, y_train)
y_pred = knn.predict(Xtest)

print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
</code></pre>

<h3>Output</h3>

<pre><code>0.8947368421052632
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        13
           1       0.79      0.92      0.85        12
           2       0.91      0.77      0.83        13

    accuracy                           0.89        38
   macro avg       0.90      0.90      0.89        38
weighted avg       0.90      0.89      0.89        38

[[13  0  0]
 [ 0 11  1]
 [ 0  3 10]]
</code></pre>

<h3>Overall</h3>

<p>I think it is great that you are trying to implement a ANN from scratch. </p>
    </div>