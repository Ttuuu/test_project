<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>If your output is really what you desire, you are working way too hard for this.</p>
<p>In your original solution you work from the back, and sum all the needed elements in each step to generate the new sum. This is inefficient. Working from the back, you can reuse the sum from the previous step and just add the current element on top of it.</p>
<pre class="lang-py prettyprint-override"><code>def parts_sums_from_the_back(ls):
    nls = []
    sum_ = 0
    for element in reversed(ls):
        sum_ += element
        nls.insert(0, sum_)
    return nls
</code></pre>
<p>You can also work from the front. Then you start with the sum over all elements, and subtract the elements as you go along:</p>
<pre class="lang-py prettyprint-override"><code>def parts_sums_from_the_front(ls):
    nls = [sum(ls)]
    for i in range(len(ls)-1):
        nls.append(nls[i]-ls[i])
    return nls
</code></pre>
<p><strong>Sidenote:</strong> As you can see, <code>sum</code> is already taken in Python, so you should not use it to name your own variables.</p>
<p>Also, since what you are doing is not uncommon it even has a special name: <a href="http://mathworld.wolfram.com/CumulativeSum.html" rel="nofollow noreferrer">cumulative sum</a>. Just think about it for a second how your code can be expressed in terms of a cumulative sum. In the meantime, let me introduce you to <a href="https://www.numpy.org/" rel="nofollow noreferrer">NumPy</a>. NumPy is a specialized library for numeric computations, and as such also has a implementation of a cumulative sum.</p>
<pre class="lang-py prettyprint-override"><code>import numpy as np

def parts_sums_np(ls):
    return np.cumsum(ls[::-1]).tolist()[::-1]
</code></pre>
<p>Spoiler: As you can see, your result is cumsum of the reversed list, reversed again.</p>
<p><strong>Addendum:</strong> Since I'm usually working with Python in a scientific context I'm quick to use NumPy for quite a lof of tasks. Fortunately there are experienced people like <a href="https://codereview.stackexchange.com/users/123200/">Maarten Fabré</a> who know a thing or two about Python. He gave the following implementation in a comment below which only uses tools from Python's standard library:</p>
<pre class="lang-py prettyprint-override"><code>from itertools import accumulate

def parts_sums_itertools(ls):
    return list(accumulate(reversed(ls)))[::-1]
</code></pre>
<p><a href="https://docs.python.org/3/library/itertools.html#itertools.accumulate" rel="nofollow noreferrer"><code>itertools.accumulate</code></a> is a very handy function to express all kind of cumulative computations. If used on a sequence with no further arguments it computes the cumsum, but it can also be used to implement other algorithms like cumulative multiplication.</p>
<hr>
<p>I tested all of them with this little snippet:</p>
<pre class="lang-py prettyprint-override"><code>ls = [1, 4, 6, 4]
nsl = [15, 14, 10, 4]
print("parts_sums", parts_sums(ls) == nsl)
print("from_the_back", parts_sums_from_the_back(ls) == nsl)
print("from_the_front", parts_sums_from_the_front(ls) == nsl)
print("numpy", parts_sums_np(ls) == nsl)
print("itertools", parts_sums_itertools(ls) == nls)
</code></pre>
<p>which happily prints</p>
<pre class="lang-none prettyprint-override"><code>parts_sums True
from_the_back True
from_the_front True
numpy True
itertools True
</code></pre>
<p>Where <code>parts_sums</code> is your original implementation.</p>
<hr>
<h3>Timing</h3>
<p>I also performed some preliminary timing. With the input given in your question the results are as follows:</p>
<ul>
<li><code>parts_sums</code>: 5µs</li>
<li><code>from_the_back</code>: 1.6µs</li>
<li><code>from_the_front</code>: 2µs</li>
<li><code>numpy</code>: 13µs</li>
<li><code>itertools</code>: <strong>1.15µs</strong></li>
</ul>
<p>As you can see <code>itertools</code> takes the lead<strike>working from the back is the most efficient approach since it doesn't make it necessary to look at all elements of the list beforehand</strike>. NumPy performs actually quite poorly here. This is likely due to the overhead from going from Python to the C backend of NumPy and back again.</p>
<p>I repeated the timing for an input with 1000 elements. The results are as follows:</p>
<ul>
<li><code>parts_sums</code>: 185<strong>m</strong>s</li>
<li><code>from_the_back</code>: 690µs</li>
<li><code>from_the_front</code>: 285µs</li>
<li><code>numpy</code>: 170µs</li>
<li><code>itertools</code>: <strong>63.1µs</strong></li>
</ul>
<p>As you can see, all the repeated summing makes your original implementation scale really badly. Also, <code>from_the_front</code> and <code>from_the_back</code> have switched places. This is likely because <code>.insert(0, ...)</code> is more expensive than <code>.append(...)</code>. You can work against this dynamic array growing since you know exactly how large the array will be at the end. If you accomodate for this (see code below), the time goes down from over 600µs to around 270µs. At this point you also see that NumPy starts to play its strengths. NumPy might get stronger here, but <code>itertools</code> still dominates the comparison by a considerable margin.</p>
<pre><code>def parts_sums_from_the_back_pre(ls):
    nls = [None, ]*len(ls)
    sum_ = 0
    for i, element in enumerate(reversed(ls)):
        sum_ += element
        nls[-(i+1)] = sum_
    return nls
</code></pre>
<hr>
<h3>Appendix: Further timing</h3>
<p>I performed some extended timings to generate a visual presentation how the function runtimes scale with the list length.</p>
<p><a href="https://i.stack.imgur.com/C70xp.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/C70xpm.png" alt="timing comparison over growing list length in log-log scale"></a>
<a href="https://i.stack.imgur.com/aYZ1z.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/aYZ1zm.png" alt="timing comparison over growing list length in linear"></a></p>
<p>As expected, the original implementation scales very badly with the size of the input. This becomes even more obvious if you look at the plot with linear axis scale on the left (click for full resolution).</p>
<p>While creating the test routine I also came to the conclusion that NumPy loses against <code>itertools</code> because it has to convert the data from Python to NumPy's own format. If you repeat the test above using input already in NumPy's own format, NumPy steals the lead from the <code>itertools</code> implementation.</p>
<p><a href="https://i.stack.imgur.com/Sd7eg.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/Sd7egm.png" alt="enter image description here"></a>
<a href="https://i.stack.imgur.com/TDvXt.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/TDvXtm.png" alt="enter image description here"></a></p>
    </div>