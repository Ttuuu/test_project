<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Here are some things that may help you improve your program.</p>

<h2>Use all required <code>#include</code>s</h2>

<p>The <code>Lexer.h</code> file uses <code>std::string</code> and <code>std::vector</code> as part of its interface, but does not include <code>&lt;vector&gt;</code> at all, and only indirectly includes <code>&lt;string&gt;</code> because that's part of <code>Tokens.h</code>.  I'd recommend explicitly putting both <code>&lt;vector&gt;</code> <em>and</em> <code>&lt;string&gt;</code> in <code>Lexer.h</code> so that if, for example, one wanted to alter the interface for <code>Token</code> to not use <code>std::string</code>, this file would still remain the same.</p>

<h2>Eliminate unused variables</h2>

<p>In this program's <code>main()</code>, <code>argc</code>, <code>argv</code> are unused and should be eliminated from the program.  Or perhaps use the next suggestion instead.</p>

<h2>Allow the user to specify input file</h2>

<p>The file names are currently hardcoded which certainly greatly restricts the usefulness of the program.  Consider using <code>argc</code> and <code>argv</code> to allow the user to specify file names on the command line.  </p>

<h2>Consider allowing a <code>std::istream</code> parameter for input</h2>

<p>As it stands, the <code>Tokenize()</code> function is only capable of reading its input from a file with the passed name, but not, say, <code>std::cin</code> or any other stream.  Instead of handling file I/O there, change it to take a <code>std::istream &amp;</code>.  This makes the function much more flexible and also somewhat smaller and simpler.</p>

<h2>Keep associated things closer together</h2>

<p>Right now there is an <code>AVSL::TokenTyp::Keyword</code> and an <code>unordered_map</code> that contains the string "Keyword" and a list of <code>keywords</code> and then part of the parser also looks for those.  They are literally spread out over all files.  Keeping associated things together is exactly a job for an object.  First, I'd rename <code>TokenType</code> to <code>Type</code> and put it inside <code>struct Token</code> so now we have <code>Token::Type</code> everywhere that <code>TokenType</code> is currently used.  Next, we could create a more generic <code>Classifier</code> class:</p>

<pre><code>class Classifier {
public:
    Classifier(Token::Type ttype, std::string name, std::unordered_set&lt;std::string&gt; tokens) :
        my_type{ttype},
        my_name{name},
        my_tokens{tokens}
    {}
    bool among(const std::string&amp; word) const { return my_tokens.find(word) != my_tokens.end(); }
    Token::Type type() const { return my_type; }
private:
    Token::Type my_type;
    std::string my_name;
    std::unordered_set&lt;std::string&gt; my_tokens;
};

static const std::vector&lt;Classifier&gt; classifiers {
    { Token::Type::Keyword, "Keyword", { "var", "for", "while", "print", "constant"} },
    { Token::Type::Operator, "Operator", { "+", "-", "*", "/", "=", "==", "+=", "-=", "*=", "/=" } },
};
</code></pre>

<p>Now the first part of <code>getToken</code> could look like this:</p>

<pre><code>for (const auto &amp;thing : classifiers) {
    if (thing.among(buffer)) {
        return Token(buffer, thing.type());
    }
}
</code></pre>

<p>Alternatively, one could include a function in the <code>Token</code> class that would emit the type name for printing.  If you have C++17, I'd suggest returning a <code>std::string_view</code> for that purpose.</p>

<h2>Wrap the regex operations into classes</h2>

<p>It's not too difficult to imagine how, like the basic static <code>Classifier</code> object above, one could use a slightly more sophisticated version to employ a <code>std::regex</code>.  If you have both kinds of classifiers derive from the same base object, then even more goodness can happen because now your code is <em>data-driven</em> which makes things easier to maintain and to understand.</p>

<h2>Use a standard tool instead</h2>

<p>There are a lot of inefficiencies with the current code.  For one thing, the same buffer is scanned many times in trying to find a match.  This is very inefficient and will make a big difference with larger files or more complex lexers.  I'd recommend instead using <a href="https://en.wikipedia.org/wiki/Flex_(lexical_analyser_generator)" rel="nofollow noreferrer"><code>flex++</code></a> instead to create a lexer which is both very easy to maintain and read and also very efficient and fast.</p>
    </div>