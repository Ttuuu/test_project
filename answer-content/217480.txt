<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<ul>
<li><p>Python has an official style-guide, <a href="https://www.python.org/dev/peps/pep-0008/#id51" rel="nofollow noreferrer">PEP8</a>. It recommends using <code>lower_case</code> for variables, functions and methods.</p></li>
<li><p>I would encourage you to use <a href="http://docs.python-requests.org/en/master/" rel="nofollow noreferrer"><code>requests.get</code></a> instead of <code>urllib.request</code>. It can take care of urlencoding the parameters for you.</p></li>
<li><p>You can make <code>pull_from_arxiv</code> a generator to save a few lines.</p></li>
<li><p><code>BeautifulSoup</code> can be <a href="https://lxml.de/elementsoup.html" rel="nofollow noreferrer">sped up using the lxml parser</a>.</p></li>
<li><p><code>on_get</code> can be simplified a bit using a list comprehension.</p></li>
<li><p>Not sure if your <code>cleanText</code> is really needed. Anyways, I would use <code>str.replace</code> instead of <code>str.split</code> and <code>str.join</code>.</p></li>
</ul>



<pre><code>import requests
from bs4 import BeautifulSoup

class ArXivPully:
    def pull_from_arxiv(self, search_query, num_results=10):
        url = "https://export.arxiv.org/api/query"
        params = {"search_query": f"all:{search_query}",
                  "start": 0,
                  "max_results": num_results}
        data = requests.get(url, params=params).text
        soup = BeautifulSoup(data, 'lxml')
        # ArXiv populates the first title value as the search query
        titles = soup.find_all('title')[1:] 
        bodies = soup.find_all('summary')
        links = soup.find_all('link', title='pdf')

        for title, body, link in zip(titles, bodies, links):
            yield (link['href'],
                   title.text.strip().replace("\n", " "),
                   body.text.strip().replace("\n", " "))

    def on_get(self, req, resp):
        """Handles GET requests"""
        resp.media = [list(self.pull_from_arxiv(*item))
                      for item in req.params.items()]
</code></pre>

<p>Side note: Using this returns completely different results compared to entering the search string on the arxiv website search field. Not sure why. Same is true for your queries, though (the only difference is that <code></code> gets encoded as <code>+</code> and <code>:</code> as <code>%3a</code> by <code>requests.get</code>).</p>
    </div>