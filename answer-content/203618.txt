<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>In the post you write:</p>

<blockquote>
  <p>I also believe the <code>in</code> operator is inefficient because it is using the naïve method of searching the string.</p>
</blockquote>

<p>But if you look at the <a href="https://github.com/python/cpython/blob/master/Objects/unicodeobject.c#L11135" rel="noreferrer">implementation of Python's <code>in</code> operator for strings</a>, you find that it calls the <a href="https://github.com/python/cpython/blob/master/Objects/stringlib/fastsearch.h" rel="noreferrer"><code>FASTSEARCH</code></a> function, which is "based on a mix between <a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm" rel="noreferrer">Boyer–Moore</a> and <a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm" rel="noreferrer">Horspool</a>".</p>

<p>The problem of searching many times for strings in a collection of documents is known as <a href="https://en.wikipedia.org/wiki/Full-text_search" rel="noreferrer">full-text search</a>. The approach in the post is to search for the string in each document in turn: this scales linearly with the number and length of the documents. To improve on this scaling behaviour, you need to preprocess the collection of documents into an <em>index</em>. (Note that this only helps if you are searching many times—if you are searching only once, then you can't do better than searching each document.)</p>

<p>Here's a simple demonstration of the full-text search approach:</p>

<pre><code>from collections import defaultdict

class SearchIndex:
    "A full-text search index."

    def __init__(self):
        # Mapping from word to set of documents containing that word.
        self._index = defaultdict(set) 

    def add(self, document):
        "Add document to the search index."
        for word in document.split():
            self._index[word].add(document)

    def search(self, query):
        "Generate the documents containing the query string."
        candidates = min((self._index[word] for word in query.split()), key=len)
        for document in candidates:
            if query in document:
                yield document
</code></pre>

<p>This works by building a mapping from words to the sets of documents containing each word (an "<a href="https://en.wikipedia.org/wiki/Inverted_index" rel="noreferrer">inverted index</a>"). When a document is added to the index, it is split into words by calling <a href="https://docs.python.org/3/library/stdtypes.html#str.split" rel="noreferrer"><code>str.split</code></a>, and the document is added to the mapping for each word. This is conveniently implemented using <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" rel="noreferrer"><code>collections.defaultdict</code></a>. </p>

<p>To search for a string, the string is also split into words, and the index consulted for each word. The rarest word (the one mapping to the fewest number of documents) is used to get a set of candidates, and then each candidate is searched for the entire string.</p>

<p>This is a very simple approach and there are <a href="https://en.wikipedia.org/wiki/Search_engine_indexing" rel="noreferrer">many refinements</a> you can make. In particular, if you are going to be making queries of the same set of documents over a long period of time then you will want to make your inverted index persistent, and for that you will want a full-text search engine or database.</p>
    </div>