<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>A few observations:</p>

<hr>

<p><code>s_t = np.zeros(n)</code> and <code>r_t = np.zeros(n)</code> are more than you need. Since you don't actually use the array values but solely overwrite them, you can use <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.empty.html" rel="nofollow noreferrer"><code>np.empty</code></a> here.</p>

<hr>

<p>You're doing quite a bit of redundant work in the <code>for</code> loop.</p>

<p>When calculating <code>s_t[i]</code>, numpy basically has to repeat all the computations it has already done for <code>s_t[i-1]</code>. If you have a look at the definition of <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html" rel="nofollow noreferrer"><code>np.std</code></a>, you can see that the mean plays a role here. Since you have already come up with a nice solution for the mean value, you could reuse it here:</p>

<pre class="lang-py prettyprint-override"><code>s_t = np.empty(n)

for i in range(n):
    s_t[i] = np.mean((sig[:i+1] - mean_t[i])**2)
    ...
s_t = np.sqrt(s_t)
</code></pre>

<p>I validated this against the original code with <code>np.allclose</code>.</p>

<p><code>r_t</code> also has some extra work that you can get rid of. At the moment your code does the following:</p>

<pre class="lang-py prettyprint-override"><code>x_t = y - t * mean_t[i]
r_t[i] = np.ptp(x_t[:i + 1])
</code></pre>

<p>All the values of <code>x_t</code> at <code>[i+1:n]</code> are computed, but never used, so you can do</p>

<pre class="lang-py prettyprint-override"><code>r_t[i] = np.ptp(y[:i+1] - t[:i+1] * mean_t[i])
</code></pre>

<p>instead, without changing the outcome. You could also write this as two list comprehensions:</p>

<pre class="lang-py prettyprint-override"><code>s_t = np.sqrt(
    np.array([np.mean((sig[:i+1] - mean_t[i])**2) for i in range(n)])
)
r_t = np.array([np.ptp(y[:i+1] - t[:i+1] * mean_t[i]) for i in range(n)])
</code></pre>

<p>Or even a single one if you'd like to get a little bit creative:</p>

<pre><code>rs_t = np.array([
    [
        np.mean((sig[:i + 1] - mean_t[i])**2),
        np.ptp(y[:i + 1] - t[:i + 1] * mean_t[i])
    ] for i in range(n)
])
rs_t[:, 0] = np.sqrt(rs_t[:, 0])
</code></pre>

<p>A fully vectorized computation of <code>x_t</code> I have come up with, starting from</p>

<pre><code>x_t = y.reshape(1, -1) - mean_t.reshape(-1, 1) @ t.reshape(1, -1)
</code></pre>

<p>is considerably slower than the looped version.</p>

<hr>

<p>I'm actually not quite sure about the rest of the code from this point on at the moment. I will have to take a closer look to give a meaningful review performancewise. As a first non-functional feedback I would like to invite you to think about more meaningful variable names in the future. Especially there at the end of the code around the least-squares optimization, they are quite hard to understand.</p>

<hr>

<p>I did some timing of different versions of this algorithm. The full benchmark code can be found in <a href="https://gist.github.com/alexvorndran/aad69fa741e579aad093608ccaab4fe1" rel="nofollow noreferrer">this gist</a>. This is what I got so far (for <code>n=15360</code>):</p>

<pre class="lang-none prettyprint-override"><code>base:              3.748915s
better_loop:       2.605374s
double_lc:         2.430255s
single_lc:         2.445943s
-----------------------
base_numba:        0.866583s
better_loop_numba: 0.813630s
double_lc_numba:   0.776361s
single_lc_numba*:  N/A
</code></pre>

<p>The lower group of results uses <a href="https://numba.pydata.org/" rel="nofollow noreferrer">numba</a>, a just-in-time compiler for Python code, that can sometimes help to speed up loops. Unfortunately, numba does not support all types of array operations in its fast <code>nonpython</code> mode, e.g. I could not get the single list comprehension version to properly work with numba.</p>

<p>The results are actually a little bit worse than I had originally expected, especially without numba, but there is still a good amount profiling work to be done here.</p>
    </div>