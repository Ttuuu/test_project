<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>First of all, yes, CortexM0 lacks any way to do 32x32=64 multiplication in hardware. CortexM3 and CortexM4 have <a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0553a/CIHJFABI.html" rel="nofollow noreferrer">the <code>umull</code> instruction</a>, which lets you do 32x32=64 really easily.</p>

<p>And yes, since you're writing in C, one <em>possible</em> implementation would be</p>

<pre><code>uint64_t mul32x32(uint32_t r0, uint32_t r1) { return r0*(uint64_t)r1; }
</code></pre>

<p>but I assume you've already tried that (with <code>-O3</code> and whatever other optimization and inlining options you can turn up) and discovered that your compiler doesn't inline the multiplication, but leaves it as a call to some internal libc function.</p>

<p>A quick Google search turned up <a href="https://stackoverflow.com/questions/23286239/fastest-cortex-m0-thumb-32x32-64-multiplication-function">this previous StackOverflow question on exactly the same topic</a>, where someone in the comments linked to GCC's implementation of 64x64=64 multiplication for CortexM0 <a href="https://gcc.gnu.org/ml/gcc-patches/2010-10/txt00435.txt" rel="nofollow noreferrer">(here)</a>, with the suggestion that you could constant-propagate "upper bits are known to be zero" through the whole thing by hand and that would give you something decent. I don't know if that's true.</p>

<p>Have you also benchmarked the "naive" approach of</p>

<pre><code>uint64_t mul32x32(uint32_t r0, uint32_t r1)
{ 
    uint16_t r0h = r0 &gt;&gt; 16, r0l = r0 &amp; 0xFFFF;
    uint16_t r1h = r1 &gt;&gt; 16, r1l = r1 &amp; 0xFFFF;
    uint64_t result = (r0h * r1h);
    result &lt;&lt;= 16;
    result += r0h*r1l;
    result += r0l*r1h;
    result &lt;&lt;= 16;
    result += r0l*r1l;
    return result;
}
</code></pre>

<p>or equivalently</p>

<pre><code>uint64_t mul32x32(uint32_t r0, uint32_t r1)
{ 
    uint16_t r0h = r0 &gt;&gt; 16, r0l = r0 &amp; 0xFFFF;
    uint16_t r1h = r1 &gt;&gt; 16, r1l = r1 &amp; 0xFFFF;
    return ((uint64_t)(r0h * r1h) &lt;&lt; 32)
         + ((uint64_t)(r0h * r1l) &lt;&lt; 16)
         + ((uint64_t)(r0l * r1h) &lt;&lt; 16)
         + ((uint64_t)(r0l * r1l) &lt;&lt; 0);
}
</code></pre>

<p>? As long as none of the arithmetic operations get turned into library function calls, this has the benefit of being portable ANSI C <em>and</em> being susceptible to inlining by the compiler. If you care about speed, susceptibility-to-inlining should be your #1 concern.</p>

<p>Since you have access to your compiler and we don't (I'm guessing Green Hills, from the <code>__asm{ }</code> syntax for inline assembly blocks?), you might get better answers if you posted the assembly that results from the above three C implementations.</p>

<p>Finally, note that CortexM0's <code>MULS</code> instruction <a href="https://electronics.stackexchange.com/questions/115342/how-many-cycles-does-an-arm-cortex-m0-use-to-multiply-floats#comment258660_115346">takes either 1 cycle or 32 cycles, depending on the processor</a>. If you're on one of those 32-cycle processors, doing four <code>MULS</code> instructions in a row is probably one of the worst things you can do. If <code>MULS</code> only takes 1 cycle, then you're probably okay; I don't <em>think</em> there's any need to space out those <code>MULS</code> instructions the way one might on a machine where they took multiple cycles (<a href="https://en.wikipedia.org/wiki/Software_pipelining" rel="nofollow noreferrer">software pipelining</a>).</p>
    </div>