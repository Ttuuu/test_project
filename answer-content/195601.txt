<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>It seems wasteful to re-crawl the specified websites every time your web page gets hit, particularly if the web pages you're crawling have nothing to do with the request sent to your webpage. This seems like a job that should be run as a cron job (say, every 5 or 30 minutes), stored in the database, then simply <em>fetched</em> from the database when your webpage gets hit.</p>

<p>A great framework for more advanced crawling is <a href="https://scrapy.org/" rel="nofollow noreferrer"><code>scrapy</code></a>. It very likely might be overkill for this application, but if you're pondering more advanced scraping, it's a good utility for that purpose.</p>

<hr>

<p>Now to actually review your code.</p>

<p>Your <code>shorten</code> function could be radically simplified using <a href="https://www.digitalocean.com/community/tutorials/how-to-index-and-slice-strings-in-python-3" rel="nofollow noreferrer">slices</a>:</p>

<pre><code>def shorten(cleaned_html, limit=50):
    """
    If the description of an article is too long, let's cut it
    to only 50 characters.
    """
    return cleaned_html[:limit] + ('...' if len(cleaned_html) &gt; limit else '')
</code></pre>

<p>Also, in <code>strip_html</code>, you compile your regex every time, but only use it once. In Python's <code>re</code> module, there are shortcut functions when you're only using a regex once. You could simply do <code>return re.sub(r"&lt;.*?&gt;", "", raw_html)</code></p>

<p>When doing your crawling, you create several temporary lists, each of which is a simple function that transforms the elements of the previous list, which you do using a list. In Python, there's a very efficient way (both in memory and compute time) to represent this using generator comprehensions. You also have a robust constructor for <code>Brick</code>; instead of creating a generic <code>Brick</code> and then modifying it, just make the exact <code>Brick</code> you want in the first place:</p>

<pre><code>def extract_brick(item):
    return Brick(
        title=item.find("title").get_text(),
        link=item.find("link").get_text(),
        description=shorten(strip_html(item.find("description").get_text())) if item.find("description") is not None else "No description.",
        img_url=item.find("media:content").get("url") if item.find("media:content") is not None else "No media.",
        creator=item.find("dc:creator").get_text() if item.find("dc:creator") is not None else "No creator.",
        date=item.find("dc:date").get_text() if item.find("dc:date") is not None else "No date."
    )

def news_list(request):
    unformatted_xmls = (urllib.request.urlopen(URL) for URL in URLS)
    formatted_xmls = (BeautifulSoup(unf_xml, "xml") for unf_xml in unformatted_xmls)
    group_of_items = (form_xml.find_all("item") for form_xml in formatted_xmls)
    bricks = [extract_brick for item_group in group_of_items for item in item_group]

    return render(request, "new/list.html", {"bricks": bricks})
</code></pre>

<p>And lastly, you don't need semi-colons at the end of every line. It's a hard habit to break when transitioning from languages where whitespace doesn't really matter, such as C++, C, or Java, but in Python they're mostly just clutter.</p>
    </div>