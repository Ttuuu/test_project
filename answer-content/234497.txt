<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I'm going to put this code into an editor, "proofread" it from top to bottom, give notes as I go, and then paste the final result to show the effect of the edits.</p>

<ol>
<li><p>Code editors don't usually wrap lines since linebreaks mean things in code.  Consequently, most coding style guidelines suggest limiting your column width so the reader doesn't need to scroll horizontally; I'm going to break up those lines as I encounter them.</p></li>
<li><p><code>if A == ('Slow').lower():</code> is either a bug or needless.  I think you want <code>if A.lower() == 'slow'</code> to do a case-insensitive comparison -- but given that this is the only thing you use this value for, I'm going to remove <code>A</code> completely.</p></li>
<li><p>Overcome indentation!  An easy way of doing this in this script is to invert your <code>if</code> checks and break early so you can get the main flow of control back to the left side of the page.  After I applied this to all those input statements, almost the entire script ends up unindented, which makes it a lot easier to read the loops that are left.</p></li>
<li><p>I'm going to say this as diplomatically as possible: these unindented comments in the middle of deeply indented code are literally a war crime against my eyeballs.  Making the reader jump from right to left and back as they're reading the code is very unkind.</p></li>
<li><p>I'm gonna use <code>NotImplementedError</code> as a way to break the control flow when we hit something that's not implemented.  It's basically the error that's built into Python as a way to say "I didn't write this part yet" so using it is a very clear way to communicate that situation even if the reader can't understand your error message, and raising an exception will make Python just stop what it's doing (which is what we want here).</p></li>
<li><p>Unless you have a really good reason otherwise, put your imports at the top of the script.  It makes it easy to see in one place what the script's dependencies are, which might be important to someone else trying to use it, or to you as you do more development on it.</p></li>
<li><p>I'm not going to try to fix this, but I think you probably have a bug in your <code>next_path</code> code -- you specify a fixed Windows path as the root (this of course isn't going to work the instant you try to run this somewhere else -- contrary to your stated intent of making things easy for the user, this is bound to be extremely frustrating once someone's in that situation), and then you prompt the user for a path with forward slashes.  Everything is being set up for failure.  I think it'd be better to just prompt the user for an absolute path, or to use the current directory as the root path.</p></li>
<li><p>Using capitalization for variable names is kinda weird; the standard convention is for individual variables (instances) to be lowercase, and to use capitalization for class names (types).  That way your eyeball can quickly pick out which is which, just like how in written English we capitalize proper nouns but not common nouns to be able to easily distinguish them.</p></li>
<li><p><code>titration_file_input.lower() not in ['done']</code> is needless syntactic sugar for <code>titation_file_input.lower() != 'done'</code>.</p></li>
<li><p>I'm gonna restructure this file reading loop a bit so that the code is simpler and the user gets faster feedback if they typo a filename.</p></li>
<li><p><code>'File' + ' '</code> should be written as <code>'File '</code>.</p></li>
<li><p>Adding linebreaks to these comment-offset blocks so that the comments are grouped with the code they describe, like paragraphs.  Again, this is all about making it easy for human eyeballs to parse the script.</p></li>
<li><p>Use spaces consistently!  The first part of the script uses normal spacing but it's like by the end you were getting stressed out about running out of room so everything is scrunched together.  :)  I'm going to add spacing and also linebreaks where it seems helpful to figure out how all the args to a complicated line are organized.</p></li>
<li><p>Giving these magic data processing formulas names would be good.  Giving the numeric variables names would also be good.  The short variable names like <code>J</code>, <code>M</code> etc are fine if they're local to the context of a standard formula that has a descriptive name, but just having magic variables in a magic formula makes it impossible for anyone else to know what this part of the script is doing.</p></li>
<li><p>Why do you take your two descriptive variables, put them into a list called <code>input_data</code>, and then only ever address them as the individual values via that list?  It's extra code that only makes the logic harder to understand.  I'm just swapping that back out.</p></li>
<li><p>A standard convention for a "placeholder" variable that is needed for the signature of a passed function but that you're not going to actually use is <code>_</code> (or you can prefix each variable with <code>_</code> if you have more than one).</p></li>
<li><p>Moving the definitions of your A, B, C variables into the one function where they're used.  That way the reader can see that they're only intermediate values for that one function and have no lasting meaning (which would be frustrating to try to determine given how short the names are).  In general, you want to keep the scope of values as short as possible so that the reader (and the compiler/interpreter for that matter) can see when it's safe to forget about them.</p></li>
</ol>

<p>Done!  Here's what I've got in my editor after making all those changes (hopefully I didn't add any fat-fingered typos in there):</p>

<pre><code>import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

# I plan on adding other scripts later to analyze different data sets. 
# Currently I have written the script for one. But this is designed to 
# be a general use program, so I want to get it out there now, but add 
# features to it later. Hence all the initial inputs.
if input(
    'Slow or Fast Exchange? (Type in "Slow" or "Fast")\n'
).lower() != 'slow':
    raise NotImplementedError('Fast Exchange is not implemented yet.')
if input(
    'Will you be using both the free and bound state peaks? (Type in "Yes" or "No")\n'
).lower() == "yes":
    raise NotImplementedError('Slow Exchange analysis using both states is not developed yet')
if input(
    'Will you be using the free or bound state peaks? (Type in "Free" or "Bound")\n'
).lower() != 'free':
    raise NotImplementedError('Slow exchange analysis for the bound peak is not developed yet')

print ('Loading up Slow Exchange Script')
# This is where the user inputs where the files they will be calling are stored. 
# To make this more general user friendly, I automatically fill the drive and user portion.
# TODO: fix this
main_path=(r'C:\Users\Sams PC')
next_path=input('Please indicate the folder the files are. E.g. /Desktop/Peaklists \n')
full_path=main_path+next_path
os.chdir(full_path)

#The data that will be analyzed is split into 3 sections. One is the experimental data itself 
# (titration_files), the settings they used to obtain the experimental data (concentrations), 
# and a normalization factor (Dilution)
data_table = []
peak_height = []
peak_names=[]
dilutions=input('Enter name of Dilution file.\n')
concentrations=input('Enter name of Concentration file.\n')
# The user can input as many peaklist files as they desire. 
print('Enter name of peaklist files. When finished, type done and enter to stop.')
while True:
    data = input()
    if data.lower() == 'done':
        break
    try:
        titration_datatable = pd.read_csv(data, sep='\s+', header=None)
        titration_datatable.columns=['Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5']
        data_table.append(titration_datatable)
    except:
        print('File ' + data + ' not found')

# The input of titration_data comes from a specific program that has the required data stored in Column 4. 
# I am creating a second table from Column 1 to use when saving the plots and savefiles.
for titration_datatable in data_table:
    peak_height.append(
        titration_datatable.loc[:, 'Column_4']
    )
    peak_names.append(
        titration_datatable.loc[:,'Column_1']
            .drop([0], axis=0)
            .drop([1], axis=0)
    )

# The first row in the datatable automatically is labeled data, so that is removed. 
# The 2nd row also has miscellanious info. The .astype is because I had to define them as integers, 
# otherwise I would get errors at the division step below. 
concatenated_titration_datatable = (pd.concat(peak_height, axis=1)
    .drop([0],axis=0)
    .drop([1],axis=0)
    .astype(int)
)
dilutions = pd.read_csv('Dilution.txt', sep='\s+', header=None)

# The data may sometimes have negative values, which can be considered the same as zero in this case.
combined = concatenated_titration_datatable.clip(lower=0)

# The data now needs to be normalized to account for dilution 
# (this is introduced in the experimental setup);
# the values are defined by a txt file the user uploads.
normalized = (combined / dilutions.values)

# It appears easier to do data modifications with a numpy matrix rather than with pandas, 
# so I converted this to numpy. I also had to do it for the function below as well.
M = pd.dataFrame.to_numpy(normalized)

# The below function is part of data processing. It's an equation for analyzing the data.
titration_data = (M[:, :1] - M) / ((M[:, :1] - M) + M)

concentrations = np.loadtxt('concentrations.txt')
protein = concentrations[:,0]
ligand = concentrations[:,1]
input_data = [protein, ligand]

# To be able to save the peak_names list above as a png for the graphs below, 
# I had to convert to a nupy array first. But this would cause errors since its a matrix, 
# thus I removed all the repeats, giving me a 1D array.
peak_names_ar=np.array(peak_names)
peak_names_array=np.unique(peak_names_ar)

# For each iteration of the function, I want to save the output of the fit (kD), 
# the standard deviation of that fit, and R2 (goodness of fit). 
# I'm also saving each plot, and using the above peak_names file to do so.
def fun(_, kd):
    a = protein
    b = protein + ligand
    c = ligand
    return np.array((b + kd - np.sqrt(((b + kd)**2) - 4*a*c))/(2*a))
kD=[]
r2=[]
standard_deviation=[]
output_for_graphing=[]
for values, i in zip(titration_data, peak_names_array):
    intensity=[values]
    intensity_array=np.array(intensity)
    x = ligand
    y = intensity_array.flatten()
    popt, pcov = curve_fit(fun, x, y)
    kD.append(popt)
    fun_data = fun(x, *popt)
    output_for_graphing.append(fun_data)
    residuals = y - fun(x, popt)
    ss_res=np.sum(residuals**2)
    ss_tot=np.sum((y - np.mean(y))**2)
    r_squared = 1 - (ss_res / ss_tot)
    r2.append(r_squared)
    std = np.sqrt(np.diag(pcov))
    standard_deviation.append(std)
    plt.plot(x, y, label='data')
    plt.plot(x, fun(x, *popt), label='fitted')
    plt.xlabel('ligand Concentration')
    plt.ylabel('intensity')
    plt.title([i])
    plt.grid()
    plt.legend()
    files_to_save = str([i])+'.png'
    plt.savefig(files_to_save)
    plt.show()

# I'm saving the output of the function as well, in case someone wants to graph it for 
# themselves and doesn't like matplotlibs display.
np.savetxt('Output for graphing.txt',output_for_graphing)

# I need to flatten the arrays to be able to stack them (I get an error otherwise)
kD_array=np.array(kD).flatten()
r2_array=np.array(r2).flatten()
standard_deviation_array=np.array(standard_deviation).flatten()
dissociation_constant=np.stack((kD_array, standard_deviation_array, r2_array), axis=-1)

# I realized after the fact that I wanted to add an extra column to the above matrix. 
# But since numpy doesn't seem to have an insert command, and I didn't want to break 
# the matrix I already had, I thought it might be easier to just change it to a pandas datatable.
dissociation_constant_table = pd.dataFrame(dissociation_constant)
dissociation_constant_table.columns = ['kD', 'Standard Deviation', 'R2']
dissociation_constant_table.insert(0, 'Files', peak_names_array)
dissociation_constant_table.to_csv('dissociation_constant.txt', sep='\t', index=False)

</code></pre>
    </div>