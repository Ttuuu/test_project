<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<ol>
<li><p>The description of the problem in the post says that the case to be detected is redeeming "over 3 time" but what the code actually detects is <em>3 times or more</em>. Which is right?</p></li>
<li><p>The description of the problem in the post says that the case to be detected is redeeming:</p>

<blockquote>
  <p>on same stamp card within 10 mins</p>
</blockquote>

<p>But what the code actually detects is redeeming:</p>

<blockquote>
  <p>on same stamp card <em>by the same user</em> within 10 mins</p>
</blockquote>

<p>Which of these is right? It seems to me that the description in the post would be better, because otherwise someone could avoid detection by switching to a new user account after redeeming twice. (Maybe the software ensures that each stamp card is redeemable only by one user, but in that case why check the user at all?)</p></li>
<li><p>The code assumes that the database will return records for each same stamp card id in increasing stamp time order, otherwise this won't work:</p>

<pre><code>g.tail(1).stamp_time.values - g.head(1).stamp_time.values
</code></pre>

<p>But the SQL query only orders them by stamp card id, not by stamp time. Perhaps it happens to be the case at the moment that records are added to the table in stamp time order. But it is a bad idea to depend on this, because a change to the way the database is updated could break this assumption. It would be more robust to be explicit and write:</p>

<pre><code>ORDER BY stamp_card_id, stamp_time
</code></pre></li>
<li><p>Here's what I suspect is the main performance problem:</p>

<pre><code>for i in range(0, len(unique_users)):
    user = unique_users[i]
    new_df = df[df.user_id == user]
</code></pre>

<p>The expression <code>df[df.user_id == user]</code> looks innocent, but actually it has to loop over all the records in the dataframe twice: once to test <code>user_id == user</code>, and a second time to select the matching records. And this has to be done for every user. So if there are 36,000 records and (say) 10,000 unique users, then the <code>user_id == user</code> test gets run 360,000,000 times!</p>

<p>Instead of iterating over the unique users and then finding the records for each user, use Panda's <a href="http://pandas.pydata.org/pandas-docs/stable/groupby.html#splitting-an-object-into-groups" rel="nofollow noreferrer"><code>groupby</code></a> method to efficiently group the records by user.</p>

<p>But looking at my point §2 above, is this step really necessary? Perhaps what we really need to do is to ignore the users altogether and go straight to the stamp card ids.</p></li>
<li><p>The same anti-pattern occurs in the stamp card processing code:</p>

<pre><code>sid = new_df.stamp_card_id.unique()
for i in sid:
    fdf = new_df[new_df.stamp_card_id == i]
</code></pre>

<p>This needs to become:</p>

<pre><code>for fdf in df.groupby(['stamp_card_id']):
</code></pre>

<p>If you really do care about the users as well as the stamp cards, then you should order the query results by both:</p>

<pre><code>ORDER BY user_id, stamp_card_id, stamp_time
</code></pre>

<p>and group by both:</p>

<pre><code>for fdf in df.groupby(['user_id', 'stamp_card_id']):
</code></pre></li>
<li><p>The code creates a multiprocessing pool, but does not use it! You have to call the pool's methods, for example <a href="https://docs.python.org/3.7/library/multiprocessing.html#multiprocessing.pool.Pool.apply" rel="nofollow noreferrer"><code>multiprocessing.Pool.apply</code></a>, to take advantage of the pool—it doesn't work by magic.</p>

<p>But actually I suspect that there's no need to use multiprocessing here. Once you have eliminated the quadratic runtime behaviour as discussed above, then it should run in an acceptable amount of time in a single process.</p></li>
</ol>
    </div>