<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>(I'm tempted to comment on, I guess, program development in general or getting more out of CodeReview@SE as opposed to reviewing the code.)</p>

<ul>
<li>Document your code. In the code. Use what tool support you can get, for "the C-family", I use&amp;recommend <a href="http://www.doxygen.nl/manual/docblocks.html" rel="nofollow noreferrer">doxygen</a>.<br>
• Document the external/public interface:<br>
What is the purpose is <code>PerformFuzzyMatch()</code>? All I can see is the locally declared <code>currentBatchMatchedWords</code> growing.<br>
What are <code>FuzzyMatchRepo</code> and <code>FuzzyMatchRepository</code>?<br>
• Comment <em>why</em> everything non-trivial is there.</li>
<li>going parallel seems the way to go - depending on approach, it may prove advantageous to estimate whether exchanging the roles of list A and B promises an improvement.<br>
The fixed group/batch size looks debatable.</li>
<li>the fixed <em>similarity limit</em> looks inflexible -<br>
use a function as a parameter?</li>
<li>computing the exact distance when interested in <em>similar enough</em> is wasteful as <a href="https://codereview.stackexchange.com/questions/212823/levenshtein-distance-between-each-pair-of-elements-from-two-large-data-sets/237420#comment411891_212823">commented by Pieter Witvoet</a></li>
</ul>

<p>To find solutions to evaluate, I find it useful to collect what seems helpful, with an eye on <em>what in the problem at hand differs from well known problems</em>:</p>

<ul>
<li>sorting the lists by length&amp;contents allows<br>
• weeding out words occurring than once<br>
• establishing bounds on similarity<br>
• reusing partial results in "dynamic computation"</li>
<li>character histograms help establish bounds on distance:<br>
sum of absolute differences is a lower bound</li>
<li>the most simple part carrying information about relative position is <em>digram</em>/(ordered)<em>pair of characters</em>  </li>
<li>the <a href="https://en.m.wikipedia.org/wiki/Triangle_inequality" rel="nofollow noreferrer">triangle inequality</a> holds for the edit distances counting replacements (Hamming), insertions&amp;deletions (Levenshtein) and <em>unrestricted</em> neighbour transpositions (unrestricted Damerau-Levenshtein - still not sure whether there is a generally accepted nomenclature)<br>
This is related to what <a href="https://stackoverflow.com/questions/54511595/optimize-matching-elements-from-two-large-data-sets-using-levenshtein-distance#comment96935784_54516063">"the Wei/Chuan/Xuemin/Chengqi paper"</a> seems to exploit (from glossing that over)</li>
<li>"all about a string" is in its <em>suffix array</em><br>
Then, there is <em>FM-index</em> (<em>Fulltext-Minute-</em>)</li>
</ul>

<hr>

<ul>
<li><code>LevenshteinDistance()</code> seems to compute the <em>restricted</em> Damerau-Levenshtein distance<br>
using offsets into the strings of -1 and, for transpositions, -2, which looks unusual<br>
ignoring last characters, which looks erroneous(, if consequential)</li>
<li>it allocates an array with size the product of the lengths involved.<br>
Wagner-Fischer reduces this to two rows for Levenshtein; it should be easy to extend this to one more row for Damerau-Levenshtein<br>
reducing this by one row has been done for Levenshtein</li>
<li>given an upper bound on distance (like <em>length of longer string</em>), don't compute entries that exceed that bound (<em>Ukkonen's optimisation</em> - en.wikipedia mentions single-row implementation but not this one?!).</li>
<li>your code follows the mathematical presentation of the measure closely, missing to bail out early:<br>
if the characters match or the current character is the 2nd of a transposition, the distance does not increase, <em>and <strong>no other edit costs less</strong></em></li>
</ul>
    </div>