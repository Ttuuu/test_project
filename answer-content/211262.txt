<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I would separate the two concerns of getting the table data and processing it a bit more. For this it might make sense to have one generator that just yields rows from the table and gets the next page if needed:</p>

<pre><code>import requests
from bs4 import BeautifulSoup, SoupStrainer

SESSION = requests.Session()

def get_table_rows(base_url, posts_per_page=30):
    """Continously yield rows from the posts table.

    Requests a new page only when needed.
    """
    start_at = 0
    while True:
        print(f'current page index is: {start_at // posts_per_page + 1}')
        response = SESSION.get(base_url + f"/+{start_at}")
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml',
                             parse_only=SoupStrainer("table", {"cellspacing": "1"}))
        yield from soup.find_all("tr")
        start_at += posts_per_page
</code></pre>

<p>This already chooses only the correct table, but still contains the header row. It also reuses the connection to the server by using a <a href="http://docs.python-requests.org/en/master/user/advanced/#session-objects" rel="nofollow noreferrer"><code>requests.Session</code></a>. This is an infinite generator. Choosing to only get the first n entries is done later using <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="nofollow noreferrer"><code>itertools.islice</code></a>.</p>

<p>Now we just need to parse a single table row, which can go to another function:</p>

<pre><code>def parse_row(row):
    """Get info from a row"""
    columns = row.select("td")
    try:
        if not columns or columns[0]["class"] in (["darkrow1"], ["nopad"]):
            return
    except KeyError:  # first column has no class
        # print(row)
        return
    try:
        title = row.select_one("td.row1 a[href^=/topic/]").text.strip() or "No Data"
        description = row.select_one("td.row1 div.desc").text.strip() or "No Data"
        replies = row.select_one("td:nth-of-type(4)").text.strip() or "No Data"
        topic_starter = row.select_one('td:nth-of-type(5)').text.strip() or "No Data"
        total_views = row.select_one('td:nth-of-type(6)').text.strip() or "No Data"
    except AttributeError:  # something is None
        # print(row)
        return
    return {"Title": title,
            "Description": description,
            "Replies": replies,
            "Topic Starter": topic_starter,
            "Total Views": total_views}

def parse_rows(url):
    """Filter out rows that could not be parsed"""
    yield from filter(None, (parse_row(row) for row in get_table_rows(url)))
</code></pre>

<p>Then your main loop just becomes this:</p>

<pre><code>from itertools import islice
import pandas as pd

if __name__ == "__main__":
    url = 'https://forum.lowyat.net/ReviewsandGuides'
    max_posts = 1740
    df = pd.DataFrame.from_records(islice(parse_rows(url), max_posts))
    print(df)
</code></pre>

<p>Note that I (mostly) followed Python's official style-guide, <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a>, especially when naming variables (<code>lower_case</code>). This code also has a <a href="http://stackoverflow.com/questions/419163/what-does-if-name-main-do"><code>if __name__ == "__main__":</code> guard</a> to allow importing from this script from another script and the functions have (probably too short) <a href="https://www.python.org/dev/peps/pep-0257/" rel="nofollow noreferrer">docstrings</a> describing what each function does.</p>
    </div>