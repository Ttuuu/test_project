<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>The main performance bottleneck is probably the fact that you keep your already seen IPs in a <code>list</code>. Doing <code>x in list</code> is <span class="math-container">\$\mathcal{O}(n)\$</span>, so the more IPs there are, the slower this will get. Another factor is that you check <code>if new_client_IP not in client_IPs</code> but then add <code>IP(new_client_IP).strNormal()</code> to the list. So even if you come across the same IP again, it will still not be in the list, since that class probably produces something different than the line (which will have a trailing newline, for example) (and if it does not produce anything different, why have this step at all?) and so you do this possibly expensive step again.</p>

<p>Instead just save them in a <code>set</code>, for which <code>in</code> is <span class="math-container">\$\mathcal{O}(n)\$</span>. And even better, if you add an already existing element to a <code>set</code> it does not care.</p>

<pre><code>client_IPs = set()
client_IPs_size = 0

def read_clients(path_unique_ips):
    """Check if the file has changed size.
    If it has, extract all IPs from it and update the global variables.
    """
    global client_IPs_size
    current size = os.stat(path_unique_ips).st_size
    if current_size != client_IPs_size:
        client_IPs_size = os.stat(path_unique_ips).st_size
        global client_IPs
        with open(path_unique_ips, "r") as client_IPs_file:
            client_IPs = {IP(line).strNormal() for line in client_IPs_file}
</code></pre>

<p>Note that I used <code>with</code> to ensure the file is properly closed, even in an event of an exception. I also used a <code>set</code> as stated above.</p>

<p>I also iterate over the file directly instead of first reading all lines into memory. The whole thing fits nicely inside a set comprehension. I also added a <a href="https://www.python.org/dev/peps/pep-0257/" rel="nofollow noreferrer"><code>docstring</code></a> to document what this function does.</p>

<p>Modifying global objects can quickly lead to hard to read code and should be avoided if possible. Here this is a bit harder to avoid, because <code>process_and_filter</code> depends on the global state always being correct at that specific point in the loop. Another way around this would be to use class to keep this global state and make the other functions methods of that class. This might be a bit overkill, though, so I leave that implementation to you if you feel it is necessary.</p>

<hr>

<pre><code>def read_events(path_sophos_to_customer):
    """Every 0.1 seconds check if a new non-blank line has been added to the end of the file.
    If there has, yield it.

    Read the file containing the list of IPs again if it has changed.
    """
    with open(path_sophos_to_customer, 'r') as connection_event_to_customer:
        connection_event_to_customer.seek(0, 2)   # seek to the end
        while True:
            new_event = connection_event_to_customer.readline()
            if not new_event:
                time.sleep(0.1)
                continue
            yield new_event

            # file size of unique IP File changed, this will read the IPs again
            read_clients(PATH_UNIQUE_IPS)
</code></pre>

<p>Since the check for a changed <code>client_IPs</code> is now inside <code>read_clients</code> the <code>if</code> clause is not needed anymore.</p>

<p>I also removed the check if the file is readable. Usually you want your code to either fail loudly (with an exception) if something happens (like a file not being readable) or you catch that exception, do something about it and log that it happened. Having it just silently fail by bypassing it with that <code>if</code> clause does not help you at all.</p>

<hr>

<p>For the splitting of the events into two logs, I would open both files only once at the beginning. I would also extract the IP from the event (since you have not shown us an example of what an event looks like, I will have to guess and say you could use for example <a href="https://www.regular-expressions.info/ip.html" rel="nofollow noreferrer"><code>re.search(r'\b(?:\d{1,3}\.){3}\d{1,3}\b', new_event).group()</code></a>). This moves this from having to iterate over all IPs every time to iterating over the string of <code>new_event</code>, which is hopefully shorter.</p>

<pre><code>def process_and_filter(my_events, match_log, no_match_log):
    """Get events in generator-object from function read_events
    and write either to matched or no match log file.
    """
    with open(match_log, 'a+') as match, open(no_match_log, 'a+') as no_match:
        for new_event in my_events:
            print(new_event)
            ip = extract_ip(new_event)
            file = match if ip in client_IPs else no_match
            file.write(new_event)
</code></pre>

<hr>

<p>With this the calling code becomes:</p>

<pre><code>if __name__ == '__main__':
    new_events = read_events(PATH_SOPHOS_TO_CUSTOMER, MATCH_LOG, NO_MATCH_LOG)
    process_and_filter(new_events)
</code></pre>

<p>Note that Python's official style-guide, <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a>, recommends using <code>ALL_CAPS</code> for global constants.</p>
    </div>