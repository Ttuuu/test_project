<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>For each word in the lexicon you are searching through each email: (11,314 emails) * (60 words/email) * (211441 word lexicon) = lots of comparisons.</p>

<p>Flip it around.  Use <code>collections.Counter</code>.  Get the unique words in each email (use a set()) and then and update the counter.</p>

<pre><code>from collections import Counter

counts = Counter()

for email in x_train:
    words = set(email.split())   # &lt;= or whatever you use to parse the words
    counts.update(words)
</code></pre>

<p>This will give you a dict mapping words in the emails to the number of emails they are in.  (11,314 emails) * (60 words/email) = a lot fewer loops.
This probably also recreated the lexicon (e.g. 
<code>counter.keys()</code> should be the lexicon.</p>

<p>On my computer, it takes 7 seconds to generate 115000 random 60-word emails and collect the counts.</p>
    </div>