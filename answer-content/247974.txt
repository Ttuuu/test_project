<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I assume you are using .net core.  If so you should make the Main method to be async Task Main(string[] args) have been supported since .net core 2.0.  I would move the configuration builder into the main method as well.  Have everything you need to support running your app in the main method.</p>
<p>Right now you have a couple of big methods that do a lot of things and we want to have more methods but each method do one thing.  Some simple ones to break out</p>
<pre><code>/// &lt;summary&gt;
/// Creates Empresa (Company)
/// &lt;/summary&gt;
/// &lt;param name="data"&gt;Info to use to fill in model (fixed width)&lt;/param&gt;
/// &lt;returns&gt;&lt;/returns&gt;
private EmpresaModel CreateCompany(string data)
{
    return new EmpresaModel()
    {
        Cnpj = data.Substring(3, 14),
        IndicadorMatrizFilial = data.Substring(17, 1).Trim(),
        RazaoSocial = data.Substring(18, 150).Trim(),
        NomeFantasia = data.Substring(168, 55).Trim(),
        CodigoSituacaoCadastral = data.Substring(223, 2).Trim(),
        DataSituacaoCadastral = data.Substring(225, 8).Trim(),
        CodigoMotivoSituacaoCadastral = data.Substring(233, 2).Trim(),
        CidadeExterior = data.Substring(235, 55).Trim(),
        CodigoPais = data.Substring(290, 3).Trim(),
        Pais = data.Substring(293, 70).Trim(),
        CodigoNaturezaJuridica = data.Substring(363, 3).Trim() + "-" + data.Substring(366, 1).Trim(),
        DataInicioAtividade = data.Substring(367, 8).Trim(),
        IdCnae = data.Substring(375, 7).Trim(),
        TipoLogradouro = data.Substring(382, 20).Trim(),
        Logradouro = data.Substring(402, 60).Trim(),
        Numero = data.Substring(462, 6).Trim(),
        Complemento = data.Substring(468, 156).Trim(),
        Bairro = data.Substring(624, 50).Trim(),
        Cep = data.Substring(674, 8).Trim(),
        UF = data.Substring(682, 2).Trim(),
        CodigoMunicipio = data.Substring(684, 4).Trim(),
        Municipio = data.Substring(688, 50).Trim(),
        DDD1 = data.Substring(738, 4).Trim(),
        Telefone1 = data.Substring(742, 8).Trim(),
        DDD2 = data.Substring(750, 4).Trim(),
        Telefone2 = data.Substring(754, 8).Trim(),
        DDDFax = data.Substring(762, 4).Trim(),
        TelefoneFax = data.Substring(766, 8).Trim(),
        Email = data.Substring(774, 115).Trim(),
        CodigoQualificacaoResponsavel = data.Substring(889, 2).Trim(),
        CapitalSocial = data.Substring(891, 14).Trim(),
        CodigoPorteEmpresa = data.Substring(905, 2).Trim(),
        CodigoOpcaoSimplesNacional = data.Substring(907, 1).Trim(),
        DataOpcaoSimples = data.Substring(908, 8).Trim(),
        OptanteMei = data.Substring(924, 1).Trim(),
        SituacaoEspecial = data.Substring(925, 23).Trim(),
        DataSituacaoEspecial = data.Substring(948, 8).Trim(),
    };
}

/// &lt;summary&gt;
/// Creates QuadroSocietario (Partner)
/// &lt;/summary&gt;
/// &lt;param name="data"&gt;Info to use to fill in model (fixed width)&lt;/param&gt;
/// &lt;returns&gt;&lt;/returns&gt;
private QuadroSocietarioModel CreatePartner(string data)
{
    return new QuadroSocietarioModel()
    {
        Cnpj = data.Substring(3, 14).Trim(),
        IdentificadorSocio = data.Substring(17, 1).Trim(),
        NomeSocio = data.Substring(18, 150).Trim(),
        CnpjCpfSocio = data.Substring(168, 14).Trim(),
        CodigoQualificacaoSocio = data.Substring(182, 2).Trim(),
        PercentualCapitalSocial = data.Substring(184, 5).Trim(),
        DataEntradaSociedade = data.Substring(189, 8).Trim(),
        CodigoPais = data.Substring(197, 3).Trim(),
        Pais = data.Substring(200, 70).Trim(),
        CpfRepresentanteLegal = data.Substring(270, 11).Trim(),
        NomeRepresentante = data.Substring(281, 60).Trim(),
        CodigoQualificacaoRepresentanteLegal = data.Substring(341, 2).Trim(),
    };
}

/// &lt;summary&gt;
/// Creates CnaeSecundarioModel (Activities)
/// &lt;/summary&gt;
/// &lt;param name="data"&gt;Info to use to fill in model (fixed width)&lt;/param&gt;
/// &lt;returns&gt;&lt;/returns&gt;
private IEnumerable&lt;CnaeSecundarioModel&gt; CreateActivities(string data)
{
    var cnpj = data.Substring(3, 14);
    // why do we start at 17?
    return Split(data.Substring(17, 693).Trim(), 7)
         .Where(x =&gt; !string.IsNullOrEmpty(x) &amp;&amp; x != "0000000")
         .Select(cnae =&gt; new CnaeSecundarioModel()
         {
             Cnae = cnae,
             Cnpj = cnpj
         });
}
</code></pre>
<p>To help "hide" the magic values for Company/Partners/Activities we can create an enum for those values.  Also a value for unknown and end of file which we will use in a bit</p>
<pre><code>public enum LineType
{
    Skip = '0',
    Company = '1',
    Partners = '2',
    Activity = '6',
    EOF = 'E',
    Unknown = 'X'
}
</code></pre>
<p>Since we are using TPL DataFlow we can create a mesh that will help process.  So first thing we need is a method to convert the zip file into models and a method to read the entries in the zip file.  I'm using System.IO.Compression for reading the zip and Microsoft.Extensions.Logging to add some logging.</p>
<pre><code>/// &lt;summary&gt;
/// Converts Fixed Line files into Company models
/// &lt;/summary&gt;
/// &lt;param name="lines"&gt;Lines from file&lt;/param&gt;
/// &lt;param name="token"&gt;Cancellation Token&lt;/param&gt;
/// &lt;returns&gt;&lt;/returns&gt;
private async IAsyncEnumerable&lt;EmpresaModel&gt; Deserialize(string file, [EnumeratorCancellation] CancellationToken token = default)
{
    EmpresaModel empresa = null;
    await foreach (var line in GetData(file).WithCancellation(token).ConfigureAwait(false))
    {
        if (string.IsNullOrWhiteSpace(line))
        {
            continue;
        }
        var type = (LineType)line[0];
        switch (type)
        {
            case LineType.EOF:
                {
                    if (empresa != null)
                    {
                        yield return empresa;
                        empresa = null;
                    }
                    break;
                }
            case LineType.Skip:
                {
                    break;
                }
            case LineType.Company:
                {
                    if (empresa != null)
                    {
                        yield return empresa;
                    }

                    empresa = CreateCompany(line);
                    break;
                }
            case LineType.Partners:
                {
                    if (empresa == null)
                    {
                        this.logger.LogWarning(new EventId((int)LineType.Partners, LineType.Partners.ToString()), "Missing Company");
                        break;
                    }
                    empresa.QuadroSocietario.Add(CreatePartner(line));
                    break;
                }
            case LineType.Activity:
                {
                    if (empresa == null)
                    {
                        this.logger.LogWarning(new EventId((int)LineType.Activity, LineType.Activity.ToString()), "Missing Company");
                        break;
                    }
                    foreach (var activity in CreateActivities(line))
                    {
                        empresa.CnaesSecundarios.Add(activity);
                    }
                    break;
                }
            default:
                {
                    this.logger.LogError(new EventId((int)LineType.Unknown, LineType.Unknown.ToString()), new FileFormatException("Unkown line type"), "Unkown line type");
                    break;
                }
        }
    }

    if (empresa != null)
    {
        yield return empresa;
    }
}

/// &lt;summary&gt;
/// Open zip files reads all files and outputs their text
/// &lt;/summary&gt;
/// &lt;param name="zipFile"&gt;&lt;/param&gt;
/// &lt;param name="token"&gt;&lt;/param&gt;
/// &lt;returns&gt;Enumerable for each file in archive with asyncenum to read the lines in that file&lt;/returns&gt;
private async IAsyncEnumerable&lt;string&gt; GetData(string zipFile, [EnumeratorCancellation] CancellationToken token = default)
{
    using (var archive = ZipFile.OpenRead(zipFile))
    {
        foreach (var file in archive.Entries)
        {
            using (var fileStream = file.Open())
            {
                using (var reader = new StreamReader(fileStream))
                {
                    while (!reader.EndOfStream &amp;&amp; !token.IsCancellationRequested)
                    {
                        var line = await reader.ReadLineAsync().ConfigureAwait(false);
                        if (line != null)
                        {
                            yield return line;
                        }
                    }
                    // special case for end of file
                    yield return ((Char)LineType.EOF).ToString();
                }
            }
        }
    }
}
</code></pre>
<p>Now we need a custom Data flow block that will take in path to zipfile and output all the models in it.</p>
<pre><code>/// &lt;summary&gt;
/// Creates a Data Block that takes in the zip file path and out put models
/// &lt;/summary&gt;
/// &lt;param name="ExecutionDataflowBlockOptions"&gt;&lt;/param&gt;
/// &lt;returns&gt;Custom Data Flow Block&lt;/returns&gt;
private IPropagatorBlock&lt;string, EmpresaModel&gt; ExtractZip(ExecutionDataflowBlockOptions options = null)
{
    var token = options?.CancellationToken ?? CancellationToken.None;
    // this will Broadcase out the models once build
    var source = new TransformBlock&lt;EmpresaModel, EmpresaModel&gt;(t =&gt; t, options);
    // Will go threw the zip and create the models
    var target = new ActionBlock&lt;string&gt;(async file =&gt;
    {
        await foreach (var model in Deserialize(file).WithCancellation(token).ConfigureAwait(false))
        {
            await source.SendAsync(model, token).ConfigureAwait(false);
        }
    }, options);

    // When the target is set to the completed state set the source to the completed state.
    target.Completion.ContinueWith(_ =&gt; source.Complete());

    return DataflowBlock.Encapsulate(target, source);
}
</code></pre>
<p>For outputting progress I typically use the IProgress&lt;&gt; interface.  Because I want it to be threadsafe I'm going to implement the interface myself and not use the Progress class.</p>
<pre><code>public class Notifier : IProgress&lt;int&gt; 
{
    private int totalCount = 0;
    private DateTime startTime = DateTime.Now;
    private DateTime lastNotified = DateTime.Now.Subtract(TimeSpan.FromSeconds(5));
    public void Report(int numberToAdd)
    {
        var total = Interlocked.Add(ref totalCount, numberToAdd);
        if (DateTime.Now.Subtract(lastNotified) &gt;= TimeSpan.FromSeconds(5))
        {
            var totalSeconds = DateTime.Now.Subtract(startTime).TotalSeconds;
            Console.WriteLine($"[{DateTime.Now.ToString("dd/MM/yyyy HH:mm:ss")}]  P-{total:n0} ({total / totalSeconds:n0}/s | {total / (totalSeconds / 60):n0}/m | {total / (totalSeconds / 60 / 60):n0}/h)");
            lastNotified = DateTime.Now;
        }
    }
}
</code></pre>
<p>We will create a method to encode the models.  I'm using the System.Text.Json and pushing json stream into the gzip stream to not have to create a memory stream</p>
<pre><code>private async Task&lt;string&gt; SerializeAsync(EmpresaModel model, CancellationToken token)
{
    using (var memoryStream = new MemoryStream())
    {
        using (var gzipStream = new GZipStream(memoryStream, CompressionMode.Compress))
        {
            await JsonSerializer.SerializeAsync(gzipStream, model, null, token).ConfigureAwait(false);
        }
        return Convert.ToBase64String(memoryStream.ToArray());
    }
}
</code></pre>
<p>The last thing we need is a method to send to the Azure.  If wanting to go to SQL and not have issue where you lost records then should look into Poly to handle transient errors.  Plus wrap it all in a transaction so they either complete or rollback as one statement.  With this when Poly retries you will get atomic writes</p>
<pre><code>private async Task&lt;string&gt; SendToQueue(QueueClient client, string message, CancellationToken token)
{
    // if want to go directly to SQL then in this method can add Poly to handle transient errors
    var receipt = await client.SendMessageAsync(message, token).ConfigureAwait(false);
    return receipt.Value.MessageId;
}
</code></pre>
<p>Noe that we have all the methods we just need to create the mesh pipeline.</p>
<pre><code>public async Task Start(string directory, QueueClient client, IProgress&lt;int&gt; progress, CancellationToken token)
{
    var executionBlockOptions = new ExecutionDataflowBlockOptions()
    {
        CancellationToken = token,
        //   MaxDegreeOfParallelism = 2,
        BoundedCapacity = 500
    };

    var extractZip = ExtractZip(executionBlockOptions);
    var encode = new TransformBlock&lt;EmpresaModel, string&gt;(async x =&gt; await SerializeAsync(x, token).ConfigureAwait(false), executionBlockOptions);
    var sendToQueue = new TransformBlock&lt;string, string&gt;(async x =&gt; await SendToQueue(client, x, token).ConfigureAwait(false), executionBlockOptions);
    var report = new ActionBlock&lt;string&gt;(_ =&gt; progress.Report(1), executionBlockOptions);
    var linkOptions = new DataflowLinkOptions()
    {
        PropagateCompletion = true,
    };
    extractZip.LinkTo(encode, linkOptions);
    encode.LinkTo(sendToQueue, linkOptions);
    sendToQueue.LinkTo(report, linkOptions);

    foreach (var file in Directory.EnumerateFiles(directory, "*.zip"))
    {
        await extractZip.SendAsync(file).ConfigureAwait(false);
    }
    extractZip.Complete();
    await report.Completion.ConfigureAwait(false);
}
</code></pre>
<p>With all the async work we doing it actually slowed down how fast my machine could do if I set MaxDegreeOfParallelism.  You could also have each Data flow block have its own execution option and tinker to see what performs best on your machine/network.  Basically we setup the mesh to extract the data, then encode the data then sent to azure and finally report the progress.   Then once the mesh is setup we loop through all the zip files in the directory and push the value into the mesh then wait for the entire mesh to finish.</p>
<p>Every machine is different but I downloaded 6 of the zips and this used ~95% of my 8 core and processed around 7,500 companies a second.  You can always tweak the data flow options to see what works best as I just took some guess, to be honest this took a lot of time but I was intrigued about it.  Using the IAsyncEnumerable will help lower the memory as we don't need to load as much of the file into memory.</p>
    </div>