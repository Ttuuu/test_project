<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h3>1. Review</h3>

<ol>
<li><p>The docstring for <code>bfs_visited</code> should explain the <code>node</code> argument.</p></li>
<li><p>The docstring for <code>compute_resilience</code> should explain that the <code>ugraph</code> argument gets modified. Alternatively, the function could take a copy of the graph so that the original is not modified.</p></li>
<li><p>In <code>bfs_visited</code> the lines:</p>

<pre><code>queue = deque()
queue.append(node)
</code></pre>

<p>can be simplified to:</p>

<pre><code>queue = deque([node])        
</code></pre></li>
<li><p>The function <code>largest_cc_size</code> builds a list of pairs:</p>

<pre><code>res = [(len(ccc), ccc) for ccc in cc_visited(ugraph)]
res.sort()
return res[-1][0]
</code></pre>

<p>But you can see that it only ever uses the first element of each pair (the size of the component). So you could simplify it by not building the pairs:</p>

<pre><code>res = [len(ccc) for ccc in cc_visited(ugraph)]
res.sort()
return res[-1]
</code></pre></li>
<li><p>Since only the size of the largest component is needed, there is no need to build the whole list. Instead you could use <a href="https://docs.python.org/3/library/functions.html#max" rel="noreferrer"><code>max</code></a> to find the largest:</p>

<pre><code>if ugraph:
    return max(map(len, cc_visited(ugraph)))
else:
    return 0
</code></pre></li>
<li><p>If you are using Python 3.4 or later, this can be further simplified using the <code>default</code> argument to <code>max</code>:</p>

<pre><code>return max(map(len, cc_visited(ugraph)), default=0)
</code></pre>

<p>This is now so simple that it probably doesn't need its own function.</p></li>
<li><p>This line:</p>

<pre><code>remaining_nodes = set(graph.keys())
</code></pre>

<p>can be written more simply:</p>

<pre><code>remaining_nodes = set(graph)
</code></pre></li>
<li><p>There is a loop over the set <code>remaining_nodes</code> where on each loop iteration you update <code>remaining_nodes</code>:</p>

<pre><code>for node in remaining_nodes:
    visited = bfs_visited(graph, node)
    if visited not in connected_components:
        connected_components.append(visited)
    remaining_nodes = remaining_nodes - visited
</code></pre>

<p>It looks as if the intention of the code to avoid iterating over the nodes in <code>visited</code> by removing them from <code>remaining_nodes</code>, but this doesn't work! The problem is that the <code>for</code> statement:</p>

<pre><code>for node in remaining_nodes:
</code></pre>

<p>only evaluates the expression <code>remaining_nodes</code> once, at the start of the loop. So when the code creates a new set and assigns it to <code>remaining_nodes</code>:</p>

<pre><code>remaining_nodes = remaining_nodes - visited
</code></pre>

<p>this has no effect on the nodes being iterated over.</p></li>
<li><p>You might imagine trying to fix this by using the <a href="https://docs.python.org/3/library/stdtypes.html#frozenset.difference_update" rel="noreferrer"><code>difference_update</code></a> method to adjust the set being iterated over:</p>

<pre><code>remaining_nodes.difference_update(visited)
</code></pre>

<p>but this would be a bad idea because then you would be iterating over a set and modifying it within the loop, which is not safe. Instead, you need to write the loop as follows:</p>

<pre><code>while remaining_nodes:
    node = remaining_nodes.pop()
    visited = bfs_visited(graph, node)
    if visited not in connected_components:
        connected_components.append(visited)
    remaining_nodes.difference_update(visited)
</code></pre>

<p>Using <code>while</code> and <a href="https://docs.python.org/3/library/stdtypes.html#frozenset.pop" rel="noreferrer"><code>pop</code></a> is the standard idiom in Python for consuming a data structure while modifying it — you do something similar in <code>bfs_visited</code>.</p></li>
<li><p>There is now no need for the test:</p>

<pre><code>if visited not in connected_components:
</code></pre>

<p>since each component is produced exactly once.</p></li>
<li><p>In <code>compute_resilience</code> the first line is:</p>

<pre><code>res = [len(ugraph)]
</code></pre>

<p>but this only works if the graph is a single connected component to start with. To handle the general case, the first line should be:</p>

<pre><code>res = [largest_cc_size(ugraph)]
</code></pre></li>
<li><p>For each node in attack order, <code>compute_resilience</code> calls:</p>

<pre><code>res.append(largest_cc_size(ugraph))
</code></pre>

<p>But this doesn't take advantage of the work that was previously done. When we remove <code>node</code> from the graph, all connected components remain the same, except for the connected component containing <code>node</code>. So we can potentially save some work if we only do a breadth-first search over that component, and not over the whole graph. (Whether this actually saves any work depends on how resilient the graph is. For highly resilient graphs it won't make much difference.)</p>

<p>In order to do this we'll need to redesign the data structures so that we can efficiently find the component containing a node, and efficiently remove that component from the collection of components.</p>

<p>This answer is already quite long, so I won't explain in detail how to redesign the data structures, I'll just present the revised code and let you figure it out for yourself.</p>

<pre><code>def connected_components(graph, nodes):
    """Given an undirected graph represented as a mapping from nodes to
    the set of their neighbours, and a set of nodes, find the
    connected components in the graph containing those nodes.

    Returns:
    - mapping from nodes to the canonical node of the connected
      component they belong to
    - mapping from canonical nodes to connected components

    """
    canonical = {}
    components = {}
    while nodes:
        node = nodes.pop()
        component = bfs_visited(graph, node)
        components[node] = component
        nodes.difference_update(component)
        for n in component:
            canonical[n] = node
    return canonical, components

def resilience(graph, attack_order):
    """Given an undirected graph represented as a mapping from nodes to
    an iterable of their neighbours, and an iterable of nodes, generate
    integers such that the the k-th result is the size of the largest
    connected component after the removal of the first k-1 nodes.

    """
    # Take a copy of the graph so that we can destructively modify it.
    graph = {node: set(neighbours) for node, neighbours in graph.items()}

    canonical, components = connected_components(graph, set(graph))
    largest = lambda: max(map(len, components.values()), default=0)
    yield largest()
    for node in attack_order:
        # Find connected component containing node.
        component = components.pop(canonical.pop(node))

        # Remove node from graph.
        for neighbor in graph[node]:
            graph[neighbor].remove(node)
        graph.pop(node)
        component.remove(node)

        # Component may have been split by removal of node, so search
        # it for new connected components and update data structures
        # accordingly.
        canon, comp = connected_components(graph, component)
        canonical.update(canon)
        components.update(comp)
        yield largest()
</code></pre></li>
<li><p>In the revised code, the <code>max</code> operation has to iterate over all the remaining connected components in order to find the largest one. It would be possible to improve the efficiency of this step by storing the connected components in a <a href="https://en.wikipedia.org/wiki/Priority_queue" rel="noreferrer">priority queue</a> so that the largest one can be found in time that's logarithmic in the number of components.</p>

<p>I doubt that this part of the algorithm is a bottleneck in practice, so it's probably not worth the extra code, but if you need to do this, then there are some <a href="https://docs.python.org/3/library/heapq.html#priority-queue-implementation-notes" rel="noreferrer">Priority Queue Implementation Notes</a> in the Python documentation.</p></li>
</ol>

<h3>2. Performance comparison</h3>

<p>Here's a useful function for making test cases:</p>

<pre><code>from itertools import combinations
from random import random

def random_graph(n, p):
    """Return a random undirected graph with n nodes and each edge chosen
    independently with probability p.

    """
    assert 0 &lt;= p &lt;= 1
    graph = {i: set() for i in range(n)}
    for i, j in combinations(range(n), 2):
        if random() &lt;= p:
            graph[i].add(j)
            graph[j].add(i)
    return graph
</code></pre>

<p>Now, a quick performance comparison between the revised and original code. Note that we have to run the revised code first, because the original code destructively modifies the graph, as noted in §1.2 above.</p>

<pre><code>&gt;&gt;&gt; from timeit import timeit
&gt;&gt;&gt; G = random_graph(300, 0.2)
&gt;&gt;&gt; timeit(lambda:list(resilience(G, list(G))), number=1) # revised
0.28782312001567334
&gt;&gt;&gt; timeit(lambda:compute_resilience(G, list(G)), number=1) # original
59.46968446299434
</code></pre>

<p>So the revised code is about 200 times faster on this test case.</p>
    </div>