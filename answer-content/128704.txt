<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Actually web crawling is a quite large topic. First, about your existing code. </p>

<ol>
<li><p>Mostly cosmetic edits. I would recommend payload functionality (moving content to files) to separate function and pass it as parameter.</p></li>
<li><p><code>MailboxProcessor</code> is a good decision for a crawler, but it seems you did not implement it properly if I did not miss something - the main issue is that agent will be busy until it will have not completed current page processing.
To solve it I would execute the following piece of code in <code>Async.StartChild</code>.</p>

<pre><code>let! r = download (IO.Path.GetTempFileName()) url'
                    match r with 
                    | Error e -&gt; log "error %O" e.Message
                    | Content f -&gt;  // todo: async { } |&gt; Async.Start  + cs.Token  + visited - Concurrent.ConcurrentDictionary
                        let hc = fileHash f.Path
                        log "processing %O as %O" url hc
                        let path = IO.Path.Combine(trgFolder, hc)
                        IO.File.Move(f.Path, path)
                        entries.WriteLine(sprintf "%O \t %O" hc url)
                        for u in urls path |&gt; Seq.map trimQuery do
                            if visited.Add u then 
                                inbox.Post (depth+1, u)
</code></pre>

<p>Second is about improvements specific for crawling.</p></li>
<li><p>I do not see the delay between requests - many sites will ban you for that.</p></li>
<li><p>You did not post code for links extraction and handling. It may be tricky to implement it properly.</p></li>
<li><p>I would set user agent to prevent blocking by some servers (though, it is not such important as delay).</p></li>
</ol>

<p>Also, I recently wrote two blog posts about the topic (<a href="http://thoughtsanddrafts.blogspot.ru/2016/05/implementing-web-crawler.html" rel="nofollow">one</a> about theoretical aspects and <a href="http://thoughtsanddrafts.blogspot.ru/2016/05/implementing-web-crawler-part-2-using-f.html" rel="nofollow">second</a> about implementation in F#) - maybe you will find something useful, especially in parts of delays implementation, URL links extraction and proper asynchronous handling.</p>
    </div>