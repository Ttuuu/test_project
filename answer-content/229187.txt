<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Ignoring threading, it's usually best to benchmark your code on a single thread first, then move to multiple threads as necessary. Some glaring things that could yield slower performance:</p>

<ol>
<li>You are not using a <code>Session</code> for requests. There is not a guarantee that sessions are thread-safe, but you could allocate a session for each thread, giving each thread it's own connection pool. This prevents the allocation of a Session under the hood when calling a bare <code>requests.get</code> method. From the source:</li>
</ol>

<pre class="lang-py prettyprint-override"><code>def request(method, url, **kwargs):
    """
    Snipping out docstring for brevity
    """

    # By using the 'with' statement we are sure the session is closed, thus we
    # avoid leaving sockets open which can trigger a ResourceWarning in some
    # cases, and look like a memory leak in others.
    with sessions.Session() as session:
        return session.request(method=method, url=url, **kwargs)


def get(url, params=None, **kwargs):
    r"""Sends a GET requeste
    """

    kwargs.setdefault('allow_redirects', True)
    return request('get', url, params=params, **kwargs)
</code></pre>

<p>So refactor to use a single session:</p>

<pre class="lang-py prettyprint-override"><code>import requests

url = 'http://google.com'

s = requests.Session()
r = s.get(url)
</code></pre>

<ol start="2">
<li>You are using lots of <code>list.insert(0, item)</code>, which is an O(N) operation, where N is the length of the list. This will naturally incur overhead as your list grows. A refactor might be better here using a data structure meant for left-append, like a <code>deque</code>:</li>
</ol>

<pre class="lang-py prettyprint-override"><code>from collections import deque

li_ = deque(map(lambda x: x.contents[0], fetched_text))
li_.appendleft(w_list[0])
</code></pre>

<p>This is much faster than <code>list.insert(0, object)</code>:</p>

<pre class="lang-py prettyprint-override"><code>(base) ➜ ~ python -m timeit -s 'from collections import deque; x = deque(range(10000))' 'x.appendleft(1)'
10000000 loops, best of 3: 0.06 usec per loop

(base) ➜ ~ python -m timeit -s 'from collections import deque; x = list(range(10000))' 'x.insert(0, 1)'
100000 loops, best of 3: 26.2 usec per loop
</code></pre>

<p>These still retain order and can be iterated over just like <code>lists</code></p>

<ol start="3">
<li>Explicitly checking if the length of a <code>list</code> is 0 is not pythonic and slower:</li>
</ol>

<pre class="lang-py prettyprint-override"><code>(base) ➜ ~ python -m timeit -s 'x = []' 'len(x)==0'
10000000 loops, best of 3: 0.0552 usec per loop
(base) ➜ ~ python -m timeit -s 'x = []' 'not x'
100000000 loops, best of 3: 0.0186 usec per loop
</code></pre>

<p>Use <code>if not fetched_text</code> instead</p>

<ol start="4">
<li><p>Your <code>self.put_queue</code> method is unnecessary. It's more readable to just use <code>self.q.put(value)</code></p></li>
<li><p>While iterating files, you don't need to check that the line is empty, this is an extra <code>if</code> statement that's implicitly handled by iterating over the file directly:</p></li>
</ol>

<pre class="lang-py prettyprint-override"><code>with open(somefile) as fh:
    for line in fh:
        # do things
</code></pre>

<p>This <code>for</code> loop will terminate when the file handle is exhausted</p>
    </div>