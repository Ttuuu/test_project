<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>If you are doing only 100 iterations, there is probably very little you can do to optimize your code. Vectorization, preallocation, etc... are all no concern at such few iterations. Still, there are a few general things to consider: </p>

<h2>Profiling</h2>

<p>Before you optimize your code, the first step is always profiling your code for bottlenecks. Do this before you consider any of my (or other peoples) suggestions. just wrap all your code into <code>profvis::profvis({..})</code> or use RStudios "Profiling" Menu (which does the same). The output will show you where your code spends most its time/memory in a nice gui. </p>

<h2>Store your resample-indices in a matrix</h2>

<p>You could create all your resamples at once and store the indices in a <code>matrix</code>, instead of always copying the <code>data.frame</code> and modifying it. This way you can also conveniently save the matrix for later reuse/reproduction if you want.</p>

<pre><code>resamples &lt;- sample(
  seq_len(folds), nrow(phen) * folds, replace = TRUE)
)
resamples &lt;- matrix(resamples, ncol = folds)

#...

model &lt;- BGLR(y = phen3[resamples[, j], 2], ...) 
</code></pre>

<p>You should also set the seed for the RNG with <code>set.seed()</code> (this way you can reproduce the output of <code>sample</code> when you run your code again)</p>

<h2>Save intermediate steps</h2>

<p>If you have R processes like yours that slow down the computer, and might eventually crash its a good idea to regularly save the output. Rewrite your loop in a way so that you can continue from any <code>i</code> and <code>j</code> and save your result every few minutes with <code>saveRDS()</code>(no need to add a timing feature, just figure out a sensible number of iterations). This will barely impact performance and you don't always have to restart from the beginning if something goes amiss.</p>

<h2>(don't!) Parallelize the code</h2>

<p><strong>edit:</strong> This is a <strong>very bad idea</strong> if your code already slows the system down, but I'll leave that here for people that have similar issues with smaller models.</p>

<p>I would venture your profiling showed you the bottleneck of your code is the model. You can use the <strong>foreach</strong> package, or rewrite your loop as a <code>lapply()</code> call and use <code>mclapply()</code> from the <strong>parallel</strong> package, or look into the new and awesome <strong>future</strong> package. <code>mclapply()</code> and <code>foreach()</code> will also take care of the preallocating, so no need to worry about that sepparately.
All of this will require some reading on your part, but its pretty simple to parallelize code in R. The easiest in your case is probably foreach.</p>

<h2>You could not reinvent the wheel</h2>

<p>the package <strong>caret</strong> is designed to do just what you are trying in a streamlined manner. There are also other packages with similar functionality like <strong>MLR</strong> and <strong>modelr</strong>, though I have not used those. On the other hand learning those packages will take time, your task seems fairly simple, and your code already works.</p>
    </div>