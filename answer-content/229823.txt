<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>After reading through @Toby_Speight's Review, I adopted a number of changes to (I hope) improve the code. </p>

<p>First, I separated the <code>Tokenizer</code> class into its own .hpp file so that it can now be readily used by a number of different projects. </p>

<p>Second, I changed the constructor to now only allow for the delimiters and the escape characters. The <code>Tokenizer</code> class uses defaults for handling of weather or not to remove <strong>escape characters</strong> (and turn double escape characters into a single escape character), remove <strong>empty tokens</strong>, convert from <strong>strings</strong> to <strong>ints</strong> or <strong>doubles</strong>, and to <strong>trim white spaces</strong> from the beginning and end of tokens. I decided that needing a new tokenizer for each of these was "safe", but highly burdensome. To give the user control over these defaults, I included <code>removeQuotes</code>, <code>removeBlanks</code>, <code>typeConvertion</code>, and <code>trimWhiteSpace</code> "setter" functions. Since, the <code>Tokenizer</code> class does all of its tokenizing during the input phase (<code>operator&lt;&lt;()</code>) I decided to clear any existing tokens when these "setters" were used. I can think of no use case where you would want to use to different switches for different input data without using the tokens in between input strings.</p>

<p>Third, I decided that trimming white spaces should be a user option and not hard wired <code>trimWhiteSpace</code>.</p>

<p>Fourth, I made some private functions to clean up redundancy in the code and make the main code easier to read. These new functions include <code>empty_string</code>, <code>parse</code>, and <code>emplace_string</code>. The function <code>parse</code> also represents my attempt to make use of the new c++17 function <code>from_chars</code> and clean up some of its clunky interface.</p>

<p>The <code>tokenizer.hpp</code> code is shown below:</p>

<pre><code>// Tokenizer.hpp

#ifndef TOKENIZER_HPP
#define TOKENIZER_HPP

#include &lt;algorithm&gt;
#include &lt;charconv&gt;
#include &lt;deque&gt;
#include &lt;iterator&gt;
#include &lt;optional&gt;
#include &lt;string&gt;
#include &lt;string_view&gt;
#include &lt;variant&gt;
#include &lt;vector&gt;

using namespace std::string_literals;

using token = std::variant&lt;int, double, std::string&gt;;

enum class token_type : std::size_t {
    INT,
    DOUBLE,
    STRING
};

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const token&amp; tok)
{

    std::visit([&amp;out](auto&amp;&amp; content) {out &lt;&lt; content; }, tok);
    return out;
}

using svciter = std::string_view::const_iterator;

class tokenizer
{
public:
    explicit tokenizer(const char* delim = ",;:|\t ",
        const char* escape = "\"\'") :
        delim_{ std::string(escape).append(delim) }, escape_{ escape } {}
    tokenizer&amp; operator&lt;&lt;(std::string_view s);
    tokenizer&amp; operator&gt;&gt;(token&amp; tok);
    tokenizer&amp; operator&gt;&gt;(std::optional&lt;token&gt;&amp; otok);
    void operator&gt;&gt;(std::vector&lt;token&gt;&amp; toks);
    std::optional&lt;token&gt; getNext();
    std::vector&lt;token&gt; getVector();
    void removeQuotes(bool remove_quotes);
    void removeBlanks(bool remove_blanks);
    void typeConvertion(bool convert);
    void trimWhiteSpace(bool trim);
    void clear() { toks_.clear(); }

private:
    std::vector&lt;std::string_view&gt; splitString(std::string_view s);
    void convertString(std::string_view s);
    std::string empty_string();
    template &lt;class T&gt;
    std::optional&lt;T&gt; parse(std::string_view s);
    void emplace_string(std::string_view s);
    std::deque&lt;token&gt; toks_;
    const std::string delim_{ };
    const std::string_view escape_{ };
    bool remove_quotes_{ true };
    bool remove_blanks_{ false };
    bool type_convert_{ true };
    bool trim_{ true };
};

std::string tokenizer::empty_string()
{
    if (remove_quotes_ || escape_.length() == 0) return "";
    return ""s + *(escape_.cbegin()) + *(escape_.cbegin());
}

tokenizer&amp; tokenizer::operator&lt;&lt;(std::string_view s)
{
    if (s.empty()) {
        if (!remove_blanks_) toks_.emplace_back(empty_string());
        return *this;
    }
    std::vector&lt;std::string_view&gt; temp_vec = splitString(s);
    for (auto&amp; value : temp_vec) {
        auto count = value.length();
        if (remove_blanks_ &amp;&amp; (count == 0 || (count == 2 &amp;&amp; remove_quotes_ &amp;&amp;
            escape_.find(value[0]) != escape_.npos))) {
            continue;
        }
        if (count == 0) {
            toks_.emplace_back(empty_string());
            continue;
        }
        auto q_index = std::find(escape_.begin(), escape_.end(), value[0]);
        std::string temp;
        if (q_index != escape_.end() &amp;&amp; value[0] == *q_index) {
            if (!remove_quotes_) {
                std::copy(value.begin(), value.end(), std::back_inserter(temp));
                toks_.push_back(temp);   // token_type::STRING
                continue;
            }
            std::copy(value.begin() + 1, value.end() - 1, std::back_inserter(temp));
            const std::string double_quote{ ""s + *q_index + *q_index };
            for (auto pos = temp.find(double_quote, 0);
                pos != std::string::npos; pos = temp.find(double_quote, 0)) {
                temp.erase(pos, 1);
            }
            value = temp;
        }
        if (type_convert_) convertString(value);
        else {
            std::copy(value.begin(), value.end(), std::back_inserter(temp));
            toks_.push_back(temp);  //;    token_type::STRING
        }
    }
    return *this;
}

tokenizer&amp; tokenizer::operator&gt;&gt;(token&amp; tok)
{
    tok = std::move(toks_.front());
    toks_.pop_front();
    return *this;
}

tokenizer&amp; tokenizer::operator&gt;&gt;(std::optional&lt;token&gt;&amp; otok)
{
    if (toks_.empty()) {
        otok = std::nullopt;
        return *this;
    }
    otok = std::move(toks_.front());
    toks_.pop_front();
    return *this;
}

void tokenizer::operator&gt;&gt;(std::vector&lt;token&gt;&amp; out)
{
    out.reserve(out.size() + toks_.size());
    out.insert(out.end(), toks_.begin(), toks_.end());
    toks_.clear();
}

std::optional&lt;token&gt; tokenizer::getNext()
{
    if (toks_.empty()) {
        return std::nullopt;
    }
    token ret(std::move(toks_.front()));
    toks_.pop_front();
    return ret;
}

std::vector&lt;token&gt; tokenizer::getVector()
{
    std::vector&lt;token&gt; ret;
    if (toks_.empty()) return ret;
    ret.reserve(toks_.size());
    std::move(toks_.begin(), toks_.end(), std::back_inserter(ret));
    toks_.clear();
    return ret;
}

void tokenizer::removeQuotes(bool remove_quotes)
{
    remove_quotes_ = remove_quotes;
    toks_.clear();
}

void tokenizer::removeBlanks(bool remove_blanks)
{
    remove_blanks_ = remove_blanks;
    toks_.clear();
}

void tokenizer::typeConvertion(bool convert)
{
    type_convert_ = convert;
    toks_.clear();
}

void tokenizer::trimWhiteSpace(bool trim)
{
    trim_ = trim;
    toks_.clear();
}

std::vector&lt;std::string_view&gt; tokenizer::splitString(std::string_view s)
{
    auto select_space = [&amp;](char c) -&gt; bool {
        if (!isspace(c)) return false;
        return delim_.find(c) == delim_.npos;
    };
    std::vector&lt;std::string_view&gt; ret;
    auto start = s.begin();
    if (trim_) while (select_space(*start)) ++start;
    auto pos_iter = std::find_first_of(start, s.end(), delim_.cbegin(),
        delim_.cend());
    while (pos_iter != s.end()) {
        auto q_index = std::find(escape_.begin(), escape_.end(), *pos_iter);
        if (q_index != escape_.end()) {
            pos_iter = std::find(pos_iter + 1, s.end(), *q_index);
            if ((pos_iter + 1) != s.end() &amp;&amp; *(pos_iter + 1) == *q_index) {
                ++pos_iter;
                continue;
            }
            pos_iter = std::find_first_of(pos_iter + 1, s.end(),
                delim_.cbegin(), delim_.cend());
        }
        auto address = &amp;s.at(start - s.begin());
        auto length = pos_iter - start;
        if (trim_) while (select_space(*(address + length - 1))) --length;
        ret.emplace_back(address, length);
        if (pos_iter == s.end()) return ret;
        if (pos_iter + 1 == s.end()) {
            ret.emplace_back("");
            return ret;
        }
        start = pos_iter + 1;
        if (trim_) while (select_space(*start)) ++start;
        pos_iter = std::find_first_of(start, s.end(), delim_.begin(),
            delim_.end());
    }
    auto address = &amp;s.at(start - s.begin());
    auto length = s.end() - start;
    if (trim_) while (select_space(*(address + length - 1))) --length;
    ret.emplace_back(address, length);
    return ret;
}

template &lt;typename T&gt;
std::optional&lt;T&gt; tokenizer::parse(std::string_view s)
{
    T value;
    auto res = std::from_chars(s.data(), s.data() + s.size(), value);
    if (res.ec != std::errc{}) return std::nullopt;
    return value;
}

void tokenizer::emplace_string(std::string_view s)
{
    std::string temp;
    std::copy(s.begin(), s.end(), std::back_inserter(temp));
    toks_.emplace_back(temp);
}

void tokenizer::convertString(std::string_view s)
{
    if (s.empty()) {
        toks_.emplace_back("");
        return;
    }
    std::uint8_t offset = 0;
    if (s[0] == '-' || s[0] == '+') ++offset;
    auto iter = std::find_if(s.begin() + offset, s.end(),
        [](unsigned char c) noexcept -&gt; bool {
            return !(isdigit(c) || c == '.');
        });
    if (iter != s.end() || s.begin() + offset == s.end()) {
        emplace_string(s);
        return;
    }
    if (s[0] == '+') {              // from_chars can't handle '+ddd'
        s = std::string_view(&amp;s.at(1), s.size() - 1);
    }
    iter = std::find(s.begin(), s.end(), '.');
    if (iter != s.end()) {
        if (auto dvalue = parse&lt;double&gt;(s)) toks_.push_back(dvalue.value());
        else emplace_string(s);
        return;
    }
    if (auto ivalue = parse&lt;int&gt;(s)) toks_.push_back(ivalue.value());
    else emplace_string(s);
    return;
}

#endif // !TOKENIZER_HPP
</code></pre>

<p>As far as testing is concerned, I have included a <code>assert</code> statements to test that the output is as expected for eight different tests that demonstrate each of the approaches to get data into and out of the <code>tokenizer</code> and look at the effects of changing the "switches." I then show how the <code>tokenizer</code> class might be used in an application that takes apart a typical .csv file (see above).</p>

<p>This is the main.cpp code</p>

<pre><code>#include &lt;algorithm&gt;
#include &lt;cassert&gt;
#include &lt;fstream&gt;
#include &lt;iostream&gt;
#include &lt;optional&gt;
#include &lt;sstream&gt;
#include &lt;string&gt;
#include &lt;string_view&gt;
#include &lt;variant&gt;
#include &lt;vector&gt;
#include "tokenizer.hpp"

using std::cout;
using namespace std::string_literals;

int main()
{
    constexpr auto typer = [](std::size_t index) -&gt; const char*
    {
        switch (static_cast&lt;token_type&gt;(index)) {
        case token_type::STRING:
            return "string";
        case token_type::DOUBLE:
            return "double";
        case token_type::INT:
        default:
            return "int";
        }
    };
    tokenizer token_maker (",", "\""); // , true, false, true
    token_maker &lt;&lt; "";
    token_maker &lt;&lt; R"("""help, this!""" ,+32 )";
    token_maker &lt;&lt; R"("gasoline",.,.0,)"; 
    std::vector&lt;token&gt; test_tokens{ "",
        R"("help, this!")",32,"gasoline",".",0.,"" };
    std::vector&lt;token&gt; tokens{ token_maker.getVector() };
    for (auto t : tokens) cout &lt;&lt; t &lt;&lt; " : " &lt;&lt; typer(t.index()) &lt;&lt; "\n";
    assert(test_tokens.size() == tokens.size() &amp;&amp; 
        std::equal(test_tokens.begin(), test_tokens.end(), tokens.begin())
        &amp;&amp; "tokens are unexpected\n");
    cout &lt;&lt; "PASSED zeroth test\n\n";
    std::string test_string;
    std::istringstream iss(R"*^*(1, """2,3"", a",   4,-1.1,,"", 5,"asdf")*^*");
    std::getline(iss, test_string);
    cout &lt;&lt; test_string &lt;&lt; " remove_quotes, !remove_blanks, convert, trim\n";
    test_tokens = std::vector&lt;token&gt;{ 1, R"("2,3", a)", 4, -1.1, "", "", 5, 
        "asdf" };
    tokens.clear();
    token_maker &lt;&lt; test_string &gt;&gt; tokens;
    assert(test_tokens.size() == tokens.size() &amp;&amp; 
        std::equal(test_tokens.begin(), test_tokens.end(), tokens.begin()) &amp;&amp;
        "tokens are unexpected in first test\n");
    for (auto t : tokens) cout &lt;&lt; t &lt;&lt; " : " &lt;&lt;
        typer(t.index()) &lt;&lt; "\n"; //  t.index()
    cout &lt;&lt; "PASSED first test\n\n";
    token_maker.removeQuotes(false);
    cout &lt;&lt; test_string &lt;&lt; " !remove_quotes, !remove_blanks, convert, trim\n";
    token_maker &lt;&lt; test_string;
    std::optional&lt;token&gt; next_tok;
    test_tokens = std::vector&lt;token&gt;{ 1, R"("""2,3"", a")", 4, -1.1, "\"\"", 
        "\"\"", 5, "\"asdf\"" };
    auto iter_test = test_tokens.begin();
    token_maker &gt;&gt; next_tok;
    while (next_tok) {
        assert(iter_test != test_tokens.end() &amp;&amp; 
            *next_tok == *iter_test++ &amp;&amp; "unexpected tokens in second test");
        cout &lt;&lt; *next_tok &lt;&lt; " : " &lt;&lt; typer(next_tok-&gt;index()) &lt;&lt; "\n";
        token_maker &gt;&gt; next_tok;
    }
    cout &lt;&lt; "PASSED second test\n\n";
    token_maker.removeBlanks(true);
    cout &lt;&lt; test_string &lt;&lt; " !remove_quotes, remove_blanks, convert, trim\n";
    test_tokens.erase(test_tokens.begin()+4);
    token_maker &lt;&lt; test_string;
    iter_test = test_tokens.begin();
    while (auto next_tok = token_maker.getNext()) {
        assert(iter_test != test_tokens.end() &amp;&amp;
            *next_tok == *iter_test++ &amp;&amp; "unexpected tokens in third test");
        cout &lt;&lt; *next_tok &lt;&lt; " : " &lt;&lt;
            typer(next_tok-&gt;index()) &lt;&lt; "\n";
    }
    cout &lt;&lt; "PASSED third test\n\n";
    token_maker.typeConvertion(false);
    token_maker.trimWhiteSpace(false);
    cout &lt;&lt; test_string &lt;&lt; " !remove_quotes, remove_blanks, !convert, !trim\n";
    tokens.clear();
    token_maker &lt;&lt; test_string &gt;&gt;tokens;
    for (auto t : tokens) {
        cout &lt;&lt; t &lt;&lt; " : " &lt;&lt; typer(t.index()) &lt;&lt; "\n";
        assert(static_cast&lt;token_type&gt;(t.index()) == token_type::STRING &amp;&amp;
        "tokens are unexpected in fourth test\n");
    }
    cout &lt;&lt; "PASSED fourth test\n\n";
    token_maker.removeQuotes(true);
    token_maker.typeConvertion(true);
    token_maker.trimWhiteSpace(true);
    cout &lt;&lt; test_string &lt;&lt; " remove_quotes, remove_blanks, convert, trim\n";
    tokens.clear();
    test_tokens = std::vector&lt;token&gt;{ 1, R"("2,3", a)", 4, -1.1,  5, "asdf" };
    iter_test = test_tokens.begin();
    token_maker &lt;&lt; test_string &gt;&gt; tokens;
    for (auto t : tokens) {
        assert(iter_test != test_tokens.end() &amp;&amp; 
            t == *iter_test++ &amp;&amp; "unexpected tokens in fifth test");
        cout &lt;&lt; t &lt;&lt; " : " &lt;&lt; typer(t.index()) &lt;&lt; "\n";
    }
    cout &lt;&lt; "PASSED fifth test\n\n";
    cout &lt;&lt; "space delimited 'this is a + text now  ' ";
    cout &lt;&lt; " remove_quotes, !remove_blanks, convert, trim\n";
    tokenizer token_maker2{ " ","" };
    token_maker2 &lt;&lt; "this is a +  text now  ";
    test_tokens = 
        std::vector&lt;token&gt;{ "this","is","a","+","","text","now","","" };
    iter_test = test_tokens.begin();
    while (auto next_tok = token_maker2.getNext()) {
        cout &lt;&lt; '\"' &lt;&lt; *next_tok &lt;&lt; '\"' &lt;&lt; "\n";
        assert(iter_test != test_tokens.end() &amp;&amp; *next_tok == *iter_test++
            &amp;&amp; "unexpected tokens in fifth test");
    }
    cout &lt;&lt; "PASSED sixth test\n\n";
    token_maker.removeBlanks(false);
    cout &lt;&lt; "Breaking down typical .csv file: delimited by , using \"";
    cout &lt;&lt; " as escape characters, and removeQuotes = true, ";
    cout &lt;&lt; "removeBlanks = false, typeConvertion = true\n\n";
    std::vector&lt;token&gt; headings;
    headings.reserve(15);
    std::ifstream test_data("ExportedGridData.csv");
    if (!test_data.is_open()) std::exit(EXIT_FAILURE);
    std::getline(test_data, test_string);
    token_maker &lt;&lt; test_string &gt;&gt; headings;
    int i=0, category_column=-1;
    for (auto t : headings) {
        std::string s = *std::get_if&lt;std::string&gt;(&amp;t);
        if (s.find("Categories", 0)!=s.npos) category_column = i;
        ++i;
    }
    const auto last_column = headings.size() - 1;
    if (last_column != category_column) {
        headings.erase(headings.begin() + category_column);
        headings.emplace_back("Categories"s);
    }
    for (auto t : headings) cout &lt;&lt; t &lt;&lt; " ";
    cout &lt;&lt; "\n";
    while (std::getline(test_data, test_string)) {
        token_maker &lt;&lt; test_string;
        std::vector&lt;token&gt; data;
        token_maker &gt;&gt; data;
        token_maker &lt;&lt; std::get&lt;std::string&gt;(data.at(category_column)) &gt;&gt; data;
        data.erase(data.begin()+category_column);
        std::sort(data.begin() + last_column, data.end(), 
            [](const token &amp; a, const token &amp; b) -&gt; bool {
                return a &lt; b;
            });
        for (auto s : data) cout &lt;&lt; s &lt;&lt; " ";
        cout &lt;&lt; "\n";
    }
}
</code></pre>

<p>This is the output:</p>

<pre><code> : string
"help, this!" : string
32 : int
gasoline : string
. : string
0 : double
 : string
PASSED zeroth test

1, """2,3"", a",        4,-1.1,,"", 5,"asdf" remove_quotes, !remove_blanks, convert, trim
1 : int
"2,3", a : string
4 : int
-1.1 : double
 : string
 : string
5 : int
asdf : string
PASSED first test

1, """2,3"", a",        4,-1.1,,"", 5,"asdf" !remove_quotes, !remove_blanks, convert, trim
1 : int
"""2,3"", a" : string
4 : int
-1.1 : double
"" : string
"" : string
5 : int
"asdf" : string
PASSED second test

1, """2,3"", a",        4,-1.1,,"", 5,"asdf" !remove_quotes, remove_blanks, convert, trim
1 : int
"""2,3"", a" : string
4 : int
-1.1 : double
"" : string
5 : int
"asdf" : string
PASSED third test

1, """2,3"", a",        4,-1.1,,"", 5,"asdf" !remove_quotes, remove_blanks, !convert, !trim
1 : string
 """2,3"", a" : string
        4 : string
-1.1 : string
"" : string
 5 : string
"asdf" : string
PASSED fourth test

1, """2,3"", a",        4,-1.1,,"", 5,"asdf" remove_quotes, remove_blanks, convert, trim
1 : int
"2,3", a : string
4 : int
-1.1 : double
5 : int
asdf : string
PASSED fifth test

space delimited 'this is a + text now  '  remove_quotes, !remove_blanks, convert, trim
"this"
"is"
"a"
"+"
""
"text"
"now"
""
""
PASSED sixth test

Breaking down typical .csv file: delimited by , using " as escape characters, and removeQuotes = true, removeBlanks = false, typeConvertion = true

Order Question Title ID/Rev Type Status difficulty Weight Avg Answer Time Group Last Editor Categories
1 Free Radical 66526 / 2 MChoice TRUE 0.623596 1 1:16  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) L01 - Introductory Parts
2 Phosphatitic acid 70264 / 1 MChoice TRUE 0.314286 1 1:44  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) L01 - Introductory Parts
3 Copy of Epimers 2 70231 / 1 MChoice TRUE 0.0714286 1 3:24  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) L01 - Introductory Parts
4 'Epimers 2' 70230 / 1 MChoice TRUE 0.457143 1 2:45  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) L01 - Introductory Parts
5 "Anabolism" 65576 / 4 MChoice TRUE 0.62605 1 1:05  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) Fed/Fast L01 - Introductory
6 dilution of hydroxide 70284 / 2 Fill in the Blank TRUE 0.185714 1 2:58  Harrison, D B01 Biochemistry BT02 - Interpretation (applying and analyzing) L01 - Introductory Water/pH/pKa
7 What Changes 68853 / 2 MChoice TRUE 0.414286 1 1:52  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) L01 - Introductory Protein Structure-Function
8 Secondary Structure 68854 / 1 MChoice TRUE 0.357143 1 1:33  Harrison, D B01 Biochemistry BT01 - Recall (remembering and understanding) L01 - Introductory Protein Structure-Function
9 Kinases 3358 / 2 MChoice TRUE 0 1 -  Harrison, D B01 Biochemistry B05 Biochemistry/Biotechnology B05.01 chemistry of biomacromolecules (proteins Protein Structure-Function and DNA) carbohydrates lipids
10 Competitive FITB 21116 / 4 Fill in the Blank TRUE 0.185714 1 5:53 NC Harrison, D B01 Biochemistry BT02 - Interpretation (applying and analyzing) Enzyme Regulation L01 - Introductory
</code></pre>

<p>I hope this helps. Additional comments welcome.</p>
    </div>