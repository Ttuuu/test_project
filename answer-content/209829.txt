<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Although I'm not an expert on this, I thought to come up with a solution which I've been following quite some time.
Making use of <code>signals</code> might be a wise attempt here. When the scraping process is done, the <code>spider_closed()</code> method is invoked and thus the <code>DictWriter()</code> will be open once and when the writing is finished, it will be closed automatically because of the <code>with statement</code>. That said there is hardly any chance for your script to be slower, if you can get rid of <code>Disk I/O</code> issues.</p>

<p>The following script represents what I told you so far:</p>

<pre><code>import scrapy
from scrapy.crawler import CrawlerProcess
from scrapy import signals
import csv

class TorrentSpider(scrapy.Spider):
    name = "torrentdata"
    start_urls = ["https://yts.am/browse-movies?page={}".format(page) for page in range(2,10)] #get something within list
    itemlist = []

    @classmethod
    def from_crawler(cls, crawler):
        spider = super().from_crawler(crawler)
        crawler.signals.connect(spider.spider_closed, signals.spider_closed)
        return spider

    def spider_closed(self):
        with open("outputfile.csv","w", newline="") as f:
            writer = csv.DictWriter(f,['Name','Year'])
            writer.writeheader()
            for data in self.itemlist:
                writer.writerow(data)

    def parse(self, response):
        for record in response.css('.browse-movie-bottom'):
            items = {}
            items["Name"] = record.css('.browse-movie-title::text').extract_first(default='')
            items["Year"] = record.css('.browse-movie-year::text').extract_first(default='')
            self.itemlist.append(items)

c = CrawlerProcess({
    'USER_AGENT': 'Mozilla/5.0',   
})
c.crawl(TorrentSpider)
c.start()
</code></pre>
    </div>