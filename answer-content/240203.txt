<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Some small performance can be gained by directly yielding from the iterator instead of having a <code>for</code> loop do it, using the <code>yield from</code> keywords, and using <code>list()</code> instead of a list comprehension:</p>

<pre><code>def tokenize2(text):
    yield from PAT_ALPHABETIC.finditer(text)

def preprocessing2(doc):
    return list(tokenize2(doc))
</code></pre>

<p>For the given example document this gives about a 15% speed-up:</p>

<pre><code>In [15]: %timeit preprocessing(doc)
335 ms ± 2.29 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [16]: %timeit preprocessing2(doc)
287 ms ± 2.79 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>

<p>Slightly faster yet is not even having the <code>preprocessing</code> function and directly returning all tokens (this avoids one function call and lets the <code>re</code> do its best):</p>

<pre><code>def tokenize3(text):
    return PAT_ALPHABETIC.findall(text)
</code></pre>

<p>This is about 35% faster then the code in the OP: </p>

<pre><code>In [21]: %timeit tokenize3(doc)
217 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>

<p>Other than that, we can't really help you without seeing more of your script. You can probably parallelize this task by scanning multiple documents in parallel, and especially by making downloading and scanning asynchronous, so that you scan a document whenever it finishes downloading, but already download the next document(s) in the background.</p>
    </div>