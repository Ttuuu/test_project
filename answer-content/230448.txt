<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Exploiting sparseness is a nice trick, though not as good as <a href="https://en.wikipedia.org/wiki/Hashlife" rel="nofollow noreferrer">Hashlife</a> (it's in a class of its own). Hashlife aside, there are simple approaches that work well on actual computers, not by being algorithmically clever but by being computer-friendly. Compared to a a completely plain approach, yours is definitely better. But it does not really tap into the potential of a modern CPU.</p>

<p>For example on my PC (using a 4770K, so not very new any more), your benchmark takes around 2.85 seconds, but if I use some really simple no-tricks AVX2 implementation (so not using sparseness or anything else clever) of Game of Life, that takes around 0.38 seconds. That's around 7.5x faster, even though a lot more <em>work</em> is done. But work isn't time, and SIMD is great at crunching through a lot of work in a short time especially if you're working with 8-bit types. </p>

<p>In a benchmark with a much sparser grid, the SIMD approach wouldn't do so well. Even in this benchmark, simulating more steps decreases the speedup, going down to ~3.7x for 100000 steps.</p>

<p><a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions" rel="nofollow noreferrer">AVX2</a> is an instruction set extension available in many x86 CPUs today, for example Haswell and newer Intel processors (including i7-8565U, but the Mystery Xeon CPU in the grading server may or may not support AVX2 depending on how old it is), and AMD Excavator and Zen. The instructions are exposed in C++ as intrinsic functions if you use a compiler that supports them. AVX2 includes instructions that apply an operation to 32 bytes at once, for example in the code below I used <a href="https://www.officedaytime.com/simd512e/simdimg/binop.php?f=paddb" rel="nofollow noreferrer"><code>_mm256_add_epi8</code></a> (aka <code>vpaddb</code>) several times, each performing 32 additions at once, to sum up the number of live neighbours for a row of 32 cells simultaneously. </p>

<p>Example code:</p>

<pre><code>void step() {
#define INDEX(a, b) ((a) + (b) * WIDTH)
    for (size_t y = 0; y &lt; HEIGHT; y++) {
        if (y == 0 || y == MAX_Y) {
            for (size_t x = 0; x &lt; WIDTH; x++) {
                next_board[INDEX(x, y)] = board[INDEX(x, y)];
            }
        }
        else {
            next_board[INDEX(0, y)] = board[INDEX(0, y)];
            next_board[INDEX(MAX_X, y)] = board[INDEX(MAX_X, y)];
            size_t x = 1;
            for (; x &lt; WIDTH - 33; x += 32) {
                __m256i n = _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x - 1, y - 1)]);
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x, y - 1)]));
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x + 1, y - 1)]));
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x - 1, y)]));
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x + 1, y)]));
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x - 1, y + 1)]));
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x, y + 1)]));
                n = _mm256_add_epi8(n, _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x + 1, y + 1)]));
                __m256i is3 = _mm256_cmpeq_epi8(n, _mm256_set1_epi8(3));
                __m256i is2 = _mm256_cmpeq_epi8(n, _mm256_set1_epi8(2));
                __m256i cellItself = _mm256_loadu_si256((__m256i*)&amp;board[INDEX(x, y)]);
                __m256i isNextLive = _mm256_or_si256(is3, _mm256_and_si256(is2, cellItself));
                isNextLive = _mm256_abs_epi8(isNextLive);
                _mm256_storeu_si256((__m256i*)&amp;next_board[INDEX(x, y)], isNextLive);
            }
            for (; x &lt; WIDTH - 1; x++) {
                int n = board[INDEX(x - 1, y - 1)];
                n += board[INDEX(x, y - 1)];
                n += board[INDEX(x + 1, y - 1)];
                n += board[INDEX(x - 1, y)];
                n += board[INDEX(x + 1, y)];
                n += board[INDEX(x - 1, y + 1)];
                n += board[INDEX(x, y + 1)];
                n += board[INDEX(x + 1, y + 1)];
                next_board[INDEX(x, y)] = n == 3 || (n == 2 &amp;&amp; board[INDEX(x, y)]);
            }
        }
    }

    swap(board, next_board);
}
</code></pre>

<p>There are <a href="https://lemire.me/blog/2018/07/18/accelerating-conways-game-of-life-with-simd-instructions/" rel="nofollow noreferrer">more clever uses of AVX2</a>, for example using <code>vpshufb</code> to implement the automaton rule.</p>

<p>An other popular approach is bit-packing the cells, and then using bitwise operations to calculate the next state, relying on the bit-parallel nature of bitwise operations to speed up the computation. <a href="https://www.cs.uaf.edu/2012/spring/cs641/lecture/02_14_SIMD.html" rel="nofollow noreferrer">This page</a> discusses that trick and some related history. </p>
    </div>