<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>Naming</h1>

<p>Variable names should be <code>snake_case</code>, and should represent what they are containing. I would also use <code>req</code> instead of <code>r</code>. The extra two characters aren't going to cause a heartache.</p>

<h1>Constants</h1>

<p>You have the same headers dict in four different places. I would instead define it once at the top of the file in <code>UPPER_CASE</code>, then just use that wherever you need headers. I would do the same for <code>site</code>.</p>

<h1>List Comprehension</h1>

<p>I would go about collecting categories in this way:</p>

<pre><code>categories = [link['href'] for link in soup.findAll(href=re.compile(r'/category/\w+$'))]
</code></pre>

<p>It's shorter and utilizes a quirk in the python language. Of course, if you want to print out each one, then add this just after:</p>

<pre><code>for category in categories:
    print(category)
</code></pre>

<p>Also, it seems like you assign <code>category_link</code> to the last element in the list, so that can go just outside the list comprehension.</p>

<h1>Save your assignments</h1>

<p>Instead of assigning the result of <code>soup.find</code> to a variable, then using it in a loop, simply put that <code>soup.find</code> in the loop. Take a look:</p>

<pre><code>for articles in soup.findAll(class_="chapter-chs"):
    for chapters in articles.findAll("a"):
        ....
</code></pre>

<p></p><hr>
As a result of the above changes, you code would look something like this:

<pre><code>from requests import get
from bs4 import BeautifulSoup
import re

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)"}
SITE = "https://readlightnovel.org/"

req = get(SITE, headers=HEADERS)
soup = BeautifulSoup(req.text, "lxml")
category = soup.findAll(class_="search-by-genre")

categories = [link['href'] for link in soup.findAll(href=re.compile(r'/category/\w+$'))]
category_link = categories[-1]

# Getting all Novel Headers
for category in categories:
    req = get(category_link, headers=HEADERS)
    soup = BeautifulSoup(req.text, "lxml")
    novels_header = soup.findAll(class_="top-novel-header")


    # Getting Novels' Title and Link
    for novel_names in novels_header:
        print("Novel:", novel_names.text.strip())

        novel_link = novel_names.find('a')['href']

        # Getting Novel's Info
        req = get(novel_link, headers=HEADERS)
        soup = BeautifulSoup(req.text, "lxml")

        # Novel Chapters
        for articles in soup.findAll(class_="chapter-chs"):
            for chapters in articles.findAll("a"):
                ch = chapters["href"]

                # Getting article
                req = get(ch, headers=HEADERS)
                soup = BeautifulSoup(req.content, "lxml")
                title = soup.find(class_="block-title")
                print(title.text.strip())
                full_article = soup.find("div", {"class": "desc"})

                # remove ads inside the text:
                for ads in full_article.select('center, small, a'):
                    ads.extract()

                print(full_article.get_text(strip=True, separator='\n'))
</code></pre>
    </div>