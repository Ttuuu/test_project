<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Your bottleneck is probably that you write the file to disk first and then read it again (I/O).
If the file does not exceed your machines random access memory, decompressing the file on the fly in memory might be a faster option:</p>

<pre><code>from gzip import decompress
from json import loads

from requests import get

def get_gzipped_json(url):
    return loads(decompress(get(url).content))

if __name__ == '__main__':
    print(get_gzipped_json("https://xxxxx.auth0.com/1537150574"))
</code></pre>

<p>Also note, that I put the running code into an <code>if __name__ == '__main__':</code> guard.</p>
    </div>