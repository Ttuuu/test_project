<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h2>Interface design</h2>

<p>Note that you only support nonnegative integers as operands.</p>

<p>Your algorithm correctly rearranges the input tokens in postfix order, but it would be more useful if it preserved the operator/operand categorization in its output.  It's likely that the results will be fed to an RPN evaluator, and it would be nice if the RPN evaluator didn't have to redo that work.  (Your <code>._is_operator()</code> and <code>._is_operand()</code> methods are "private", and therefore shouldn't be reused.)</p>

<p>Consider turning <code>.parse()</code> and <code>.tokenize()</code> into generators that <code>yield</code>s their results as they go, instead of building a list to be returned.</p>

<p>I don't see <a href="https://pyvideo.org/pycon-us-2012/stop-writing-classes.html" rel="noreferrer">any reason to define <code>ShuntingYardParser</code> as a class</a>.  The class doesn't keep any instance state, so it's just a glorified namespace.  It would be less cumbersome to write these "methods" as functions in the <code>ShuntingYardParser.py</code> module.</p>

<h2>Implementation</h2>

<p>The tokenizer could take advantage of regular expressions to classify the token types, so that you wouldn't need <code>._is_operand()</code> and <code>.is_operator()</code>.  I suggest using the <a href="https://docs.python.org/3/library/re.html#writing-a-tokenizer" rel="noreferrer">tokenizer recipe</a> in Python's <code>re</code> documentation.</p>

<p>In <code>.parse()</code>, <code>operators</code> doesn't need to be a <code>collections.deque</code>; a list would work just fine.</p>

<p>You don't really need to test <code>if not isinstance(infix_expression, str):</code>, since regular expression searches on anything other than a string (or bytestring) will raise a <code>TypeError</code> anyway.</p>

<p>"parenthesises" is not a word.  The exception message could be more informative, specifying whether an opening or closing parenthesis is unmatched.</p>

<p>Similarly, the "Syntax error" could be more specific about the offending token.</p>

<p>To print the message associated with a caught exception (rather than some weird <code>args</code> tuple), do:</p>

<pre><code>except ValueError as e:
    print(e)
</code></pre>

<h2>Suggested solution</h2>

<p>ShuntingYardParser.py</p>

<pre><code>from collections import namedtuple
import re

class Token(namedtuple('Token', 'kind value')):
    @property
    def precedence(self):
        if self.kind == 'OPERATOR':
            return {
                '*': 3, '/': 3,
                '+': 2, '-': 2,
            }[self.value]

def tokenize(expression):
    """
    Yield tokens in the order that they are encountered in the expression.
    """
    # https://docs.python.org/3/library/re.html#writing-a-tokenizer
    token_spec = [
        ('PAREN',       r'[()]'),
        ('OPERATOR',    r'[+*/-]'),
        ('OPERAND',     r'\d+'),
        ('IGNORE',      r'\s+'),
        ('JUNK',        r'\S+?\b'),
    ]
    tokenizer = re.compile('|'.join(
        '(?P&lt;{kind}&gt;{pattern})'.format(kind=kind, pattern=pattern)
        for kind, pattern in token_spec
    ))
    for match in tokenizer.finditer(expression):
        kind, value = match.lastgroup, match.group(match.lastgroup)
        if kind == 'JUNK':
            raise ValueError('Unrecognized token: {0}'.format(value))
        elif kind != 'IGNORE':
            yield Token(kind, value)

def parse(infix_expression):
    """
    Yield tokens in the infix expression, reordered as as a postfix expression.
    """
    operators = []
    for token in tokenize(infix_expression):
        if token.kind == 'OPERAND':
            yield token

        elif token.kind == 'OPERATOR':
            while (operators and
                   operators[-1].value != '(' and
                   operators[-1].precedence &lt;= token.precedence):
                yield operators.pop()
            operators.append(token)

        elif token.value == '(':
            operators.append(token)

        elif token.value == ')':
            # Pop all the operators in front of the "(".
            while operators and operators[-1].value != '(':
                yield operators.pop()
            if not operators:
                raise ValueError('Unmatched )')
            # Remove matching prenthesis.
            operators.pop()

    for operator in operators:
        if operator.value == '(':
            raise ValueError('Unmatched (')
        yield operator


if __name__ == '__main__':
    while True:
        try:
            postfix_expr = parse(input("Enter infix expression: "))
            print([op for op in postfix_expr])
        except ValueError as e:
            print(e)
</code></pre>

<p>Unit tests:</p>

<pre><code>import unittest
import ShuntingYardParser

class TestShuntingYardParser(unittest.TestCase):
    def test_single_number(self):
        output = list(ShuntingYardParser.parse("5"))
        self.assertEqual(output, [
            ShuntingYardParser.Token('OPERAND', '5'),
        ])

    def test_non_string_input(self):
        # arrange &amp; act &amp; assert
        self.assertRaises(TypeError, lambda: list(ShuntingYardParser.parse(5)))

    â€¦
</code></pre>
    </div>