<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>While decorators are fun to learn about (especially when you get to decorators taking arguments and class decorators) and they can be quite useful, I think this decorator should not be one. Sorry.</p>

<p>Your code becomes much easier to read and understand by making this into two functions, one that gets the links and one that gets the title from a link, which you then apply to each link:</p>

<pre><code>import requests
from urllib.parse import urljoin
from bs4 import BeautifulSoup

def get_title(link):
    """Load a link to get the page title."""
    res = requests.get(link)
    soup = BeautifulSoup(res.text,"lxml")
    return soup.title.text.split(" - ")[1] # Will only work exactly like this  with Stackexchange
    # return soup.select_one("h1[itemprop='name'] a").text

def get_links(link):
    """Get all links from a page."""
    res = requests.get(link)
    soup = BeautifulSoup(res.text,"lxml")
    relative_urls = soup.select(".summary .question-hyperlink")
    return [urljoin(url, items.get('href')) for items in relative_urls]


if __name__ == '__main__':
    url = "https://stackoverflow.com/questions/tagged/web-scraping"
    links = get_links(url)
    link_titles = [get_title(link) for link in links]
    print(link_titles)
</code></pre>

<p>If you really want to, you can then make a new function that uses these two functions:</p>

<pre><code>def get_link_titles(url):
    """Get the titles of all links present in `url`."""
    return [get_title(link) for link in get_links(url)]
</code></pre>

<p>In addition, you should use <a href="http://docs.python-requests.org/en/master/user/advanced/#session-objects" rel="nofollow noreferrer"><code>requests.Session</code></a> to reuse the connection to the website (since you are always connecting to the same host).</p>

<p>You could put getting a page and parsing it with <code>BeautifulSoup</code> into its own function:</p>

<pre><code>SESSION = requests.Session()

def get_soup(url):
    res = SESSION.get(url)
    return BeautifulSoup(res.text,"lxml")
</code></pre>

<p>You might also want to check the headers for a rate limit, because when I ran your code and tried to time it, Stack Exchange temporarily blocked me after some time because the request rate was too high :).</p>
    </div>