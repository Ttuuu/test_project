<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I don't see a good reason why this should be a class. You only have two things in your state, <code>self.text</code>, which you could pass as an argument, and <code>self.path, self.output_path</code>, which I would also pass as arguments, maybe with a default value.</p>

<p>Also, you are probably using classes wrong if your class has a <code>main</code> method that needs to instantiate new instances of the class on the fly.</p>

<p>Your algorithm is not very efficient. You need to run over the whole text <em>twice</em> for each keyword. Once to check if it is in there and then again to <code>count</code> it. The former is obviously redundant, since <code>str.count</code> will just return <code>0</code> if the value is not present.</p>

<p>However, what would be a better algorithm is to first extract all the words (for example using a regex filtering only letters) and then count the number of times each word occurs using a <code>collections.Counter</code>, optionally filtering it down to only those words which are keywords. It even has a <code>most_common</code> method, so your file will be ordered by number of occurrences, descending.</p>

<p>Instead of mucking around with <code>os.getcwd()</code> and <code>os.listdir</code>, I would recommend to use the (Python 3) <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" rel="nofollow noreferrer"><code>pathlib.Path</code></a> object. It supports globbing (to get all files matching a pattern), chaining them to get a new path and even replacing the extension with a different one.</p>

<p>When reading the keywords, you can use a simple list comprehension. Or, even better, a set comprehension to get <code>in</code> calls for free.</p>

<p><code>line.strip()</code> and <code>line.strip("\n")</code> are probably doing the same thing, unless you <em>really</em> want to preserve the spaces at the end of words.</p>

<p>At the same time, doing <code>self.filename.strip('.pdf')</code> is a bit dangerous. It removes all characters given, until none of the characters is found anymore. For example, <code>"some_file_name_fdp.pdf"</code> will be reduced to <code>"some_file_name_"</code>.</p>

<p>The <code>csv.writer</code> has a <a href="https://docs.python.org/3/library/csv.html#csv.csvwriter.writerows" rel="nofollow noreferrer"><code>writerows</code></a> method that takes an iterable of rows. This way you can avoid a <code>for</code> loop.</p>

<p>I would ensure to run only over PDF files, otherwise you will get some errors if a non-PDF file manages to sneak into your folder.</p>

<p>I have done all of this in the following code (not tested, since I don't have <code>textract</code> installed ATM):</p>

<pre><code>from collections import Counter
import csv
from pathlib import Path
import re
import textract

def extract_text(file_name):
    return textract.process(file_name, method='tesseract', language='eng',
                            encoding='utf-8').decode('utf-8')

def extract_words(text):
    return re.findall(r'([a-zA-Z]+)', text)

def count_keywords(words, keywords):
    return Counter(word for word in words if word in keywords)

def read_keywords(file_name):
    with open(file_name) as f:
        return {line.strip() for line in f}

def save_keywords(file_name, keywords):
    with open(file_name, "w", newline='') as csvfile:
        writer = csv.writer(csvfile, delimiter=',')
        writer.writerow(['keyword', 'keyword_count'])
        writer.writerows(keywords.most_common())

def main():
    output_folder = Path("output_results")
    keywords = read_keywords('keywords.txt')

    for f in Path("folderForPdf").glob("*.pdf"):
        words = extract_words(extract_text(f))
        keyword_counts = count_keywords(words, keywords)
        save_keywords(output_folder / f.with_suffix(".csv"), keyword_counts)

if __name__ == "__main__":
    main()
</code></pre>
    </div>