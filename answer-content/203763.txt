<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I'd expect that most of the performance problem comes from the indirect branch (<code>jmp qword ptr [r15 + r10 * 8]</code>) - it's relatively unpredictable and should cause lots of branch mispredictions, bad speculations and pipeline stalls.</p>

<p>There's only really 2 ways to deal with this:</p>

<p>1) Amortise the cost. For example, if you packed 4 instructions into <code>r10</code> and had a significantly larger jump table you could reduce the number of indirect branches the CPU has to do to 25% (and therefore reduce the branch mispredictions, etc). Note that BF only really has 8 instructions so you only need 3-bit opcodes, so packing 4 together could cost 12 bits and give you a 4096-entry jump table.</p>

<p>2) Use JIT techniques. This would probably be an order of magnitude faster, but would involve a significant "redesign and rewrite". [ADDED] For one possibility, instead of pre-compiling the BF into a "16-bit opcode + 16-bit operand" form, you could precompile BF instructions into a series of <code>call ...</code> 80x86 instructions and then execute the resulting series of calls. This wouldn't be "full JIT" (wouldn't be generating native code for the actual work) but it would be using "JIT techniques" (to generate code to optimise the whole "fetch and decode" part of the interpreter).</p>
    </div>