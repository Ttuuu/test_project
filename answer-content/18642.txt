<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Q: <em>should I create as many cursors as the number of threads?</em></p>

<p>A: <del>Yes</del> Maybe. Don't share DB connection among threads, as docs say thread safety level = 1. Maybe better to have a <code>queue</code> of db connections. Once a thread popped a cursor from the queue, it's his only.</p>

<p>Q: <em>do I really need to lock the execution of a query?</em></p>

<p>A: No. Trust your DB to take care for its own locking. That's what DBs are for. </p>

<p>Q: <em>I read about the Queue class...</em></p>

<p>A: <del>You don't need any locks <em>at all</em> in this code. Just don't share anything.</del> Yap, a <code>queue</code> of db connections would be great here.</p>

<p>Q: <em>using multithreading can I suffer from I/O (network) bottleneck?</em></p>

<p>A: Yes, but that's not a point against threads.</p>

<p>Q: <em>using my code, there could be a bottleneck...</em></p>

<p>A: Though 'bottles necks' should be verified by testing, not by reading anonymous posts on forums, it's very likely that <em>downloading the files</em> will always be your bottle neck, regardless of implementation.</p>

<p>Q: <em>if the way to go is multithreading, is 100 an high number of threads?</em></p>

<p>A: I don't think you should explicitly use threads <em>at all</em> here. Can't you assign a callback to an async http request?</p>

<hr>

<p>Code sample for async http request, taken almost as-is from <a href="http://www.doughellmann.com/PyMOTW/asyncore/" rel="nofollow">this post</a>:</p>

<p>I still owe you the db part.</p>

<pre><code>import socket
import asyncore
from cStringIO import StringIO
from urlparse import urlparse

def noop(*args):
    pass

class HttpClient(asyncore.dispatcher):
    def __init__(self, url, callback = noop):
        self.url = url
        asyncore.dispatcher.__init__(self)
        self.write_buffer = 'GET %s HTTP/1.0\r\n\r\n' % self.url
        self.read_buffer = StringIO()
        self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
        self.connect((urlparse(url).netloc, 80))
        self.on_close = callback

    def handle_read(self):
        data = self.recv(8192)
        self.read_buffer.write(data)

    def handle_write(self):
        sent = self.send(self.write_buffer)
        self.write_buffer = self.write_buffer[sent:]

    def handle_close(self):
        self.close()
        self.on_close(self.url, self.read_buffer.getvalue())

def parse(source, response):
    print source, 'got', len(response), 'bytes' 

if __name__ == '__main__':
    clients = [HttpClient('http://codereview.stackexchange.com/questions/18618/improve-multithreading-with-network-io-and-database-queries/18642#18642/', parse),
        HttpClient('http://www.doughellmann.com/PyMOTW/contents.html', parse)]

    print ('LOOP STARTING')
    asyncore.loop()
    print ('LOOP DONE')
</code></pre>
    </div>