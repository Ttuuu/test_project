<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>When we are discussing performance of a particular piece of code, it's important to recognize bottlenecks and major contributors to the runtime of the program.</p>

<p>In your particular case, even though you've applied some optimizations like <code>SoupStrainer</code> speed-up for HTML parsing, the <em>synchronous nature of the script</em> is the biggest problem by far. The script is processing pages one by one, not getting to the next page until the processing for the current page is finished.</p>

<p>Switching to an asynchronous approach would be the natural next step in your optimizations. Look into using third-party frameworks like <a href="https://scrapy.org/" rel="nofollow noreferrer"><code>Scrapy</code></a> or, if you are adventurous, things like <code>asyncio</code> or <code>grequests</code>. </p>

<hr>

<p>You could apply one more optimization to your current script which should help you optimize the "crawling/scraping" part - instead of using <code>requests.get()</code>, initialize <code>session = requests.Session()</code> and use <code>session.get()</code> to make requests (<a href="http://docs.python-requests.org/en/master/user/advanced/#session-objects" rel="nofollow noreferrer">documentation</a>). This would allow the underlying TCP connection to be re-used for subsequent requests resulting in a performance increase.</p>
    </div>