<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Apart from speeding up your code, there are some other improvements possible that I don't see mentioned yet.</p>

<h1>The speedup</h1>

<p>As other users have already picked up, you only need to transform around 200 countries instead of 17k rows. You can do this efficiently by storing the mapping in a <strong>dictionary</strong>:</p>

<pre><code>iso_map = {country: do_fuzzy_search(country) for country in df["Country"].unique()}
df["country_code"] = df["Country"].map(iso_map)
</code></pre>

<p>This is in essence very similar to using the <code>lru_cache</code> proposed by Peilonrayz, but it's a bit more explicit.</p>

<hr>

<h1>Consistent naming</h1>

<p>As a side note, I would advise you to use a consistent naming scheme in your DataFrame. This doesn't have to follow the python convention, but it should be easy to remember.</p>

<p>For example, turn all columns to lowercase by using something like:</p>

<pre><code>df = df.rename(columns = {name: name.lower() for name in df.columns}
</code></pre>

<hr>

<h1>Using categoricals</h1>

<p>Since the number of countries (and isocodes) is limited, you might want to consider using <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html" rel="noreferrer">categorical columns</a>. These have the advantage of requiring less memory and being faster on some operations. </p>

<p>It might not be worth the extra lines of code in your situation, but it's something useful to keep in the back of your mind.</p>
    </div>