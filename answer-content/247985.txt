<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>As mentioned in <a href="https://codereview.stackexchange.com/a/247927/1581">Joseph's excellent answer</a>, your server is vulnerable to a <em>path-traversal attack</em>. If I send it a request with enough <code>..</code>s in it, I can reach the root directory, and thus any directory from there.</p>
<p>E.g. if your web root is <code>/var/www/root</code>, and I request the URI <code>../../usr/share/doc/bc/bc.html</code>, I will get the HTML documentation of the <code>bc</code> command from your PC. In fact, I can get <em>any</em> HTML document from your PC (including e.g. a <code>bookmarks.html</code> from a browser).</p>
<p>You are asking (<strong>bold</strong> emphasis mine)</p>
<blockquote>
<p>I'm looking for <strong>all kind of feedback</strong>, from style, code smells, anti-patterns, <strong>anything that can be improved</strong> is very welcome.</p>
</blockquote>
<p>So, I will answer your question in a direction that you probably didn't intend but might be interesting for you anyway.</p>
<p>"Real" webservers support a lot of additional features, for example:</p>
<ul>
<li>Virtual Hosts</li>
<li>Access Control</li>
<li>Server-side scripting</li>
<li>Redirection</li>
<li>Compression</li>
</ul>
<p>to name just a few.</p>
<p>Obviously, your web server is only intended as a simple exercise, and all of these features require complex configuration files and massive machinery â€¦ or do they?</p>
<p>It turns out, there are actually some tiny web servers that support some or all of these features in a clever way. For example, <a href="http://www.fefe.de/" rel="nofollow noreferrer">Felix von Leitner (fefe)</a>'s <a href="http://www.fefe.de/fnord/" rel="nofollow noreferrer">fnord (discontinued)</a> and <a href="http://www.fefe.de/gatling/" rel="nofollow noreferrer">gatling</a>, or <a href="http://acme.com/" rel="nofollow noreferrer">ACME Labs</a>' <a href="http://acme.com/software/thttpd/" rel="nofollow noreferrer">thttpd</a>. Especially fefe's web servers employ Unix filesystem semantics in "interesting" ways to avoid needing any configuration files.</p>
<h1>Virtual Hosts</h1>
<p>Configuring a Virtual Host in Gatling is easy: it's just a directory. Gatling does not serve files from the root of the web server directory, rather, it looks for a directory name that matches the <code>Host</code> HTTP header. So, if a browser sends a <code>GET</code> request for <code>/foo/bar.html</code> on <code>Host: 192.168.1.1:80</code>, Gatling will serve the file <code>$WEB_ROOT/192.168.1.1:80/foo/bar.html</code>.</p>
<p>If you have ever needed to configure Virtual Hosts in Apache, you will appreciate how simple this is:</p>
<pre class="lang-sh prettyprint-override"><code>mkdir -p 192.168.1.1:80/foo
touch 192.168.1.1:80/foo/bar.html
</code></pre>
<p>Boom, you're done.</p>
<h1>Access Control</h1>
<p>Access Control is a little trickier. But all three of the web servers I mentioned, have a really neat security feature that I wish more web servers had. Most web servers only care whether <em>they themselves</em> are allowed to read the file they are serving. However, thttpd, fnord, and gatling will <em>only</em> serve files that are explicitly <em>world-readable</em>, and they will only serve from directories that are explicitly <em>word-accessible</em>. They will also only generate directory listings for directories that are <em>world-readable</em> and will only show files within that listing that are <em>world-readable</em>.</p>
<p>It is sometimes surprising to people when web servers make files readable to the world that are not <em>world-readable</em>.</p>
<p>Note that this would also at least somewhat alleviate the path-traversal attack, since now I would only be able to access <em>world-readable</em> files in <em>world-accessible</em> directories.</p>
<h1>Server-side scripting</h1>
<p>In Gatling, any file that is <em>executable</em> will not be served as-is, but it will instead be <em>executed</em>, and the <em>output</em> of that file will be served. Specifically, it supports a subset of <a href="https://wikipedia.org/wiki/Common_Gateway_Interface" rel="nofollow noreferrer">CGI</a> (<a href="https://tools.ietf.org/html/rfc3875" rel="nofollow noreferrer">RFC 3875</a>).</p>
<p>So, all you need to do to set up scripting in gatling, is <code>chmod +x</code>.</p>
<h1>Redirection</h1>
<p>In Gatling, <em>symbolic links</em> signify redirects. Remember that the target of a symbolic link is <em>just a path</em>. It doesn't actually have to exist.</p>
<p>So, if you want to set up a <em>redirect</em> from <code>/search.html</code> to <code>https://google.com/</code>, the way you would do that in Gatling is simply this:</p>
<pre class="lang-sh prettyprint-override"><code>ln -s https://google.com/ search.html
</code></pre>
<p>Again, compare this to redirects in Apache, or in a typical routing engine of a typical web framework.</p>
<h1>Compression</h1>
<p>At least Gatling and thttpd also support compression. I.e. if the client indicates that it supports <em>deflate</em> compression, and it requests the path <code>/foo/bar/baz.html</code>, they will first look for a file named <code>/foo/bar/baz.html.gz</code> and serve that if it exists.</p>
<p>These are just a couple of ideas how to improve and extend your tiny web server. Most of these are additional features, and thus not really in scope for a simply Code Review, but I believe that at least the "only serve world-readable files out of world-accessible directories" part would be a worthwhile addition and increase the security and usability. (Of course, you also need to fix the path-traversal attack identified by Joseph.)</p>
    </div>