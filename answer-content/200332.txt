<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<blockquote>
<pre><code>def masterLocksmith(k, initial_state):
    ...
    for i in occurence:
        for j in num_set:
            shortest[j] += min(abs(i-j), k - abs(i-j)) * occurence[i]
    return min([[k, shortest[k]] for k in shortest], key=itemgetter(1,0))[0]
</code></pre>
</blockquote>

<p>The aliasing of <code>k</code> is not very helpful for readability; that last line is hard enough to decipher without confusion about the names. Another answer observed that using a running minimum would reduce memory usage and therefore possibly performance; in my opinion it would also be more readable.</p>

<hr>

<blockquote>
<pre><code>from collections import defaultdict
...
    occurence = defaultdict(int)
    for i in initial_state:
        occurence[i] += 1
</code></pre>
</blockquote>

<p>There's a specialised class for this:</p>

<pre><code>from collections import Counter
...
    occurence = Counter(initial_state)
</code></pre>

<hr>

<blockquote>
  <p>the best I could solve this in was still \$O(nâˆ—k)\$</p>
</blockquote>

<p>I concur with Quuxplusone that it's actually \$O(n^2)\$. Looking at the small example case by hand, I think there's a reasonably straightforward way to do it in \$O(n \lg n)\$ time. This is just a sketch: I haven't implemented it.</p>

<p>Basically the task is to add a series of functions which look something like</p>

<pre><code>  ^
 / \
/   \
     \   /
      \ /
       v
</code></pre>

<p>Note that there are two points of inflexion: at the initial value, and opposite the initial value. (Correctly handling odd vs even values of <code>k</code> will be a minor complication). Also note that a sum of piecewise linear functions is piecewise linear.</p>

<p>So you can first calculate in \$O(n)\$ time the score if the target number is <code>0</code> and the gradient of the sum at \$0\$. Then sort a list of inflexion points in \$O(n \lg n)\$ time and iterate through them, calculating the score by extrapolation from the previous one and the new gradient. Finally extrapolate to <code>k-1</code>.</p>
    </div>