<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>The most time is consumed by <code>BeautifulSoup</code> conversions, namely</p>

<pre><code>soup = BeautifulSoup(listing_obj.response_text, "html.parser")
</code></pre>

<p>For proof, firstly create a <code>.pkl</code> file of a <em>reasonable</em> size for debugging:</p>

<pre><code>if __name__ == "__main__":
    with open("D:\\Downloads\\listings20191231.pkl", "rb") as infile:
        listing_objs = pickle.load(infile)
    data = listing_objs[222:666]
    with open("D:\\Python\\CR\\listings20191231.pkl", "wb") as oufile:
        pickle.dump(data, oufile, pickle.HIGHEST_PROTOCOL)
</code></pre>

<p>Then, check and compare consumed time using following adapted code (moreover, I removed all the <code>progressbar</code> stuff from the rest of original code):</p>

<pre><code>if __name__ == "__main__":
    import time
    import sys
    argcnt = len(sys.argv) - 1
    argtxt = 'parse_listings_from_pkl()' if argcnt == 0 else 'BeautifulSoup'
    startload = time.time()
    with open("D:\\Python\\CR\\listings20191231.pkl", "rb") as infile:
        listing_objs = pickle.load(infile)

    length = len(listing_objs)
    print( 'checking time: ', argtxt, length, 'records')
    start0 = time.time()
    if argcnt == 0:
        parse_listings_from_pkl()
    else:
        for listing_obj in listing_objs: #progressbar(listing_objs):
            soap = BeautifulSoup(listing_obj.response_text, "html.parser")

    start1 = time.time()
    print("time consumed: ", argtxt, start1 - start0)
</code></pre>

<p><strong>Output</strong> shows that cca <strong>86 % of time</strong> (<code>100 * 32.761232137680054 / 38.00445818901062</code>) is consumed by converting original <code>html</code> to <code>BeautifulSoup</code> format:</p>

<pre><code>D:\Python\CR\234876.py
</code></pre>

<blockquote>
<pre><code>checking time:  parse_listings_from_pkl() 444 records
Validate listing responses
Parse financials and details for listings
Perform listing calculations
time consumed:  parse_listings_from_pkl() 38.00445818901062
</code></pre>
</blockquote>

<pre><code>D:\Python\CR\234876.py 1
</code></pre>

<blockquote>
<pre><code>checking time:  BeautifulSoup 444 records
time consumed:  BeautifulSoup 32.761232137680054
</code></pre>
</blockquote>

<p>Although there are some <em>optimizable parts</em> in the rest of <em>pure <code>python</code> code</em> (and I tried them with only minor performance improvements), I found that the <code>BeautifulSoup</code> conversion time corresponds to original <code>html</code> size and there is most of <em>gubbins</em> of no use inside the analyzed <code>html</code>. </p>

<p>Hence, I'd try cutting the <code>listing_obj.response_text</code> into pieces of useful parts and convert merely those parts to <code>&lt;class 'bs4.BeautifulSoup'&gt;</code> type. Maybe <a href="https://stackoverflow.com/questions/25539330/speeding-up-beautifulsoup">Speeding up beautifulsoup</a> or <a href="https://docs.python.org/3/library/html.parser.html" rel="nofollow noreferrer">Simple HTML and XHTML parser</a> could help extracting useful info from the original <code>html</code>?</p>
    </div>