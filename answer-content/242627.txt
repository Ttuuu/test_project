<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Since inserting into the DB takes a non-negligible amount of time, you should try to use <code>insert_many</code>, instead of <code>insert_one</code>. If you used a single thread this would be easy, just chunk your file and insert a whole chunk. Since you are using multiprocessing, this is a bit more complicated, but it should still be doable </p>

<p>(untested code)</p>

<pre><code>from itertools import islice
import pymongo
import multiprocessing as mp
from tqdm import tqdm
import et


def chunks(iterable, n):
    it = iter(iterable)
    while (chunk := tuple(islice(it, n))):  # Python 3.8+
        yield chunk

def work(chunk):
    try:
        posts.insert_many([attrib_to_dict(elem.attrib) for _, elem in chunk],
                          ordered=False)
    except pymongo.errors.BulkWriteError:
        # skip element
        pass

if __name__ == "__main__":
    pool = mp.Pool(4)
    # progress bar
    pbar = tqdm(total=POSTS_SIZE)
    n = 100
    try:
        for chunk in chunks(et.iterparse("Posts.xml", tag="row"), n):
            pool.apply_async(work, args=(chunk,),
                             callback=lambda: pbar.update(len(chunk)))
        pool.close()
    except KeyboardInterrupt:
        pool.terminate()
    finally:
        pbar.close()
        pool.join()
</code></pre>

<p>Here I used <a href="https://stackoverflow.com/a/56319442/4042267">this</a> to ignore duplicate keys.</p>
    </div>