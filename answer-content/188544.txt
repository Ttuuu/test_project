<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I like all of <a href="https://codereview.stackexchange.com/a/188540/47529">Ev. Kounis'</a> answer, so I'll add some higher level details.</p>

<h3>Let it be truth-y</h3>

<p>Right now you aren't strictly requiring <code>func</code> to return <code>True</code> or <code>False</code>, just something truth-y or false-y. This is fine, and Pythonic. I think you would benefit from pointing that out in a docstring (which you should also write). Additionally, it may be worthwhile to return the actual value of <code>func(*func_args)</code> instead of <code>True</code> or <code>False</code>; this way you can actually get a value from the function if you wanted to take advantage of the truth-yness of the value.</p>

<h3>Better <code>kwargs</code> support</h3>

<p>You also don't allow any keyword arguments to be passed to the function - the function might support them, so you should to. I would promote the two keyword arguments you pull out of <code>kwargs</code> to explicit keyword arguments, with appropriate defaults (5 in your case).</p>

<h3>Exceptions</h3>

<p>It's weird to me that this function does have any concept of retrying after exceptions. I wouldn't want you to do something like this, for what I hope are obvious reasons</p>

<pre><code>for _ in range(retry_count):
    try:
        if func(*func_args):
            return True
    except:
        pass
    log.debug("wating for %s seconds before retrying again")
    sleep delay)
</code></pre>

<p>However, in many cases I suspect you would know what exceptions you might expect (for example, a network timeout or connectivity blip) and that you might want to be handled by the retrying framework. To this end, I think something like this could be nice:</p>

<pre><code>def retry(func, *args, retry_count=5, delay=5, allowed_exceptions=(), **kwargs):
    for _ in range(retry_count):
        try:
            result = func(*args, **kwargs)
            if result: return result
        except allowed_exceptions as e:
            pass
</code></pre>

<p>This obviously isn't a complete implementation; I left out some of the other pieces you have, and it behaves oddly if it fails on the last iteration, but it should be enough to start.</p>

<h3>Fancy stuff</h3>

<p>I think we could also get more value from this if it was a decorator. Then consumers of a function don't even need to know if they want it to retry or not; they just call their function and see that it works, and whether or not it was retried becomes irrelevant. Don't forget to use <a href="https://docs.python.org/2/library/functools.html#functools.wraps" rel="noreferrer"><code>functools.wraps</code></a> to preserve metadata.</p>

<pre><code>import functools

def retry(retry_count=5, delay=5, allowed_exceptions=()):
    def decorator(f):
        @functools.wraps(f)
        def wrapper(*args, **kwargs):
            for _ in range(retry_count):
                # everything in here would be the same

        return wrapper
    return decorator
</code></pre>

<p>Then you can enable retrying for everyone, like so:</p>

<pre><code>@retry(retry_count=5, delay=5)
def is_user_exist(username):
    try:
        pwd.getpwnam(username)
        log.info("User %s exist" % username)
        return True
    except KeyError:
        log.exception("User %s does not exist." % username)
        return False
</code></pre>

<h3>Really fancy stuff</h3>

<p>Why block when you're waiting? You could be doing so much more (this is for Python 3.5 and above) using <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.sleep" rel="noreferrer"><code>asyncio</code></a>.  There isn't built-in support for this before that, but I know there are asynchronous frameworks that should be able to accomplish the same task.</p>

<p>By <code>await</code>ing an asynchronous function that just runs for <code>n</code> seconds, you achieve the same goal but allow other asynchronous functions to do work while you're just waiting. Note that depending on the event loop you might end up waiting for slightly more or less time.</p>

<p>I also cleaned up the issues I mentioned about handling exceptions; it now always returns the result of the function if it has one, and it'll re-raise the exception without losing any traceback if there was one. That also uses a Python 3 only feature; I've left a comment for how to do it in Python 2.</p>

<p>Note, I'm not as familiar with asyncio as I never got to do any serious dev there, so I might not have this piece of code exactly correct; the theory should be sound though.</p>

<pre><code>import functools
import asyncio    

def retry(retry_count=5, delay=5, allowed_exceptions=()):
    def decorator(f):
        @functools.wraps(f)
        async def wrapper(*args, **kwargs):
            result = None
            last_exception = None
            for _ in range(retry_count):
                try:
                    result = func(*func_args, **kwargs)
                    if result: return result
                except allowed_exceptions as e:
                    last_exception = e
                log.debug("Waiting for %s seconds before retrying again")
                await asyncio.sleep(delay)

            if last_exception is not None:
                raise type(last_exception) from last_exception
                # Python 2
                # import sys
                # raise type(last_exception), type(last_exception)(last_exception), sys.exc_info()[2]

            return result

        return wrapper
    return decorator
</code></pre>
    </div>