<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>One way of acceleration the code is numerating all the words in preprocessing step. Since the only thing you really care when you process two words is whether they are equal or not, you can replace each word with its unique ID.</p>

<p>In order to do so, you have to preprocess your whole dictionary and generate <code>std::unordered_map&lt;std::string, int&gt; wordsMap</code> which maps each word in the dictionary to some unique integer. Then create a compressed dictionary which consists of sequences of integers (i.e. <code>std::vector&lt;int&gt;</code>) instead of sequences of strings. When you search a sentence, you have to first replace each word with its ID in <em>wordsMap</em>. If it is not present there, give it some nonexistent ID (for instance -1). Then you can solve a problem of edit distance between two sequences of ints, which has smaller size.</p>

<p>Regarding code quality, I suggest avoiding memory allocation/deallocation in the innermost loop. Try to preallocate all the memory, or make your vectors static/global, etc.</p>

<p><strong>EDIT:</strong> Given that you have many sentences you have to check, I think you should introduce some pruning. Perhaps you should look <a href="https://stackoverflow.com/questions/3603760/what-is-the-best-algorithm-for-closest-word">this question</a> and implement some data structure for closest word search.</p>

<p>Here is one simple idea for pruning. You can create for each word a list of sentences it appears in. When searching for a sentence, you can merge these lists for all the words in the sentence. As a result you'll have a list of all sentences that has at least one common word with yours. Hopefully it is smaller than the whole dictionary. Speaking of all the other sentences (which have no common words), you can check only the shortest of them (it is enough).</p>
    </div>