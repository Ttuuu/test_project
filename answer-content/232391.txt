<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p><strong><em><h3>Ways to significantly improve performance and processing flow:</h3></em></strong></p>

<p><em>Accumulating lexicon dataset</em> phase</p>

<p>The first 2 <strong><code>for</code></strong> loops for accumulating <code>positive_lexicon</code> and <code>negative_lexicon</code> could at least be optimized with a list comprehension:</p>

<pre><code>...
reader = csv.reader(f)
positive_lexicon = [row[0] for row in reader]
</code></pre>

<p>that's better, but not the best when reading large files. (we'll beat that in the <em>final</em> version below)</p>

<p>The next 4 <strong><code>for</code></strong> loops are redundantly traversing the same sequences for just enriching each entry/token with <code>{token : True}</code>, then - with respective keyword flag <code>"Positive"/"Negative"</code>.</p>

<p>Since all intermediate datasets are not used anywhere further and just intended to compose a combined final dataset <code>dataset = positive_dataset + negative_dataset</code> - all those <strong>6</strong> <code>for</code> loops can be substituted with a <strong>single</strong> efficient <em>generator</em> function which will be consumed just once and return the needed entries.<br>The final version for the 1st processing phase (lexicons/accuracy):</p>

<pre><code>pos_lexicon_fname = "Fullform_Positive_lexicon.txt"
neg_lexicon_fname = "Fullform_Negative_lexicon.txt"

def get_lexicon_dataset(pos_lexicon_fname, neg_lexicon_fname):
    with open(pos_lexicon_fname) as f:
        reader = csv.reader(f)
        for row in reader:
            yield ({row[0]: True}, "Positive")

    with open(neg_lexicon_fname) as f:
        reader = csv.reader(f)
        for row in reader:
            yield ({row[0]: True}, "Negative")

dataset = list(get_lexicon_dataset(pos_lexicon_fname, neg_lexicon_fname))
#shuffle dataset
...
</code></pre>

<hr>

<p><em>Stopwords/tokenizing/probability</em> phase:</p>

<p><strong><code>norwegian_stopwords</code></strong> accumulation approach is better composed with a list comprehension:</p>

<pre><code>with open("stopwords.csv") as f:
    reader = csv.reader(f)
    norwegian_stopwords = [row[0] row in reader]
</code></pre>

<p>The code fragment which runs on each iteration (of the outer <code>for</code> loop):</p>

<pre><code>...
filtered_tokens = []
for word in custom_tokens:
    if word not in  norwegian_stopwords:
        filtered_tokens.append(word)

classification = classifier.classify(dict([token, True] for token in filtered_tokens))
probdist = classifier.prob_classify(dict([token, True] for token in filtered_tokens))
</code></pre>

<p>introduces 2 issues:</p>

<ul>
<li><code>filtered_tokens</code> is better accumulated with a list comprehension</li>
<li>the same <code>filtered_tokens</code> sequence is then redundantly traversed twice</li>
</ul>

<p>But, considering that the <em>target</em> data structure for <em>classifying</em> operation is a dictionary of filtered tokens (<code>dict([token, True], ...)</code>) - the more optimized and straightforward way is to compose such a dictionary at once:</p>

<pre><code>for comment in list_of_comments:
    custom_tokens = word_tokenize(comment)
    filtered_tokens_dict = {word: True for word in custom_tokens
                            if word not in norwegian_stopwords}

    classification = classifier.classify(filtered_tokens_dict)
    probdist = classifier.prob_classify(filtered_tokens_dict)
    pred_sentiment = probdist.max()
    print("Sentence: " + comment)
    ...
</code></pre>

<hr>

<p><em>Things to remember:</em></p>

<ul>
<li><em>Generator expressions</em> don’t materialize the whole output sequence when they’re run. Instead, generator expressions evaluate to an iterator that yields one item at a time from the expression</li>
<li><em>Generators</em> can produce a sequence of outputs for arbitrarily large inputs because their working memory doesn’t include all inputs and outputs</li>
</ul>
    </div>