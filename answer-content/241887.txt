<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>Noise...noise...noise</h1>

<p>There's quite a lot of noise in your tests.  As has been pointed out by @OpenSauce, part of that is because you're catching the <code>AssertionError</code>.  If you stop catching it, then your test runner will report the message embedded in the exception.  As it stands, this message will be wrong, because you're passing your parameters to <code>assertEquals</code> the wrong way round:</p>

<blockquote>
  <p>assertEquals(k, expectedOutput[i]);</p>
</blockquote>

<p>They should be:</p>

<pre><code>assertEquals(expectedValue, actualValue)
</code></pre>

<p>Another source of noise is the iteration.  Having loops like this in your tests obscures the relevant elements of the test.  There are two obvious approaches for extracting the iteration aspect from the test.</p>

<ol>
<li><p>Extract each iteration into its own test.  This allows tests to be given meaningful names and means that when you change related behaviour, you only have to change the impacted test.  So, you might end up with some tests like:</p>

<pre><code>romanToArabic_null_minusOne
romanToArabic_empty_minusOne
romanToArabic_I_one
</code></pre>

<p>etc.  There's some repetition here, but there's a trade off because each individual test is more specific and easier to understand.  It also helps you to understand your expectations, does it really make sense for <code>null/""</code> to return <code>-1</code>, or should it throw an exception?</p></li>
<li><p>Use a <a href="https://github.com/junit-team/junit4/wiki/Parameterized-tests" rel="nofollow noreferrer">parameterised</a> test.  These allow the test behaviour to be separated from the test data.  The test runner will then run the test, for each dataset, displaying the values passed in for each execution.  This removes a lot of the need for the custom error handling to log the inputs into the test (which can get forgotten).</p></li>
</ol>

<p>You've also got some naming noise in your tests... Rather than calling your <code>TestCases</code>, give it a meaningful name that describes what it's testing.  A common practice is to link it in some way to the class being tested, i.e. <code>RomanNumbersTests</code>.  Having <code>test</code> at the start of all of your test names also seems redundant.  They have <code>@Test</code> attributes and they're in a test class, so the runner can find them.  I think of it as the class name, method name (and in the case of parameterised tests the parameters) combining to present a high level overview what each test is doing.</p>

<p>Using meaningful names instead of <code>k</code>, such as <code>calculatedRomanValue</code> or <code>calculatedArabicValue</code> would also make your assertions easier to follow.  Anything that makes the tests easier to read is positive.</p>
    </div>