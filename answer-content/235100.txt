<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I don't really know the libraries that you're using, but maybe the overhead of dropping rows from the CSV one by one is significant?  You could try batching the drop (it looks like that <code>drop</code> function takes a list of indices but you're only passing it one at a time) and see if that speeds things up:</p>

<pre><code>from pandas import DataFrame
from typing import List

def remove_rows_that_dont_have_important_1_in_important_2(df: DataFrame) -&gt; DataFrame:
    """
    Removes all rows of the dataframe that do not have important_1 inside of important_2.
    Note: All rows have the same value for important_1.
    Note: Every row can have a different value for important_2.
    Note: There are unrelated columns in the df that cannot be dropped from the df. But rows still can.
    """
    important_1 = df.at[0, 'important_1']  # get the icao fro the df from the first ob
    important_2_col = df.columns.get_loc('important_2')  # column order won't always be the same, so find the right column first

    indices_to_drop: List[int] = []

    for i in range(len(df), 0, -1):
        print(i)  # DEBUG printing

        important_2  = df.iat[i, important_2_col]
        if important_2 == np.NaN or important_1 not in important_2:
            indices_to_drop.append(i)

    df.drop(indices_to_drop, inplace=True)
    return df
</code></pre>
    </div>