<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Few tips:</p>

<ul>
<li>try hashing fitness function, create dictionary of hashed individuals
and their fitness values; fitness evaluation is often costly; no reason to evaluate same specimen twice</li>
<li>don't use <code>roulette</code> selection, you can loose selective pressure, when there's little difference between fitnesses or converge too fast, when there's huge deviation; use <code>tournament</code> selection instead, it doesn't care about fitness distribution and maintains selective pressure well</li>
<li>GA is rather well suited for parallel computation; exploit that fact; you got nice <code>multiprocessing</code> package in python's standard lib</li>
<li>try to use hill climber to improve some of the individuals; there was a lot of research about hybrids: simulated annealing, tabu search, FIHC. It depends on your problem and encoding though.</li>
</ul>

<p>Now most important stuff - vanilla GA is slow, because it searches through space like a blind man. Try to learn about linkage learning (discrete problems) and fitness landscape analysis (continous problems). You'll be able to crash your problem way much faster.
If you'd like to know more about it, get some papers, please create separate thread on <a href="https://datascience.stackexchange.com/">https://datascience.stackexchange.com/</a> or <a href="https://stats.stackexchange.com/">https://stats.stackexchange.com/</a>. We can talk there.</p>
    </div>