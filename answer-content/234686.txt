<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Looking at your code, I can see two potential slowdowns:</p>

<ol>
<li>When you do a <code>.count</code>, Python is implicitly performing a for-loop over each element in the array. This scales horribly with bigger tables and is definitely causing a slowdown. The comment about returning a count would actually help a lot. Below, I've implemented a similar solution.</li>
<li>Converting a list to a set is usually fine, but in this case, when you have almost a million elements, it is not efficient. It is especially inefficient when there was no use for the list in the first place. From the code you gave, it seems like the best solution is to directly instantiate a set and add to that incrementally. </li>
</ol>

<p>Implementing those points and then cleaning up the logic should result in something like this:</p>

<pre class="lang-py prettyprint-override"><code>from collections import Counter


def get_employee_language_data(self, employee_id):
    self.apps_cursor.execute("SELECT id, language_id, hr_employee_id, lang_write, lang_speak, lang_read FROM employee_language WHERE hr_employee_id=%s" % employee_id)
    employee_languages = self.apps_cursor.fetchall()

    language_id_list = Counter(language.get('language_id') for language in employee_languages)

    repeated_language_records = []
    non_repeated_language_records = []
    duplicate_language_ids_list = set()
    repeated_language_records_not_to_be_deleted = []

    for language in employee_languages:
        if language_id_list[language['language_id']] &gt; 1:
            duplicate_language_ids_list.add(language['language_id'])
            repeated_language_records.append(language)
        else:
            non_repeated_language_records.append(language)


    for unique_record in duplicate_language_ids_list:
        temp_list = []
        flag_3 = False
        flag_2 = False
        flag_1 = False
        for repeated in repeated_language_records:

            if repeated['language_id'] == unique_record:

                if None not in (repeated['lang_speak'], repeated['lang_read'], repeated['lang_write']):
                    temp_list = repeated
                    flag_3 = True

                elif (repeated['lang_speak'], repeated['lang_read'], repeated['lang_write']).count(None) == 1 and not flag_3:
                    temp_list = repeated
                    flag_2 = True

                elif (repeated['lang_speak'], repeated['lang_read'], repeated['lang_write']).count(None) == 1 and not flag_3 and not flag_2:
                    temp_list = repeated
                    flag_1 = True

                elif not flag_3 and not flag_2 and not flag_1:
                    temp_list = repeated

        repeated_language_records_not_to_be_deleted.append(temp_list)

    language_record_ids_not_to_be_deleted = []

    for record in non_repeated_language_records + repeated_language_records_not_to_be_deleted:
        language_record_ids_not_to_be_deleted.append(int(record['id']))

    return language_record_ids_not_to_be_deleted
</code></pre>

<p>I'm sure there are further improvements that could be made, but I cannot follow the specific logic of the code you gave. More context and examples would be necessary to simplify it further. I am certain this is faster, but as fast as it could be.  </p>
    </div>