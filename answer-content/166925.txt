<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h3>Notes about your code</h3>

<ul>
<li><p>You can also simplify the way you look for the links to follow:</p>

<pre><code>for link in soup.select("a[href]"):
    downloadImages(link["href"], level - 1)
</code></pre>

<p>Here, we are enforcing the <code>a</code> elements to have <code>href</code> values, not checking for elements to be found (since the loop body would just not be executed in this case).</p></li>
<li><p>As far as managing the urls you've already visited:</p>

<ul>
<li><em>don't use globals</em></li>
<li>use a <code>set</code> instead of a <code>list</code> for <em>faster lookups</em></li>
</ul></li>
<li><p>It's also a good practice to always specify <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser" rel="noreferrer">the parser <code>BeautifulSoup</code> uses under-the-hood</a>:</p>

<pre><code>soup = BeautifulSoup(urlContent, "lxml")  
# or soup = BeautifulSoup(urlContent, "html.parser")
# or soup = BeautifulSoup(urlContent, "html5lib")
</code></pre></li>
<li><p>follow <a href="https://www.python.org/dev/peps/pep-0008/" rel="noreferrer"><code>PEP8</code> recommendations</a> - specifically, naming is agreed to be in <code>lower_case_with_underscores</code> format, not <code>camelCase</code></p></li>
<li>no need to join the <code>urlContent</code> - simply pass <code>urlContent</code> to <code>BeautifulSoup</code></li>
</ul>

<h3>Alternative solution</h3>

<p>I would implement it this way:</p>

<pre><code>try:
    from urlparse import urljoin
except ImportError:
    from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup


class Scraper:
    def __init__(self):
        self.visited = set()
        self.session = requests.Session()
        self.session.headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.109 Safari/537.36"}

        requests.packages.urllib3.disable_warnings()  # turn off SSL warnings

    def visit_url(self, url, level):
        print(url)
        if url in self.visited:
            return

        self.visited.add(url)

        content = self.session.get(url, verify=False).content
        soup = BeautifulSoup(content, "lxml")

        for img in soup.select("img[src]"):
            image_url = img["src"]
            if not image_url.startswith(("data:image", "javascript")):
                self.download_image(urljoin(url, image_url))

        if level &gt; 0:
            for link in soup.select("a[href]"):
                self.visit_url(urljoin(url, link["href"]), level - 1)

    def download_image(self, image_url):
        local_filename = image_url.split('/')[-1].split("?")[0]

        r = self.session.get(image_url, stream=True, verify=False)
        with open(local_filename, 'wb') as f:
            for chunk in r.iter_content(chunk_size=1024):
                f.write(chunk)


if __name__ == '__main__':
    scraper = Scraper()
    scraper.visit_url('http://www.yahoo.com', 1)
</code></pre>

<p>Aside from things mentioned above, here are some other applied changes:</p>

<ul>
<li>using <code>requests</code> third-party library with a <a href="http://docs.python-requests.org/en/master/user/advanced/#session-objects" rel="noreferrer">shared session</a></li>
<li>Python 2 and 3 compatible</li>
<li>using class for sharing "session" and a set of visited urls</li>
<li>separate methods to visit urls and download images</li>
<li><a href="https://stackoverflow.com/questions/419163/what-does-if-name-main-do"><code>if __name__ == "__main__":</code></a> is used to avoid the code being executed on import</li>
<li>changed the way image filename is determined (probably still not the best way)</li>
<li>handling relative urls as well as absolute</li>
</ul>
    </div>