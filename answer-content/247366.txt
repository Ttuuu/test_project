<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>If you really want to know where to look at speeding things up, use a profiler.  There is one in the <a href="https://docs.python.org/3.7/library/profile.html#module-cProfile" rel="nofollow noreferrer">standard library</a>.  There are also third party libraries.</p>
<p>My guess is that <code>randomLine()</code> and <code>rawCount()</code> are the biggest time sinks.</p>
<p><code>rawCount()</code> reads an entire file to determine its size.  <code>randomLine()</code> first calls <code>rawCount()</code> and then reads parts of the file again.  To randomly select a line, <code>randomLine()</code> reads each entire file an average of 1.5 times and makes two calls to 'open()<code>, two to </code>close()<code>and at least 2 to</code>read()`.</p>
<p>(3 files)<em>(6 function calls)</em>(10 million random records) = a lot (180 million) of calls.  That's a lot of I/O.</p>
<p>Instead, read a file into a list once.  Then use <code>random.choice()</code> to pick an item.  The functionality can be put into a convenient class:</p>
<pre><code>import random

class RandomLineChooser:
    def __init__(self, filename):
        with open(filename) as f:
            self.lines = f.readlines()

    def choose(self):
        return random.choice(self.lines)

firstnames = RandomLineChooser(FirstNames)
lastnames = RandomLineChooser(LastNames)
objects = RandomLineChooser(Objects)
</code></pre>
<p>I'll also point out two useful Python libraries:</p>
<ul>
<li><p><a href="https://faker.readthedocs.io/en/stable/" rel="nofollow noreferrer">Faker</a>, which is designed to generate fake data, and</p>
</li>
<li><p><a href="https://hypothesis.readthedocs.io/en/latest/index.html" rel="nofollow noreferrer">Hypothesis</a>, which is designed for testing, but can be used to generate fake data as well.</p>
</li>
</ul>
    </div>