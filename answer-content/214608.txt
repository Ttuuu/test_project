<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>This is one of those times when "the rubber meets the road" as far as big-O complexity goes. You've got <code>n = 2.5e6</code> words, so all that stuff about how <span class="math-container">\$O(\log n) &lt; O(n) &lt; O(n\log n) &lt; O(n^2)\$</span> starts to be important.</p>

<h3>Existing performance</h3>

<p>You'll want to get a meaningful set of sample data, maybe 10 or 100 thousand words, and you'll want to look at using the <code>timeit</code> module, or something else you devise, to measure real performance.</p>

<p>That said, let's look at your code:</p>

<pre><code>def index_containing_substring(the_list, substring):
    for i, s in enumerate(the_list):
        if substring in s:
            return i
    return -1
</code></pre>

<p>This function is called with a single word from the input list of words. It checks that one word against all the words already present in <code>the_list</code>. To do that, it iterates over <code>the_list</code> once, and then uses the <code>in</code> operator on each value.</p>

<p>Eventually, <code>the_list</code> is going to be sized based on the input word list. If nearly every word in the input list is a substring of some larger word, for example: <code>[ 'aaaa', 'aaa', 'aa', 'a' ]</code> then you will have one member. But if every word in the input is distinct, for example: <code>[ 'a', 'b', 'c', 'd' ]</code> you will have <code>len(the_list) == N</code> where N is the number of input words. For the worst case, we have to assume this.</p>

<p>For the use of <code>substring in s</code>, Python's <code>substr in string</code> is worst-case <span class="math-container">\$O(s \cdot t)\$</span>, according to <a href="https://stackoverflow.com/questions/18139660/python-string-in-operator-implementation-algorithm-and-time-complexity">this post</a>. In this analysis, <code>s</code> and <code>t</code> are <em>lengths</em> of the string and substring. Since your substrings eventually get added to the list, <code>s == t</code>. Thus, your <code>index_containing_substring</code> is worst-case <span class="math-container">\$O(n \cdot s^2)\$</span> (and average case about <span class="math-container">\$O(n \cdot s)\$</span>).</p>

<pre><code>def string_match():
    test_list=[...]
    safe_to_add=[]

    for s in test_list:
        if len(s)==max_len:
            safe_to_add.append(s)
        else:
            idx=index_containing_substring(safe_to_add,s)
            if idx==-1:
                safe_to_add.append(s)
            else:
                ...
</code></pre>

<p>In this function, you iterate once over the entire list of strings, calling the <code>index_containing_substring</code> function for almost every one. Your behavior is worst-case <span class="math-container">\$O(n)\$</span> where <code>n</code> is the length of the word list, times the behavior of the <code>index_containing_substring</code> function, which is <span class="math-container">\$O(n \cdot s^2)\$</span>. Thus, your overall performance is <span class="math-container">\$O(n^2 \cdot s^2)\$</span>, which since <span class="math-container">\$n \gg s\$</span> simplifies to <span class="math-container">\$O(n^2)\$</span>.</p>

<p>It's worth noting that there are some "constant factors" in there which get ignored. For example, every time through the loop you check the length of your inputs to determine if you can add them without checking if they are contained substrings. This is a mistake for two reasons: first, what if they are duplicates? I don't see you doing any quality checks on the data, so I can't guarantee that two copies of "the longest word in the list" don't appear, and get added twice. Second, of course, is that you say the words are sorted in reverse order by length. This means that doing the substring-check on the first, long words is the <em>cheapest operation possible.</em> Checking for substrings in a list of length 0, or 1, is much much cheaper than it will ever be again. So you aren't saving very much. But you are doing that length comparison <em>every single time</em>.</p>

<p>I'd suggest that you either (1) abandon all that stuff entirely, and just pay the small price for the first couple of words; or (2) create a separate loop at the beginning to filter those words into the list, and then run your main loop starting after those are done.</p>

<h3>An alternative</h3>

<p>Suppose you computed every substring of a word. That would require iterating across the entire word, and for each point you reached you would iterate across all possible lengths of the substring:</p>

<pre><code>word, wor, wo, w
 ord, or, o
  rd, r
   d
</code></pre>

<p>That is going to be <span class="math-container">\$O(s^2)\$</span> where <code>s</code> is the length of your word. </p>

<p>Now suppose you added all of the generated substrings to a Python <a href="https://docs.python.org/3/library/stdtypes.html?highlight=set#set" rel="nofollow noreferrer"><code>set</code></a>     that has <span class="math-container">\$O(1)\$</span> access time. You could do something like this:</p>

<pre><code>for word in big_list:
    if word in set_of_all_substrings:
        ...
    else: 
        add_all_substrings_of(word, set_of_all_substrings)
</code></pre>

<p>Assuming your "found" condition is <span class="math-container">\$O(1)\$</span>, the performance is <span class="math-container">\$O(n \cdot s^2)\$</span>, which again simplifies to <span class="math-container">\$O(n)\$</span>.</p>

<h3>Another alternative</h3>

<p>Suppose you build a table of <em>suffixes</em> of all the words. That is, <code>word[i:] for i in range(len(word))</code>. Adding a single word's suffixes would be <span class="math-container">\$O(s)\$</span> as you can see, instead of <span class="math-container">\$O(s^2)\$</span> for substrings.</p>

<p>You could then binary-search the list, comparing <code>word &lt; suffix[:len(word)]</code> to test for membership. The binary search would be <span class="math-container">\$O(\log n)\$</span> and you would do it <code>n</code> times, so your overall performance would be <span class="math-container">\$O(n \log n)\$</span>. This seems worse than the <span class="math-container">\$O(n)\$</span> above, but it might be worth checking. The log(2.5 million) is about 22, and if your words have an average length of 10 letters, the difference between <span class="math-container">\$s\$</span> and <span class="math-container">\$s^2\$</span> would be 10, putting the two techniques a factor of 2.2 apart in performance. That's the kind of difference that code being written in C versus Python, or being particularly well-tuned for a particular purpose, can overcome.</p>

<p>Note that I don't expect this to work: inserting values into a sorted list gets quite expensive, so I suspect you'll find that this code loses the battle of small performance tweaks. But that's why they run horse races, eh?</p>
    </div>