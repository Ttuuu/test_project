<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<blockquote>
  <p>is the current implementation 'safe'?</p>
</blockquote>

<p>Absolutely not. <strong>The fact that you had to ask this question indicates that you do not understand enough about threading to build your own mechanisms like this</strong>. You need to have a <em>deep</em> and <em>thorough</em> understanding of the memory model to build these mechanisms. <strong>That is why you should always rely on the mechanisms provided for you in the framework, that were written by experts.</strong>.</p>

<p>Why is it unsafe? Consider the following scenario. We have two threads, A and B. <code>_Value</code> is <code>null</code> and <code>_Loaded</code> is <code>false</code>.</p>

<ul>
<li>We're on thread A.</li>
<li>The memory location of <code>_Value</code> is loaded into the processor cache for the CPU that thread A is affinitized to. It is <code>null</code>.</li>
<li>We switch to thread B.</li>
<li>Thread B reads <code>_Loaded</code> as <code>false</code>, takes the lock, checks <code>_Loaded</code> again, calls <code>create</code>, assigns <code>_Value</code> and <code>_Loaded</code> and leaves the lock.</li>
<li>We switch back to thread A.</li>
<li><code>_Loaded</code> is now <code>true</code>, so thread A returns <code>_Value</code> from the processor cache, which is null.</li>
</ul>

<p>Thread A is not required to invalidate the cache because thread A <em>never takes a lock</em>.!</p>

<p>Now, I made an argument here from processor caches. <strong>This is the wrong argument to make in general</strong>. Rather, what you <strong>must</strong> do when trying to build a new threading mechanism like this is to <em>not</em> reason about any specific processor architecture, but rather to reason about the <em>abstract memory model of the C# language</em>.  C# permits reads and writes to move forwards and backwards in time in multithreaded programs.  <strong>Any time travel that is not explicitly forbidden by the C# specification must be considered to be possible</strong>.  Your task is to then write code that is correct for <strong>any possible combination of movements of reads and writes in time</strong> regardless of whether they are really possible on a specific processor or not.  </p>

<p>Note that in particular <strong>the C# specification does not require that all threads observe a consistent set of write and read re-orderings</strong>. It is perfectly legal and possible for two threads to <em>disagree</em> on how a read was re-ordered with respect to a write.</p>

<p>If writing correct programs in a world where all reads and writes can be moved around in time sounds hard, that's because it is. <strong>I am not competent to do this work, and I do not attempt to</strong>. I leave it to experts.</p>

<blockquote>
  <p>are there any important performance considerations vs the original one?</p>
</blockquote>

<p>Only you can answer that question.  Answer performance questions by gathering real-world empirical data.</p>

<p>However, I can say a few things about this problem in general.</p>

<p>The first is: double-checked locking is intended to avoid the cost of the lock. Let's examine the assumptions underlying that intention.  <strong>The assumption is that the cost of taking the lock is too high on the uncontended path</strong>.  Is that assumption warranted? What is the cost of taking an uncontended lock? Did you measure it? Did you compare it against the cost of the lock-avoiding check?  (Since the lock-avoiding check code is <em>wrong</em>, testing it for performance is not actually meaningful since we can always write faster code if we don't care about correctness, but still, we need to know whether this intervention is an improvement.)  And most importantly, <strong>is the cost of taking an uncontended lock relevant to the consumer of this code</strong>?  Because they are the stakeholder whose opinions are relevant; what do they say about the cost of an uncontended lock?</p>

<p>Let's suppose that the cost of an uncontended lock is relevant. <strong>Then surely the cost of a contended lock is enormously relevant</strong>.  You've built a mechanism that potentially contends a lot of threads!  What are the alternatives that you considered here?  For example, you could avoid the lock altogether by deciding that it is OK for the <code>create</code> function to be called on multiple threads -- perhaps we know that it is cheap and idempotent.  Those threads can then race to their heart's content to initialize the field, and we can use an interlocked exchange to ensure that we get a consistent value. That avoids the cost of the lock altogether, but it creates a different kind of cost, and puts a requirement on the caller to pass an idempotent creator.</p>

<p>Let's consider other aspects of your solution with respect to performance. <strong>You allocate the lock object regardless of whether you ever take the lock</strong>, and you keep it forever.  What's the burden on the garbage collector? What is the impact on collection pressure? <strong>These things are all deeply relevant to performance</strong>.  Again, remember, the assumption here is that <strong>we are so worried about the couple of nanoseconds it takes to enter and leave an uncontended lock that we're willing to write a double checked lock</strong>.  If those nanoseconds are relevant then surely the <strong>milliseconds</strong> it takes to do an extra collection are incredibly relevant!</p>

<blockquote>
  <p>is there anything else I'm missing that I should be concerned about in a high traffic application?</p>
</blockquote>

<p>I don't know how to answer that question.</p>
    </div>