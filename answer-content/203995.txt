<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Your naive solution is quadratic time, O(n^2) and O(1) additional memory. Note, polynomial time doesn't say much about the actual time complexity other than it's not exponential or factorial.</p>

<p>Your improved version is O(nlogn) time for the implementation with <code>set</code> and O(n) for the one with <code>unordered_set</code> and both come with the additional cost of O(n) memory.</p>

<p>However the hash version is not necessarily faster than the set version depending on the cost of the hash function and value of n, you should allow the user the option of choosing a specific implementation if they want.</p>

<p>I would probably call the functions something like <code>remove_duplicates_stable</code> to imply the property you are designing for that is preserving the original order and keeping the first observed value. Which by the way differs between the naive implementation and the others, the naive one keeps the last of the dupes.</p>

<p>If keeping the order of the elements is not important I would probably sort the source array and use std unique or something. Because sorting can make use of move construction to avoid possibly expensive copy construction of all non duplicate elements which is necessary in your implementation, requires no additional space, and is O(nlogn). But again it depends on if copy construction is expensive and of the hash function is expensive.</p>

<p>I would also put the implementation in a separate namespace, like "detail" but this is just personal style.</p>
    </div>