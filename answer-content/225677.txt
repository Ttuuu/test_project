<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h2>From Comments</h2>

<p><em>Have you tested performance of copying data of a single day to a temporary table, truncating the target table, and re-inserting the copied data back to the target table?</em></p>

<blockquote>
  <p><em>Yes, it's not taking much time to copy or insert, it is taking time to delete and select. One of the column has huge XML string.</em></p>
</blockquote>

<h2>Proposed Solution</h2>

<p>Since inserting and copying data does not seem to yield a performance penalty, I would suggest to:</p>

<ul>
<li>copy to data of today to a staging table</li>
<li>truncate the existing table (much faster than delete, no transaction logs)</li>
<li>copy staged data back to existing table</li>
</ul>

<p>Or alternatively, as Dannnno suggests:</p>

<p><em>Potentially faster than copying the data twice would be to copy data to a staging table, truncate the existing table, then rename them both to swap places. This minimizes latches required for DDL, and also only requires a single copy. Snapshot isolation would also help this be as non-invasive as possible for anyone hitting the database.</em></p>

<h3>Links</h3>

<ul>
<li><a href="https://dba.stackexchange.com/questions/189607/delete-millions-of-rows-from-a-sql-table">Similar problem: non-clustered index bottleneck on delete</a></li>
<li><a href="https://stackoverflow.com/questions/24213299/how-to-delete-large-data-of-table-in-sql-without-log">Enlists a couple of possible solutions</a></li>
</ul>
    </div>