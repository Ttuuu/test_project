<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>The answers to the question don't pay attention that the original array consists of a million of <strong>signed eleven digit integers</strong> (i.e. both positive and negative). That is the real reason for the poor performance of the Python code, even on a 64-bit architecture.</p>

<p>[EDIT] Integers in Python 3 have arbitrary precision by default (e.g. see this <a href="https://rushter.com/blog/python-integer-implementation/" rel="nofollow noreferrer">article</a> for details of implementation). In short, they can be represented as</p>

<p>i = x*2^(30*0) + y*2^(30*1) + z*2^(30*2)...</p>

<p>For numbers &gt; 2^31 (e.g. eleven digit numbers), they are manipulated as complex objects with &gt;=2 parts, and therefore the performance of the code manipulating such numbers is much slower than on smaller numbers in a range -2^30 to 2^30 for which there is a "fast path" CPython implementation (they are treated as fixed 32-bit integers). The 2-SUM programming assignment in the Algo_Stanford course deliberately uses huge numbers in the input array to make brute force solutions unacceptably slow.</p>
    </div>