<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>This is going to be relatively long, but I don't have a TL;DR section</p>

<h1><code>if debug: print</code></h1>

<p>Whenever you see code repeated like this, it's quite often you can refactor it into either a function, or there's a builtin to support it. Fortunately, the <a href="https://docs.python.org/3/howto/logging.html" rel="nofollow noreferrer"><code>logging</code></a> module makes this quite simple. You do lose a bit of speed over the <code>if</code> statement, but it's a much easier call to read and visually separate from the rest of your code:</p>

<pre class="lang-py prettyprint-override"><code>import logging
import sys

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
# I'm specifying sys.stdout because default is sys.stderr which
# may or may not be viewable in your console, whereas sys.stdout
# is always viewable
logger.addHandler(logging.StreamHandler(stream=sys.stdout))

for i in range(10):
    if i &gt; 8:
       logger.debug(f'{i}')
       # do other things

9

# rather than
for i in range(10):
    if i &gt; 8:
        if debug:
            print(i)
        # do other things

9

</code></pre>

<p>You can set this up with a <code>level</code> mapping to point to other logging levels:</p>

<pre class="lang-py prettyprint-override"><code>levels = {True: logging.DEBUG,
          False: logging.INFO}

debug = True

logger.setLevel(levels[debug])
</code></pre>

<p>This way you don't lose your original way of keeping track of your debug status. The major benefit is that it doesn't visually collide with the rest of your flow control. When you have a ton of <code>if</code> statements, visually sifting through to ignore <code>if debug</code> becomes a major pain.</p>

<p>The way to fix this is to find <code>if debug print</code> and replace it with <code>logger.debug</code>, and everywhere else <code>print</code> is needs to be <code>logger.info</code>, <code>logger.warn</code>, or <code>logger.exception</code> (which will include a stack trace for you :) ). You'll need to fix the print arguments as well, how to do that is below.</p>

<h2>Using <code>logger</code> with objects</h2>

<p>I'd probably start switching to using <a href="https://realpython.com/python-f-strings/#f-strings-a-new-and-improved-way-to-format-strings-in-python" rel="nofollow noreferrer">f-strings</a>, this way you avoid string concatenation and your code is a bit more readable:</p>

<pre class="lang-py prettyprint-override"><code>import pandas as pd
import logging
import sys

df = pd.DataFrame([[1,2,3],[4,5,6]], columns = list('abc'))

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
logger.addHandler(logging.StreamHandler(stream=sys.stdout))


logger.debug(f'My dataframe is \n{df.head()}')
My dataframe is
   a  b  c
0  1  2  3
1  4  5  6

# you can still use it for objects by themselves
logger.debug(df.head())
   a  b  c
0  1  2  3
1  4  5  6

# To show logging.exception behavior
def f():
  raise TypeError("Some random error")

try:
  f()
except TypeError as e:
  logger.exception("An error occurred")

An error occurred
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 2, in &lt;module&gt;
  File "&lt;stdin&gt;", line 3, in f
TypeError: Some random error
</code></pre>

<h1>Opening and closing files</h1>

<p>I see lots of different ways you open files:</p>

<pre class="lang-py prettyprint-override"><code>for line in open(file):
   ...

fh = open(file)
for line in fh:
   ...

</code></pre>

<p>It's best to be consistent, and the most pythonic way to <a href="https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files" rel="nofollow noreferrer">open a file</a> is to use <a href="https://docs.python.org/3/reference/compound_stmts.html#with" rel="nofollow noreferrer"><code>with</code></a>:</p>

<pre class="lang-py prettyprint-override"><code>with open(file) as fh:
    for line in fh:
        ...

</code></pre>

<p>This removes the need to manually close the file, since even on an exception, the handle is closed and you don't have to wait for <code>fh</code> to exit function scope.</p>

<h1>os.listdir vs os.scandir</h1>

<p>If your directories are particularly large, it can be quite advantageous to use <code>os.scandir</code> since it produces a generator rather than a list:</p>

<pre class="lang-py prettyprint-override"><code>os.listdir('.')
['newfile.py', '.Rhistory', 'VMBash.txt', '.config', 'Music', '.sparkmagic', 'transcripts.tar.gz', '.amlinstaller', 'spotify.docx', 'tree.py', '.condarc', '.docker', 'company.20190102.idx.1', 'itertools_loop.py', 'sql2019.ipynb', 'somexml.xml', 'temp'...]

os.scandir('.')
&lt;posix.ScandirIterator object at 0x10bbb51b0&gt;
</code></pre>

<p>For large directories, you'd have to wait for <code>listdir</code> to aggregate all of the files into memory, which could be either a) long-running or b) crash your machine (probably not but who knows). You would iterate over <code>scandir</code> with the <code>file.name</code> attribute to get back to what you had before:</p>

<pre class="lang-py prettyprint-override"><code>for file in os.scandir('.'):
    print(file.name)

newfile.py
.Rhistory
VMBash.txt
...
</code></pre>

<h1>Tracking an Index</h1>

<p>If you ever find yourself doing the following:</p>

<pre class="lang-py prettyprint-override"><code>counter = 0

for x in iterable:
  something[x] = 1
  counter += 1
</code></pre>

<p>It's probably better to use <code>enumerate</code> to track the index:</p>

<pre class="lang-py prettyprint-override"><code>l = list('abcd')

for idx, item in enumerate(l):
  print(idx)

0
1
2
3
</code></pre>

<p>You can also provide a <code>start</code> kwarg to tell <code>enumerate</code> where to begin:</p>

<pre class="lang-py prettyprint-override"><code>l = list('abcd')

for idx, item in enumerate(l, start=1):
  print(idx)

1
2
3
4
</code></pre>

<p>So in your <code>identifyFields</code> function, I would definitely leverage that:</p>

<pre class="lang-py prettyprint-override"><code>for counter, field_name in enumerate(df.columns, start=1):
  # rest of loop
</code></pre>

<h1>Counter</h1>

<p>When you are iterating over your file to get character counts, you are losing speed with extra steps by converting to <code>list</code>, then checking for <code>\n</code>, then building your Counter. <code>Counter</code> will consume a string, and <code>\n</code> is a single string object. Move that into a separate function for separation of concerns:</p>

<pre class="lang-py prettyprint-override"><code>def read_file(filepath):
    # It is much better practice to open files using the with context manager
    # it's safer and less error-prone
    with open(filepath) as fh:
        char_counts = []

        for line in fh:
            # don't construct a list, there's no need,
            # just check if startswith, which is the same
            # as line[0] == '\n'
            if not line.startswith('\n'):
                # Counter will consume a string
                char_counts.append(Counter(line))
    return char_counts

char_counts = read_file(name)
</code></pre>

<p>Or, a bit more succinctly as a list comprehension:</p>

<pre class="lang-py prettyprint-override"><code>def read_file(name):
    with open(filename) as fh:
        return [Counter(line) for line in fh if not line.startswith('\n')]
</code></pre>

<p>Where the <code>str.startwith</code> is a bit more robust for variable-length strings, as it avoids the <code>if mystring[:len(to_check)] == to_check</code> mess.</p>

<h1>Checking duplicate columns</h1>

<p>It might be easier to leverage <code>itertools.combinations</code> to get pairs of columns in your dataframe, then use the <code>pd.Series.all()</code> function to check the values:</p>

<pre class="lang-py prettyprint-override"><code># change your naming to fit with common naming standards for
# variables and functions, pep linked below
def get_duplicate_columns(df):
    '''
    You are looking for non-repeated combinations of columns, so use
    itertools.combinations to accomplish this, it's more efficient and
    easier to see what you are trying to do, rather than tracking an index
    '''
    duplicate_column_names = set()
    # Iterate over all pairs of columns in df
    for a, b in itertools.combinations(df.columns, 2):
        # will check if every entry in the series is True
        if (df[a] == df[b]).all():
            duplicate_column_names.add(b)

    return list(duplicate_column_names)
</code></pre>

<p>This way you avoid the nested loops, and you are just checking across the boolean mask.</p>

<h1>Check pandas datatype for column</h1>

<p>It is both unclear and bad practice to do:</p>

<pre class="lang-py prettyprint-override"><code>if str(df[fieldName].dtypes).replace('64', '',1) == 'float':
</code></pre>

<p>To explicitly check a pandas datatype, use the <code>dtype</code> on a <code>pd.Series</code> by accessing the column directly:</p>

<pre class="lang-py prettyprint-override"><code>import numpy as np

if df[field_name].dtype == np.float64:
  # do things

</code></pre>

<p>You'll need <code>numpy</code> because the dtypes for pandas inherit from <code>numpy</code> dtypes. An even clearer way to check (in case you get <code>np.float32</code> instead of <code>np.float64</code>, for example) is to leverage the <code>pandas.api.types</code>:</p>

<pre class="lang-py prettyprint-override"><code>import pandas as pd
import pandas.api.types as pdtypes

if pdtypes.is_float_dtype(df[field_name]):
  # do things
</code></pre>

<p>This might be the preferred way to go, since you are assuming that you will always get <code>float64</code>, where you might not. This also works for other types:</p>

<pre class="lang-py prettyprint-override"><code>if pdtypes.is_integer_dtype(df[field_name]):
  pass

elif pdtypes.is_object_dtype(df[field_name]):
  pass

elif pdtypes.is_datetimetz(df[field_name]):
  pass

# etc
</code></pre>

<h1>Checking last element in an indexed data structure</h1>

<p>Instead of using <code>object[len(object) - 1]</code>, just use <code>object[-1]</code>. Negative indexing also works for counting backwards:</p>

<pre class="lang-py prettyprint-override"><code>x = list('abcdefg')

# get the last element
x[-1]
'g'

# get the third-to-last element
x[-3]
'e'
</code></pre>

<h1>Finding a substring using str.find</h1>

<p>In your datetime processing logic there's a ton of the following:</p>

<pre class="lang-py prettyprint-override"><code>year_st = field_value.find(str(date_time.year))

if year_st == -1:
  # do something
</code></pre>

<p>This will never evaluate to true, because <code>find</code> will never return a negative index:</p>

<pre class="lang-py prettyprint-override"><code>mystr = 'abcd'

mystr.find('d')
# 3
</code></pre>

<p>Likewise, later you use:</p>

<pre class="lang-py prettyprint-override"><code>mon_st = format.find(str(dateTime.month))
if mon_st != -1:
  # do things
</code></pre>

<p>This will always evaluate to <code>True</code>.</p>

<p>This falls under checking <code>str.endswith</code>, since you want to know if that block of text is the last element in the string:</p>

<pre class="lang-py prettyprint-override"><code>if field_value.endswith(str(date_time.year)):
  # do things
</code></pre>

<h1>tuples vs lists</h1>

<p>There are numerous places in your code where you use lists that you do not modify:</p>

<pre class="lang-py prettyprint-override"><code>if ending not in formats:

...
df = df.drop(columns=skipSeperator, errors='ignore')

...
</code></pre>

<p>You incur extra overhead by allocating a mutable data structure:</p>

<pre class="lang-py prettyprint-override"><code>import sys

lst, tup = list(range(100)), tuple(range(100))

sys.getsizeof(lst)
1008

sys.getsizeof(tup)
848
</code></pre>

<p>With this in mind, it's better to stick with the smaller data structure.</p>

<h1>Pandas Recommendations</h1>

<h2>data-type checking</h2>

<p>This kind of code-snippet is not something you'll want:</p>

<pre class="lang-py prettyprint-override"><code>if str(df[fieldName].dtypes).replace('64', '',1) == 'float':
</code></pre>

<p>You're calling <code>dtypes</code>, then coercing it to a string, then replacing it, <em>then</em> comparing to a fixed string. No need, those are numpy datatypes, so just do:</p>

<pre class="lang-py prettyprint-override"><code>if df[fieldName].dtype == np.float64:
</code></pre>

<h2>str functions</h2>

<p>You can refactor code snippets like:</p>

<pre class="lang-py prettyprint-override"><code>fieldStructure.loc[fieldName,'Size'] = df[fieldName].map(str).apply(len).max()
</code></pre>

<p>To be</p>

<pre class="lang-py prettyprint-override"><code>fieldStructure.loc[fieldName, 'Size'] = df[fieldName].str.len().max()
</code></pre>

<p>Since the field is already a string type, you shouldn't need to map everything with <code>str</code>, and then the <code>len</code> operation should already be supported. The latter is faster largely because of the fewer operations that need to occur:</p>

<h3>timing</h3>

<pre class="lang-py prettyprint-override"><code>python -m timeit -s "import pandas as pd; df = pd.DataFrame([['kladflna', 'l;adfkadf', ';aljdnvohauehfkadflan'] for i in range(1000)], columns=list(range(3)))" 'df[2].map(str).apply(len).max()'
1000 loops, best of 3: 506 usec per loop

python -m timeit -s "import pandas as pd; df = pd.DataFrame([['kladflna', 'l;adfkadf', ';aljdnvohauehfkadflan'] for i in range(1000)], columns=list(range(3)))" 'df[2].str.len().max()'
1000 loops, best of 3: 351 usec per loop
</code></pre>

<h3>function calls</h3>

<pre class="lang-py prettyprint-override"><code>from dis import dis

import pandas as pd; df = pd.DataFrame([['kladflna', 'l;adfkadf', ';aljdnvohauehfkadflan'] for i in range(1000)], columns=list(range(3)))

def f(df):
    df[2].map(str).apply(len).max()

def g(df):
    df[2].str.len().max()

dis(f)
  2           0 LOAD_FAST                0 (df)
              2 LOAD_CONST               1 (2)
              4 BINARY_SUBSCR
              6 LOAD_ATTR                0 (map)
              8 LOAD_GLOBAL              1 (str)
             10 CALL_FUNCTION            1
             12 LOAD_ATTR                2 (apply)
             14 LOAD_GLOBAL              3 (len)
             16 CALL_FUNCTION            1
             18 LOAD_ATTR                4 (max)
             20 CALL_FUNCTION            0
             22 POP_TOP
             24 LOAD_CONST               0 (None)
             26 RETURN_VALUE

dis(g)
  2           0 LOAD_FAST                0 (df)
              2 LOAD_CONST               1 (2)
              4 BINARY_SUBSCR
              6 LOAD_ATTR                0 (str)
              8 LOAD_ATTR                1 (len)
             10 CALL_FUNCTION            0
             12 LOAD_ATTR                2 (max)
             14 CALL_FUNCTION            0
             16 POP_TOP
             18 LOAD_CONST               0 (None)
             20 RETURN_VALUE

</code></pre>

<h1>Opening a file multiple times</h1>

<p>In your <code>identifyFixedWidth</code> function, you open and read a file multiple times. I would say this makes it a candidate for a refactor, since these tasks should probably be broken into smaller functions:</p>

<pre class="lang-py prettyprint-override"><code>def identify_fixed_width(name):
    filepath = os.path.join(path, name)

    # open the file here, and re-use the file-handle with fh.seek(0)
    with open(filepath) as fh:
        number_lines, avg_chars, max_length = get_avg_chars(fh)

        # re-use this file handle, go back to the beginning
        fh.seek(0)
        counter = find_header(fh, avg_chars)

        fh.seek(0)
        col_pos = get_row_counter(fh, counter)

    common = list(set.intersection(*map(set, col_pos))
    logger.debug(f"Potential field separator posistions: {common}")

    # replace this with a list comprehension, it's faster and more compact
    new_common = [x for x in common if (x-1) not in common]
    new_common.append(max_len)

    logger.debug(f"Field separator positions identified as {new_common}"

    # do not shadow builtin names like range. If you must, use a leading underscore
    _range = len(new_common)
    width = []

    # underscore will show an unused or throwaway variable
    for i, _ in enumerate(new_common[0:_range-1]):
        width.append(new_common[i+1] - new_common[i])

    logger.debug(f'Column Lengths: {width}') 
    return counter, width  


def get_avg_chars(fh):
    """
    Use enumerate to track the index here and
    just count how much you want to decrement from the index
    at the end
    """
    decrement, max_len, total_chars = 0, 0, 0

    for idx, line in enumerate(fh, start=1)
        total_chars += len(line)
        if len(line) &lt;= 2:
            decrement += 1

        # this can be evaluated with a ternary expression
        max_len = len(line) if len(line) &gt; max_len else max_len

    # at the end of the for loop, idx is the length of the file
    num_lines = idx - decrement
    avg_chars = total_chars / num_lines

    return num_lines, avg_chars, max_len


def find_header(fh, avg_chars):
    counter = 0
    for line in fh:
        logger.debug(f"{counter} has {len(line)} chars")
        lower = len(line) &lt;= avg_chars * 0.9
        upper = len(line) &gt;= avg_chars * 1.1
        if upper or lower:
            logger.debug(f"Line {counter}: Maybe part of header and needs to be skipped")
            counter += 1
        else:
            logger.debug(f"Header found at {counter}")   
            break
    return counter


def get_row_counter(fh, counter):
    """
    Again, use enumerate here for row_counter
    """ 
    col_pos = []
    for row_counter, line in enumerate(fh):
        if row_counter &lt;= counter:
             continue
        blanks = [m.start() for m in re.finditer(' ', line)]
        if len(blanks) &gt; 2:
            # you've already declared this variable, so use it 
            col_pos.append(blanks)
            if row_counter &lt;= 5:
                logger.debug(col_pos[-1])
    return col_pos
</code></pre>

<p>Now, it's easier to break apart, debug, and separate out pieces of work within a function.</p>

<h1>Style</h1>

<p>A few things</p>

<ol>
<li><p>Variable and function names <a href="https://www.python.org/dev/peps/pep-0008/#function-and-variable-names" rel="nofollow noreferrer">should be lowercase</a> with words separated by underscores (<code>_</code>). Upper case is usually reserved for types, classes, etc. So something like <code>rowCounter</code> should really be <code>row_counter</code>.</p></li>
<li><p>When checking for <a href="https://www.python.org/dev/peps/pep-0008/#programming-recommendations" rel="nofollow noreferrer">equivalence with singletons such as <code>None</code>, <code>True</code>, and <code>False</code></a>, it is usually better to use <code>if value:</code> or <code>if not value</code>:</p></li>
</ol>

<pre class="lang-py prettyprint-override"><code># change this to
if date_flag == True:

# this
if date_flag:
</code></pre>

<ol start="3">
<li>I'm not sure if there's a PEP for it, but visually separating blocks of code with newlines can be very helpful. As an example:</li>
</ol>

<pre class="lang-py prettyprint-override"><code>    logger.debug('% of rows missing the charecter')
    logger.debug(df.isna().sum()/ df.isna().count())
    cleanupCandidates=df.dropna(axis='columns', thresh = (df.shape[0] + 1)*.8).fillna(-1)
    logger.debug('Dropping characters not present in 80% of the columns')
    logger.debug(cleanupCandidates.head())
    lowestVariance = 0
    spaceDetectedFlag = False
    Separator2 = ''
    for character in cleanupCandidates.columns:
        logger.debug('**********' + character +' **********')
        x = cleanupCandidates.loc[:,character].var()
        logger.debug('Calculated variance : ' + str(x) )
        if character == ' ':
            spaceDetectedFlag = True
            logger.debug('Potential position based file...')
            continue
        if lowestVariance &gt;= x:
            lowestVariance =x
            Separator2 = character
        logger.debug("Separator identified as : " + Separator2 + ' using METHOD 2')
    if Separator == Separator2:
        commonSep= Separator
    else:
        commonSep = list(set(Candidates).intersection(cleanupCandidates.columns))
        logger.debug('Both methods identify '+ str(commonSep) + 'as one of the separator candidates.')
        maxMode = 0
        modeTable = cleanupCandidates.mode()

</code></pre>

<p>This just looks like a gigantic wall of code, and is difficult to quickly scan for keywords, patterns, etc. Try breaking up the code by breaking things into logical steps:</p>

<pre class="lang-py prettyprint-override"><code># Break all of this apart
    logger.debug('% of rows missing the charecter')
    logger.debug(df.isna().sum()/ df.isna().count())

    cleanupCandidates=df.dropna(axis='columns', thresh = (df.shape[0] + 1)*.8).fillna(-1)
    logger.debug('Dropping characters not present in 80% of the columns')
    logger.debug(cleanupCandidates.head())

    lowestVariance = 0
    spaceDetectedFlag = False
    Separator2 = ''

    for character in cleanupCandidates.columns:
        logger.debug('**********' + character +' **********')
        x = cleanupCandidates.loc[:,character].var()
        logger.debug('Calculated variance : ' + str(x) )

        # separate these if statements, they do different things
        if character == ' ':
            spaceDetectedFlag = True
            logger.debug('Potential position based file...')
            continue

        if lowestVariance &gt;= x:
            lowestVariance =x
            Separator2 = character

        logger.debug("Separator identified as : " + Separator2 + ' using METHOD 2')

    # if, elif, else should be connected because they are one logical
    # block of code
    if Separator == Separator2:
        commonSep= Separator
    else:
        commonSep = list(set(Candidates).intersection(cleanupCandidates.columns))
        logger.debug('Both methods identify '+ str(commonSep) + 'as one of the separator candidates.')
        maxMode = 0
        modeTable = cleanupCandidates.mode()
</code></pre>

<ol start="4">
<li>Make sure there's <a href="https://www.python.org/dev/peps/pep-0008/#other-recommendations" rel="nofollow noreferrer">consistent whitespace around variables and operators.</a></li>
</ol>

<pre class="lang-py prettyprint-override"><code># go from this
lowest_variance =x
common_sep= separator
# to this
lowest_variance = x
common_sep = separator
</code></pre>
    </div>