<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I have made some changes to make it neater and more efficient. See the end of this response for the final solution. But I'll start with a few comments.</p>

<p>There is no point making your class inherit the <code>object</code> class, especially if you're working with Python 3.</p>

<pre><code>class Page(object):
</code></pre>

<p>The <code>soup()</code> method seems to be called indiscriminately causing <code>BeautifulSoup</code> to parse the contents of the page in concern too many times (see the <code>map_page()</code> method, for example). It is probably more efficient to parse once, afterwhich you can save whatever (e.g. <code>title</code> and <code>links</code>)you need as object properties.</p>

<p>Using <code>list</code> and <code>map</code> in this context seems unnecessary. It helps if you strive for readability --- your future self will thank you.</p>

<pre><code>links = [i for i in (list(map((lambda url : url if bool(urlparse(url).netloc) == True else urljoin (self.base_url, url)),href))) if i.startswith(self.base_url)]
</code></pre>

<p>Also, checking the truthiness of <code>urlparse(url).netloc</code> doesn't require you to coerce it to a boolean result first. Simply replacing <code>if bool(urlparse(url).netloc)</code> with <code>if urlparse(url).netloc</code> would suffice.</p>

<p>In the <code>site_map()</code> function, you can replace the while loop with something simpler, e.g.:</p>

<pre><code>while links_to_map:
    check_and_add(links_to_map.pop())
</code></pre>

<p>I have also made other subjective simplifications that hopefully should be obvious to you.</p>

<pre><code>import pprint
import urllib.request
from pprint import pprint
from urllib.parse import urlparse, urljoin

import bs4 as bs


class Page:
    def __init__(self, base_url, url):
        self.url = url
        self.base_url = base_url
        self.souped = None
        self.title = None
        self.links = None

    def soup(self):
        def clean(url):
            return url if urlparse(url).netloc else urljoin(self.base_url, url)

    sauce = urllib.request.urlopen(self.url).read()
    self.souped = bs.BeautifulSoup(sauce, "lxml")
    self.title = self.souped.title.string
    hrefs = set([clean(i.get("href")) for i in self.souped.findAll("a")])
    self.links = [link for link in hrefs if link.startswith(self.base_url)]
    return self

    @property
    def map_page(self):
        lookup = {self.url: {"title": self.title, "links": self.links}}
        return lookup


def site_map(base_url):
    map_pages = {}
    links_to_map = [base_url]

    def check_and_add(url):
    if url not in map_pages:
        page = Page(base_url, url).soup()
        links_to_map.extend(page.links)
        map_pages.update(page.map_page)

    while links_to_map:
        check_and_add(links_to_map.pop())

    pprint(map_pages)
</code></pre>
    </div>