<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>It would be good to have some test graph to try the code, I've generated an overly simple graph (one edge per node, 7MB file generated) using the following Python script (output redirected to file):</p>

<pre><code>nodes = 1000000
edges = nodes/2
print("{} {}".format(nodes, edges))
for i in range(1, nodes+1, 2):
   print("{} {}".format(i, i+1))
</code></pre>

<p>Additionally, in order to profile data in Visual Studio, I've done following changes:</p>

<ol>
<li>At the start of main(), I've redirected cin to read from input file (needed to automate profiling):
std::ifstream in("graph.dat");
std::cin.rdbuf(in.rdbuf());</li>
<li>To placate Visual Studio C++ compiler, I've changed the visited array to:
 bool *visited = new bool[nodes];
 ...
 delete[] visited;</li>
</ol>

<p>With these changes, profiler shows that 86.5% of CPU time is spent in basic_istream (mostly in _Lock/_Unlock buffer methods, could be MSVC specific), i.e. reading the data.
dfs algorithm itself takes only 0.45% of CPU time!
If the entire program run time is measured at the competition, the obvious place is to refactor the data input to something much faster, possibly using low-level APIs like scanf.</p>

<p>Perhaps the profiling results will be different on Linux, my general advice is to use profiler.</p>
    </div>