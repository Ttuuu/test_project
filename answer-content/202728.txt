<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>First of all I'd like to say that your code is fast. From studying it, the major bottlenecks that I've found come from the input being a string, and from converting to numpy arrays and back.</p>

<p>Since what you're doing is a kind of cumulative sum with some alterations, I'd go with <code>numpy.cumsum</code>. It's a bit tricky to get everything in place, but the calculations of the actual sequence is actually not the major bottleneck. From what I've seen, the solution I came up with is about twice as fast, and 75% of the time is used to convert the string input to something useful, which in this case is a numpy array representing the character index in the string <code>"ATCG"</code> for each character in the input string.</p>

<pre><code>def transform_fast(seq, d):
    l = len(seq)
    x = np.linspace(0, l, 2 * l + 1, dtype = np.float32)
    y = np.zeros(2* l + 1, dtype = np.float32)

    atcg = np.array([d[x] for x in seq], dtype = np.int8)

    a = (atcg == 1).astype(np.int8)
    t = (atcg == 2).astype(np.int8)
    c = (atcg == 4).astype(np.int8)
    g = (atcg == 8).astype(np.int8)
    ac = a - c
    tg = -t + g

    cum_sum = np.concatenate((
        np.array([0]),
        np.cumsum(tg[:-1])
    ))

    y[1::2] = cum_sum + 0.5*(ac + tg)
    y[2::2] = cum_sum + tg

    return x, y
</code></pre>

<p>In the function above, the argument <code>d</code> is a dictionary which looks like:</p>

<pre><code>d = {
    "A": 1, "T": 2, "C": 4, "G": 8,
    "U": 0, "W": 0, "S": 0, "M": 0,
    "K": 0, "R": 0, "Y": 0, "B": 0,
    "D": 0, "H": 0, "V": 0, "N": 0, "Z": 0
}
</code></pre>

<p>The only difference compared to your solution is that this returns numpy arrays rather than lists. If this doesn't suit your use case, you can convert them to lists. However, this will slow down the overall performance significantly. </p>

<p>The code above also does not handle the non-<code>ATCG</code> characters in the input string. However, I think that you'll be able to follow the code and implement that in a similar fashion. </p>

<pre><code>Benchmark with random input string of length 10^3
transform(seq): 0.45ms
transform_fast(seq): 0.24ms
Speedup factor: 1.82

Benchmark with random input string of length 10^6
transform(seq): 388.42ms
transform_fast(seq): 133.40ms
Speedup factor: 2.91
</code></pre>

<p>EDIT: I found that the <code>np.fromiter(map(...))</code> that was previously used was unnecessary, and replaced it. This increased performance, benchmarks have been updated. I also found that <code>-t + g</code> was used thrice, and saved the result to a variable. I also switched <code>x</code> and <code>y</code> to be <code>np.float32</code> arrays, as that improved performance slightly. </p>

<p>It should be noted that the approach above uses more memory than your original approach, which could be a problem for large enough sequences. On my machine (16GB RAM) I couldn't get the result for a sequence of length \$10^8\$, as I ran out of memory.</p>

<p>For the sake of curiosity, here are the benchmarks for when the input string is parsed into a numpy array before <code>transform_fast</code>, which could be used if the input sequences are reused often (these benchmarks haven't been updated, but should remain roughly the same):</p>

<pre><code>Benchmark with random input string of length 10^3
transform(seq): 0.42ms
transform_fast(seq): 0.13ms
Speedup factor: 3.15

Benchmark with random input string of length 10^6
transform(seq): 380.23ms
transform_fast(seq): 37.23ms
Speedup factor: 10.21
</code></pre>
    </div>