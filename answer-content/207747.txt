<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Since you never use <code>getLinks</code> without a call to <code>getFullLink</code> afterwards, I would merge these two functions. I would also make it a generator:</p>

<pre><code>def get_links(soup, pattern):
    for link in soup.select(pattern):
        yield urljoin(base, link.get("href"))
</code></pre>

<p>Then your main part can become this nested <code>for</code> loop:</p>

<pre><code>if __name__ == "__main__":
    pattern1 = "#seriesDiv [href*='&amp;CIK']"
    pattern2 = "[id=documentsbutton]"
    pattern3 = "[summary='Document Format Files'] td:nth-of-type(3) [href$='.htm'],td:nth-of-type(3) [href$='.txt']"

    final_links = []
    for first_link in get_links(make_soup(start_urls[0]), pattern1):
        for second_link in get_links(make_soup(first_link), pattern2):
            final_links.extend(get_links(make_soup(second_link), pattern3))
    print(final_links)
</code></pre>

<p>I also renamed your functions according to Python's official style-guide, <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a> and added a <a href="http://stackoverflow.com/questions/419163/what-does-if-name-main-do"><code>if __name__ == "__main__":</code> guard</a>.</p>

<p>One way to make this a bit faster (this sounds like it could be a lot of requests) is to use <a href="http://docs.python-requests.org/en/master/user/advanced/" rel="nofollow noreferrer"><code>requests.Session</code></a> to re-use the connection to the server:</p>

<pre><code>session = requests.Session()

def make_soup(url):
    res = session.get(url)
    res.raise_for_status()
    return BeautifulSoup(res.content, "lxml")
</code></pre>

<p>Here I also added a guard so that the program stops if any site does not exists (i.e. returns 404 or similar).</p>
    </div>