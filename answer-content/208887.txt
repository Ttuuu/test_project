<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<ol>
<li><p>When using NumPy, stick to NumPy functions where possible instead of going via pure Python and back again (which is usually slower). So instead of getting the unique elements of an array by writing <code>np.array(list(set(...)))</code>, call <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html" rel="noreferrer"><code>numpy.unique</code></a>.</p></li>
<li><p>The expression <code>np.argwhere(vocs[j]==x[i,j])</code> has to search the whole vocabulary for the word <code>x[i,j]</code>, and this has to be done for every feature in every sample. This means that if there are <span class="math-container">\$s\$</span> samples and <span class="math-container">\$f\$</span> features, and each feature has <span class="math-container">\$w = O(s)\$</span> words, the overall runtime is proportional to <span class="math-container">\$sfw = O(s^2f)\$</span>. That is, it's quadratic in the number of samples. This is why it takes so long.</p>

<p>To avoid this, we need to construct, for each feature, an inverse mapping from words in the samples to their indexes in the vocabulary. How do we construct such inverse mappings? Well, looking at the <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html" rel="noreferrer"><code>numpy.unique</code></a> documentation, we find that it takes a keyword argument:</p>

<blockquote>
  <p>return_inverse : <em>bool, optional</em></p>
  
  <p>If <code>True</code>, also return the indices of the unique array (for the specified axis, if provided) that can be used to reconstruct <em>ar</em>.</p>
</blockquote>

<p>These inverse arrays are exactly what you need, and so your code becomes:</p>

<pre><code>vocs, inverses = zip(*(np.unique(feature, return_inverse=True) for feature in x.T))
x_new = np.vstack(inverses).T
</code></pre></li>
</ol>
    </div>