<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<blockquote>
  <p>I tried using the fused multiply-add and multiply-add-negate instructions, and they made the code significantly slower than using 2 or 3 separate instructions, unfortunately.</p>
</blockquote>

<p>This is usually indicative of a latency bottleneck,</p>

<blockquote>
  <p>That's about a 33% increase, which is OK. Given that I'm calculating 8 times as many pixels at once, I was hoping for more.</p>
</blockquote>

<p>And so is this.</p>

<p>Actually this is expected for Mandelbrot, because it based on iterated function application, so it inherently has a non-trivial loop-carried dependency. Floating point operations on Intel have a high throughput, but they are still slow operations in the sense of having a high latency compared to their throughput. On Skylake X (which I guess you are using, from your use of AVX512), an FMA takes 4 cycles but the processor can start two of them every cycle. So if they are too "tied up" (and with FMA things get even more tied up, because every FMA is waiting for 3 instead of 2 inputs to be ready), it might be that there is always some floating point operation being executed, but actually on Skylake X we would want 8 operations to be "busy" at any time. On Haswell it was even worse, taking 10 "overlapping" FMAs to saturate the floating point units.</p>

<p>That situation can be improved by interleaving the calculation of several (4? 8?) independent rows of 8 pixels, though an unfortunate side-effect of this is that it would also "round up" the loop count to the max count among all pixels in the block. That already happens at a smaller scale now but it will get worse, and suppress the potential gain from doing this.</p>
    </div>