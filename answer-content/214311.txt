<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>Review</h1>

<ul>
<li><p>Styling</p>

<ol>
<li>Import should be at the top of the file</li>
<li>Use a <code>if __name__ == '__main__:'</code> guard</li>
<li>Split some functionality into function, keeping everything in the global namespace is considered bad form</li>
</ol></li>
<li><p>Use <a href="https://docs.python.org/3/library/stdtypes.html#str.translate" rel="nofollow noreferrer"><code>str.translate</code></a> for cleaning texts</p>

<p>This should faster compared to regex substitution</p>

<p>Secondly you can use <code>string.punctuation</code> which in is in the standard library, making your first code block:</p>

<pre><code>trans_table = str.maketrans('', '', string.punctuation.replace('.', ''))
trans_text = text.translate(trans_table).lower()
</code></pre>

<p><em>You'd still need to clean the wiki references <code>[15]...etc</code> from the text though</em></p></li>
<li><p>Why do you import nltk 2 times?</p>

<p>Just <code>import nltk</code> once</p></li>
<li><p>Using <code>set</code> lookup is O(0)</p>

<p>Instead of checking if a variable is in a list you should compare against a set, this will improve performance, <a href="https://wiki.python.org/moin/TimeComplexity" rel="nofollow noreferrer">see Python time complexity</a></p>

<pre><code>stop_words = set(nltk.corpus.stopwords.words('english'))
</code></pre></li>
<li><p>Use list comprehension</p>

<p>List comprehension should be a bit faster compared to appending in a for loop, and it is considered Pythonic,</p>

<p>Secondly you can pre-process the text to hold a list of sentences, instead of calculating it everytime</p>

<pre><code>word_list = set(
    word for sent in trans_text.split('.') for word in sent.split() 
    if word not in stop_words and nltk.pos_tag([word])[0][1] in desirable_tags
)
sentences = [
    set(sentence.split()) for sentence in trans_text.split('.')
]
</code></pre></li>
<li><p>Use <a href="https://www.python.org/dev/peps/pep-0279/" rel="nofollow noreferrer">enumerate</a> if you need both the item and the index</p>

<pre><code>table = np.zeros((len(word_list), len(word_list)), dtype=int)
for sent in sentences:
    for i, e in enumerate(word_list):
        for j, f in enumerate(word_list):
            if e in sent and f in sent:
                table[i,j] += 1
</code></pre></li>
<li><p>Use <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer"><code>collections.Counter()</code></a> for counting words</p>

<p>And you can create a dataframe from <code>Counter</code> in one go with</p>

<pre><code>count_words = pd.DataFrame.from_dict(Counter(word_list), orient='index').reset_index()
</code></pre>

<p>But you don't need to convert it to a dataframe at all, since you can get the word count by just reading the Dictionary</p>

<pre><code>count_words = Counter(word_list)
...
assoc_df = assoc_df.append({'Word 1': row_word, 
                            'Word 2': col_word, 
                            'Association Strength (Word 1 -&gt; Word 2)': df[row_word][col_word]/count_words[row_word]}, 
                            ignore_index=True)
</code></pre></li>
</ul>

<p><em>Note that I am not really into Pandas/Preprocessing so I might have missed a few things :)</em></p>
    </div>