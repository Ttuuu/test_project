<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h2>Style</h2>

<p>Python comes with an official <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">Style Guide</a> often just called PEP8, and especially as a beginnger it's a good starting point to get going. Of course coding style is often a matter of choice, however, there are aspects you should definitely follow.</p>

<p><strong>Whitespace</strong><br>
As you know, Python's code structure is build upon indentation, so some parts are already language-defined. The style guide also has recommendations on how to use <a href="https://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements" rel="nofollow noreferrer">whitespace within statements and expressions</a>. For example, <code>,</code> should always be followed be a single space character, while <code>=</code> is preceded and followed by a single space when used in assignments (there should be no whitespace around <code>=</code> if used as keyword arguments to functions such as <code>foo(batz='bar')</code>). So you would go from</p>

<pre class="lang-py prettyprint-override"><code>gradL_W,gradL_b=self.backward(y_i,y_hat,x_i)
self.w_,self.b_=self.update(gradL_W,gradL_b)
</code></pre>

<p>to</p>

<pre class="lang-py prettyprint-override"><code>gradL_W, gradL_b = self.backward(y_i, y_hat, x_i)
self.w_, self.b_ = self.update(gradL_W, gradL_b)
</code></pre>

<p>which does look way cleaner IMHO.</p>

<p><strong>Variable names</strong><br>
It's always good practice to use descriptive variable names. Simply writing <code>self.weights</code> instead of <code>self.w_</code> wont hurt that much. Apart from that, the Style Guide also recommends to use a single leading underscore for non-public variable names. Note, this is only a convention, since Python has no "real" private member variables as you may know from other languages.</p>

<p><strong>Documentation</strong><br>
There is a single function in your perceptron class that has a) documentation and b) also follows the <a href="https://www.python.org/dev/peps/pep-0008/#documentation-strings" rel="nofollow noreferrer">docstring-style</a> from the Style Guide. You should apply that to the other functions and maybe even to the class as well. Your current project might be simple, but if projects become more complex, good documentation will save you a lot of headache. Following the official docstring style also has the nice benefit that Python's <code>help(...)</code> function as well as most IDEs will easily find it.</p>

<h2>The code</h2>

<p>Apart from the stylistic issues mentioned above, there are some more direct code-focused aspects you should work on.</p>

<p><strong>Code duplication</strong><br>
There is some duplicated code in your implementation of the perceptron model. E.g., you implement the scalar product at the input of the perceptron twice! The first time at <code>net_input</code>, which is likely where it's supposed to go, and the second time in <code>predict</code>. <code>predict</code> also reimplements pretty much the whole point of <code>activation</code>. It's pretty straightforward to implement <code>predict</code> using <code>net_input</code> and <code>activation</code>:</p>

<pre class="lang-py prettyprint-override"><code>def predict(self, X):
    s = self.net_input(X)
    y_hat = list(map(self.activation, s))
    return y_hat
</code></pre>

<p>If you use Python for a while you will also learn to use list comprehensions more often than the <code>list(map(...))</code> construct, simply because it's more flexible and readable. Rewriting the calculation of <code>y_hat</code> as list comprehension would look like <code>y_hat = [self.activation(i) for i in s]</code>. After you have arrived at</p>

<pre class="lang-py prettyprint-override"><code>def predict(self, X):
    s = self.net_input(X)
    y_hat = [self.activation(i) for i in s]
    return y_hat
</code></pre>

<p>you may also find the similarity between <code>predict</code> and <code>forward</code> quite striking. <code>forward</code> can now be boiled down to simply</p>

<pre class="lang-py prettyprint-override"><code>def forward(self, x):
    return self.predict(x)[0]
</code></pre>

<p>Getting the "first" result of the return value using <code>[0]</code> is mainly to ensure that the new version just returns a single number as it was before. Otherwise it would be a list with a single element.</p>

<p><strong>Explicit is better than implicit</strong><br></p>

<p>(Taken from the <a href="https://www.python.org/dev/peps/pep-0020/" rel="nofollow noreferrer">Zen of Python</a>)</p>

<p>Using code like </p>

<pre class="lang-py prettyprint-override"><code>heaviside = lambda x: (1, -1)[x &lt; 0]
return heaviside(z)
</code></pre>

<p>might be clever, but clever does not equal good or readable most of the time. The same thing can also be expressed as <code>return -1 if z &lt; 0 else 1</code>, which is almost a verbatim translation of the mathematical definition of the step function as presented by Rashka. If you don't like the inline-if, you may also write it as "normal" if condition:</p>

<pre class="lang-py prettyprint-override"><code>if z &lt; 0:
    return -1
else:
    return 1
</code></pre>

<p><code>gradL_b = error * 1</code> is another instance of cleverness. This time, I am not even sure what you are actually trying to accomplish here. Depending on the type of your labels <code>y</code>, <code>error</code> will either be of type <code>int</code> or maybe also <code>float</code>, and multiplying it with <code>1</code> will not change that.</p>

<p><code>errors += (y_hat != y_i) * 1</code> is more obvious, but could also be expressed explicitly as <code>errors += int(y_hat != y_i)</code>. Python should even be able to do <code>errors += y_hat != y_i</code> without changing the end result.</p>

<p><strong>Return values</strong><br>
I'm not 100% sure what you are trying to accomplish with some of your function return values. For example, I cannot see the point in <code>fit</code> returning <code>self</code>. <code>update</code>is another instance of that topic. I can see you're using it as <code>self.w_, self.b_ = self.update(gradL_W, gradL_b)</code>, but there is not a real reason to do this, since <code>update</code> already modifies the weights internally.</p>

<p>You will likely have to think about that topic as you further progress in your journey into the depths of neural networks (pun intended). Often, the multilayer perceptron is  one of the next logical steps in this process. At this stage, you will need the gradients of previous layers to be able to propagate errors through the network. But time will tell<sup>1</sup>.</p>

<p>Until then: Happy coding!</p>

<hr>

<p><sub><sup>1</sup>You will also probably soon find out that modelling single neurons is not sufficient (and computationally efficient) for what there is to come. Depending on your learning materials, matrix operations will pop up more and more often. This is the time where the NumPy library will help you shine.</sub></p>
    </div>