<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>Build a userland threaded prefetch</h1>

<p>In addition of <a href="https://codereview.stackexchange.com/a/235379/115494">Damon excellent</a> answer, I would like emphasize this: trying to add any optimization only to be limited by disk throughput is a <strong>waste of time.</strong></p>

<p>It's something that's hard to see and even harder to believe. And so this answer.</p>

<p>Your desktop machine probably has more than one CPU, and certainly any server your code may run will be by dozen of CPUs by now.</p>

<p>So a portable solution the get 80% of that critical performance is to code a threaded file prefetcher. Say, a separate thread dedicated to read <code>N</code> sequencial pre-allocated buffers of <code>M</code> size, while the parsing occurs in another thread.</p>

<p><code>N</code> and <code>M</code> are left for your experimentation because you <strong>most probably</strong> will discover the parsing thread will be starving most of time, even after tweaking these numbers. This is even more true in the world of SSD drivers, where scheduling disk reads in parallel does not have a dramatic effect anymore.</p>

<p>You can add a alert into the prefetcher to warn about a full buffers situation, <strong>and only when</strong> worry about parser or processing optimization.</p>

<h1>Then build a thread parser</h1>

<p>Every ms spend in reading is a ms wasted in parsing. And other ms wasted in processing.</p>

<p>Leave your specific code simple and readable, but a thread parser, with small data accumulation may be a significant improvement.</p>
    </div>