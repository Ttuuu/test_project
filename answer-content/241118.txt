<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>user input</h1>

<p>What happens if the user does not type in <code>c</code> or <code>g</code>?</p>

<h1>typing</h1>

<p>As a general remark, I would include type annotations, so users of your code, (this includes you in 6 months time) can know what to expect.</p>

<h1>docstring</h1>

<p>The same goes for a docstring.</p>

<p>You kind of do that already </p>

<pre><code>def get_raw_frame(self):
    # Get a bolean and current frame (numpy array) from the webcam
</code></pre>

<p>But if you turn that into a docstring</p>

<pre><code>def get_raw_frame(self):
    """Get a bolean and current frame (numpy array) from the webcam"""
</code></pre>

<p>IDE's etc can keep track of this.</p>

<h1>inheritance</h1>

<p>I would not use inheritance here, but composition. An excellent explanation is given by Brandon Rhodes <a href="https://python-patterns.guide/gang-of-four/composition-over-inheritance/" rel="nofollow noreferrer">here</a></p>

<p>You can define a procotol.</p>

<pre><code>class VideoProcessor(typing.Protocol):
    def process(self, raw_frame:np.ndarray) -&gt; np.ndarray:
        ...
</code></pre>

<p>And then give 2 implementations:</p>

<pre><code>class ColorProcessor(VideoProcessor):
    def process(self, raw_frame: np.ndarray) -&gt; np.ndarray:
        """Return the frame untouched."""
        return raw_frame


class GrayProcessor(VideoProcessor):
    def process(self, raw_frame: np.ndarray) -&gt; np.ndarray:
        """Convert the raw frame to grayscale."""
        return cv2.cvtColor(raw_frame, cv2.COLOR_BGR2GRAY)
</code></pre>

<p>Then the init and <code>process</code> become something like this:</p>

<pre><code>def __init__(
        self, source: int, processor: VideoProcessor
    ):
        self.processor = processor
        self.capture = cv2.VideoCapture(source) 
        # If source = 0 the webcam starts

def process(self):
    """Let the processor process the raw frame."""
    raw_frame = self.get_raw_frame()
    if raw_frame is not None:
        return self.processor.process(raw_frame)
</code></pre>

<p>This way, If you ever want to implement a sepia, or green version, it's just a matter of implementing another <code>Processor</code>.</p>

<p>These processors can also be tested individually, without having to set up a videosource</p>

<h1>Hoist the IO</h1>

<p>Another thing I would change, is instead of letting the <code>Video</code> class instantiate the connection to the webcam, I would let this be done on a higher level, and have the Video class accept a video source.</p>

<p>Here are <a href="https://rhodesmill.org/brandon/talks/#clean-architecture-python" rel="nofollow noreferrer">1</a> <a href="https://rhodesmill.org/brandon/talks/#hoist" rel="nofollow noreferrer">2</a> talks on why you would want to do this. This concept is not limited to python (<a href="https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/" rel="nofollow noreferrer">3</a>)</p>

<pre><code>class VideoSource(typing.Protocol):
    def read(self) -&gt; typing.Tuple[bool, np.ndarray]:
        """Read the current frame.

        Returns a boolean success flag, 
        and the current frame, if successful.
        """
        ...

    def release(self) -&gt; None:
        """Release the connection to the video source."""
        ...

def __init__(
    self, source: VideoSource, processor: VideoProcessor
):
    self.processor = processor
    self.capture = source
</code></pre>

<p>This change makes it even easier to test the <code>Video</code> class.</p>

<h1>context manager</h1>

<p>Turning <code>Video</code> into a <code>context manager</code> is very simple:</p>

<pre><code>def __enter__(self):
    return self

def __exit__(self, type, value, traceback):
    self.end()
</code></pre>

<h1>Putting it together</h1>

<pre><code>if __name__ == "__main__":    
    while True:
        user_preference = input('Enter "c" for color, or "g" for grayscale: ')
        if user_preference in  "cg":
            break

    if user_preference == 'c':
        processor = ColorProcessor()
    if user_preference == 'g':
        processor = GrayProcessor()
    source = cv2.VideoCapture(0) 

    with Video(source=source, processor=processor) as video:
        while True:
            video.show_current_frame()

            if cv2.waitKey(1) &amp; 0xFF == ord('q'):
                break
</code></pre>

<h1>rectangles on the screen</h1>

<p>You could even generalize this to have consequent processors, for example if you want to add the rectangles</p>

<p>The Processor itself can be quite simple (I use <code>dataclasses</code> to avoid the boiler plate <code>__init__</code>:</p>

<p>import dataclasses</p>

<pre><code>@dataclasses.dataclass
class RectangleProcessor(VideoProcessor):
    x1: int
    y1: int
    x2: int
    y2: int

    color: typing.Tuple[int, int, int]

    def process(self, raw_frame: np.ndarray) -&gt; np.ndarray:
        return cv2.rectangle(
            raw_frame, (self.x1, self.y1), (self.x2, self.y2), self.color, 2
        )
</code></pre>

<p>You can implement a chain of processors very simply:</p>

<pre><code>class Video:
    def __init__(
        self,
        source: VideoSource,
        processors: typing.Optional[typing.Sequence[VideoProcessor]] = None,
    ):
        self.processors = processors
        self.capture = source

    def process(self) -&gt; np.ndarray:
        raw_frame = self.get_raw_frame()
        if self.processors is None:
            return raw_frame
        for processor in self.processors:
            raw_frame = processor.process(raw_frame)
        return raw_frame
</code></pre>

<p>This way you can even skip the noop <code>ColorProcessor</code></p>

<pre><code>if __name__ == "__main__":
    while True:
        user_preference = input('Enter "c" for color, or "g" for grayscale: ')
        if user_preference in "cg":
            break
        while True:


    processors = []
    if user_preference == "g":
        processors.append(GrayProcessor())

    user_preference = input('Do you want to add a rectange [y/N]:')

    if user_preference.lower() == "y":
        processors.append(RectangleProcessor(0, 0, 10, 10, (255, 0, 0)))

    source = cv2.VideoCapture(0)

    with Video(source=source, processors=processors) as video:
        while True:
            video.show_current_frame()

            if cv2.waitKey(1) &amp; 0xFF == ord('q'):
                break
</code></pre>

<p>Like this, you can easily add Processors that add timestamps to video's, names to streams, ...</p>
    </div>