<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Assuming you have a multi-core processor, you can use the multiprocessing module to do your scraping in parallel. Here's a good article that explains how to use it: <a href="https://sebastianraschka.com/Articles/2014_multiprocessing.html" rel="nofollow noreferrer">An introduction to parallel programming using Python's multiprocessing module</a> (you only need to read the first half of the article)</p>

<p>The simplest way to parallelize this would be to do your 2017 loop in a separate process from your 2018 loop. If you need it faster than that, you could further subdivide your 2017 and 2018 ranges. It also depends on how many cores you have. If you only have 2 cores, you won't benefit from dividing it into more than 2 processes (or 4 processes for 4 cores).</p>

<p>Other than that I can't see anything in your code structure you could change to speed it up.</p>

<p>Update: I'm not familiar with the API you're using, but if there's a way to make one API call that returns a list of games with their box scores instead of making a separate request for each game, that would be the best way to speed it up.</p>

<p>Also, according to Mathias in the comments, <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map" rel="nofollow noreferrer">multiprocessing.Pool.map</a> would be particularly helpful in this case. I'm not familiar with it, but it does look like it would be convenient for this.</p>
    </div>