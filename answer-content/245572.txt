<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>The process I would follow to improve the performance of any code would be to go through it in 3 passes,</p>
<ol>
<li>Cleaning - fix those small issues of style, fix bigger issues of semantics, and make the code nice to read.</li>
<li>Understanding - find out what we actually want to tell the computer to do.</li>
<li>Improving - choosing more appropriate algorithms or data structures for the task(s).</li>
</ol>
<p>Below I'll walk you through the steps I would take for cleaning up the code.</p>
<hr>
<p>The code as it stands is decent. There are some formatting issues, but the spacing and comments are pretty nice. Good job.</p>
<p>The first thing that stands out is the small inconsistencies. I would suggest using an auto-formatting tool (black, yapf, etc) to find and fix those sort of problems, we really don't need to be wasting mental resources on them. As an example, the spacing between arguments in <code>c_df.loc[np.isclose(c_df[col],x, atol=5)]</code> is not consistent.</p>
<p>While we are discussing tooling, a linter (pep8, pylint, pyflakes, etc) also picks up on some quick things to clean up. I wouldn't worry too much about lint warnings (or scoring), but I would take into account any critical errors it points out. For example, a quick lint highlights unused variables <code>row_spaces = {}</code> and missing imports "undefined name 'np'".</p>
<p>One minor issue which these tools don't catch is extra characters. Often I find code to look a lot nicer if there is less of it. Python is quite good about this, as you don't need brackets around conditions in if statements, or necessarily need square brackets when the generator expression will do.</p>
<p>If you want, here is the code I will base the next clean up on. I've fixed lint errors like unused variables, removed extra parenthesis, and removed comments for brevity. One thing of note is that in <code>left_groups = df_coord.loc[matches.index.values].reset_index()</code> df_coords is undefined, and I don't know what it should actually be.</p>
<pre><code>def pairwise(splits):
    "s -&gt; (s0,s1), (s1,s2), (s2, s3), ..."
    a, b = itertools.tee(splits, 2)
    next(b, None)
    return list(zip(a, b))


def space_sort(df):
    groups = df.groupby('page')
    pages = {
        i: j[['top', 'top1', 'left', 'middle', 'left1']]
        for i, j in groups
    }
    cols = ['left', 'middle', 'left1']
    boxes = {}
    for page in pages:
        c_df = pages[page]
        min_x = min(c_df.left)
        gaps = c_df.loc[df.left_diff &gt; 5]

        #
        counts = {'left': [], 'middle': [], 'left1': []}
        [
            counts[col].append(gaps[col].unique()) for col in cols
            if (gaps[col].value_counts() &gt; 2).any()
        ]

        if len(counts['left']) &gt; 0:
            counts['left'][0] = np.insert(counts['left'][0], 0, int(min_x))

        #
        for col in cols:
            if len(counts[col]) &gt; 0:
                for x in counts[col][0]:
                    matches = c_df.loc[np.isclose(c_df[col], x, atol=5)]
                    left_groups = df_coord.loc[
                        matches.index.values].reset_index()

                    #
                    vert_gaps = left_groups.loc[(left_groups.top -
                                                 left_groups.top1.shift()) &gt; 5]
                    vert_indexes = vert_gaps.index.values
                    vert_indexes = np.insert(vert_indexes, 0, 0)
                    vert_indexes = np.append(vert_indexes, len(left_groups))

                    #
                    pairs = pairwise(vert_indexes)
                    for start, end in pairs:
                        box = left_groups.loc[start:end - 1]
                        coords = (page, min(box.top), min(box.left),
                                  max(box.top1), max(box.left1))
                        boxes[coords] = list(left_groups.loc[start:end - 1,
                                                             ('index')])

    #
    table = []
    for a, b in itertools.combinations(boxes, 2):
        a_pg, a_top, a_left, a_top1, a_left1 = a
        b_pg, b_top, b_left, b_top1, b_left1 = b
        a_centre = (a_top + a_top1) // 2
        b_centre = (b_top + b_top1) // 2
        if np.isclose(a_top, b_top, atol=5) | np.isclose(
                a_centre, b_centre, atol=5) | np.isclose(
                    a_top1, b_top1, atol=5):
            table.append([boxes[a], boxes[b]])

    #
    t = pairwise(table)
    row = 0
    for i in t:
        if (i[1][0][-1] - i[0][1][-1]) == 1:
            for r in i:
                row += 1
                num = 1
                for col in r:
                    print('indexes', col, 'row', row, 'col', num)
                    num += 1
        else:
            row = 0
</code></pre>
<hr>
<pre><code>def pairwise(splits):
    "s -&gt; (s0,s1), (s1,s2), (s2, s3), ..."
</code></pre>
<p>PEP8 defers to <a href="https://www.python.org/dev/peps/pep-0257/#one-line-docstrings" rel="nofollow noreferrer">PEP257</a> for docstring convention. Convention dictates even single line docstrings should have three double quotes.</p>
<hr>
<pre><code>cols = ['left', 'middle', 'left1']
</code></pre>
<p>It looks like <code>cols</code> is not modified anywhere else in the code. You can enforce its immutability by changing <code>cols</code> to a tuple. This is useful to prevent accidental edits. The change is rather nice to make, just drop the square brackets.</p>
<pre><code>cols = 'left', 'middle', 'left1'
</code></pre>
<hr>
<pre><code>counts = {'left': [], 'middle': [], 'left1': []}
[
    counts[col].append(gaps[col].unique()) for col in cols
    if (gaps[col].value_counts() &gt; 2).any()
]
</code></pre>
<p>Modifying <code>counts</code> inside of a list comprehension is quite unexpected. List comprehensions are usually used to construct new lists. I would suggest turning this into a loop.</p>
<p>There is a potential bug waiting to happen. If <code>cols</code> is added to, but <code>counts</code> is forgotten about, an exception will occur due to the missing key.</p>
<pre><code>&gt;&gt;&gt; cols = ['left', 'middle', 'left1', 'middle_y']
&gt;&gt;&gt; counts = {'left': [], 'middle': [], 'left1': []}
&gt;&gt;&gt; counts['middle_y'].append(42.0)

KeyError: 'middle_y'
</code></pre>
<p>I think you should link <code>counts</code> to <code>cols</code> with something like <code>counts = {col: [] for col in cols}</code> or make a note beside one of them reminding whoever to do the manual update.</p>
<hr>
<pre><code>counts['left'][0] = np.insert(counts['left'][0], 0, int(min_x))
</code></pre>
<p>The docs for <a href="https://numpy.org/doc/stable/reference/generated/numpy.insert.html" rel="nofollow noreferrer">np.insert</a> have a see also section (which I find incredibly useful for when you just can't remember the name of a function, but you know a similar one). In it is np.concatentation. While searching for the difference between them, I found two results that suggest you may get better performance by changing the insert to a concatentation<sup><a href="https://stackoverflow.com/a/43184184/3503611">1</a>,<a href="https://stackoverflow.com/a/54773471/3503611">2</a></sup>. I don't know how someone would figure this out by themselves, but hey, potentially a free performance win. You just need to measure it now.</p>
<hr>
<pre><code>for col in cols:
    if len(counts[col]) &gt; 0:
        ...
</code></pre>
<p>I would much prefer a guard clause here, since the if statement has no else, and since the code inside continues to indent. Less indentation is a good goal. It gives you more room on each subsequent line, and a lot of indentation is an indication of (overly) complicated code<sup><a href="https://blog.codinghorror.com/flattening-arrow-code/" rel="nofollow noreferrer">3</a></sup>.</p>
<pre><code>for col in cols:
    if len(counts[col]) == 0:
        continue
    ...
</code></pre>
<hr>
<pre><code>vert_indexes = vert_gaps.index.values
vert_indexes = np.insert(vert_indexes, 0, 0)
vert_indexes = np.append(vert_indexes, len(left_groups))
</code></pre>
<p>I think np.concatenate would be especially useful here, since it would make it clear you are pre-pending and appending to the indexes. It could also perform the task more efficiently as it only needs to make one copy of <code>vert_indexes</code> instead of the two above.</p>
<pre><code>vert_indexes = np.concatenate([0], vert_gaps.index.values, [len(left_groups)])
</code></pre>
<p>You should double check this. Without trying it out I don't know if it fails to flatten when it should (and therefore needs axis=None or something).</p>
<hr>
<pre><code>a_pg, a_top, a_left, a_top1, a_left1 = a
b_pg, b_top, b_left, b_top1, b_left1 = b
a_centre = (a_top + a_top1) // 2
b_centre = (b_top + b_top1) // 2
if np.isclose(a_top, b_top, atol=5) | np.isclose(
        a_centre, b_centre, atol=5) | np.isclose(
            a_top1, b_top1, atol=5):
</code></pre>
<p>You probably want the short circuiting behaviour that the keyword <code>or</code> provides. I don't see a reason to use the bitwise or instead.</p>
<p>I don't like the unpacking that happens here. If you change the order of packing in <code>coords</code>, it will become outdated here (and vice versa). There is no link between them, so it may silently break. Without good tests you may not notice for a long time. I don't have a solution to this problem, so this is just a "be wary".</p>
<p>On a related note to the unpacking, there is a nice idiom for unused variables. As only a_top, a_top1, b_top, and b_top1, you can reduce the noise by using an <a href="https://stackoverflow.com/a/5893946/3503611">underscore</a> to indicate you know about this variable, but don't need it.</p>
<p>The section of code might now look something like this</p>
<pre><code>_, a_top, _, a_top1, _ = a
_, b_top, _, b_top1, _ = b
a_centre = (a_top + a_top1) // 2
b_centre = (b_top + b_top1) // 2
if np.isclose(a_top, b_top, atol=5) or np.isclose(
        a_centre, b_centre, atol=5) or np.isclose(
            a_top1, b_top1, atol=5):
    table.append([boxes[a], boxes[b]])
</code></pre>
<p>There is some incongruence in this code. There is a mismatch between using np.isclose (which I would expect to be used for floating point numbers) and // 2 (which I would expect for integers). So, are the variables expected to be floats or integers? Should the integer division (<code>// 2</code>) be floating point division (<code>/ 2</code>), or is np.isclose overkill when <code>abs(a_top - b_top) &lt;= 5</code> would do?</p>
<hr>
<pre><code>for i in t:
    if (i[1][0][-1] - i[0][1][-1]) == 1:
        for r in i:
</code></pre>
<p>This code is not easy to understand at a glance, mostly due to the variable names. Do you have more descriptive names you could use? What are <code>i[1][0]</code> and <code>i[0][1]</code>? Is this just debugging code and can be left out?</p>
    </div>