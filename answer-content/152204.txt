<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>When opening very large files, first concern would be memory availability on your system to avoid swap on slower devices (i.e. disk). </p>

<p>Pandas is shipped with built-in reader methods. For example the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html#pandas.read_table" rel="noreferrer"><code>pandas.read_table</code></a> method seems to be a good way to read (also in chunks) a tabular data file.</p>

<p>In the specific case: </p>

<pre><code>import pandas

df = pandas.read_table('./input/dists.txt', delim_whitespace=True, names=('A', 'B', 'C'))
</code></pre>

<p>will create a <code>DataFrame</code> objects with column named <code>A</code> made of data of type <code>int64</code>, <code>B</code> of <code>int64</code> and <code>C</code> of <code>float64</code>.</p>

<p>You can by the way force the <code>dtype</code> giving the related <code>dtype</code> argument to <code>read_table</code>. For example forcing the second column to be <code>float64</code>.</p>

<pre><code>import numpy as np
import pandas

df = pandas.read_table('./input/dists.txt', delim_whitespace=True, names=('A', 'B', 'C'),
                   dtype={'A': np.int64, 'B': np.float64, 'C': np.float64})
</code></pre>
    </div>