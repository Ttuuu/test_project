<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Two warnings before I give my suggestions:</p>

<ol>
<li><p>I'm no expert with pandas, numpy or this domain. There could be a one line solution that has a nice name and has been implemented already. If there is I don't know it.</p></li>
<li><p>I'm testing the code I provide with python 3.6.6, numpy 1.15.0, and pandas 0.23.4. These are guaranteed to be different versions than what you are using, so check every line, does what you want it to do.</p></li>
</ol>

<p>Onto the review.</p>

<hr>

<pre><code>TotalOrders = df_ord['ORD_KEY'].drop_duplicates().count() #Orders
</code></pre>

<p>I found the function nunique in the panda docs, which I believe does exactly what you want. As the comment here doesn't do much, I'd drop it.</p>

<pre><code>TOTAL_ORDERS = df_ord['ORD_KEY'].nunique()
</code></pre>

<p>Nitpick: According to the python style guide, there are a few different <a href="https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions" rel="nofollow noreferrer">naming conventions</a> that are recognised. I would usually associate CamelCase names with classes. I'd expect this variable to fall under the category of a GLOBAL_VARIABLE (if you were to reorganise the code or write it in another language) so that convention may be more appropriate. This is up to you so go with whatever you like. Once it is consistent it is easier to read.</p>

<hr>

<pre><code>arr_order_sku_pivot = pd.pivot_table(df_ord, values = 'QTY', index = 'ORD_KEY', columns = 'SKU_KEY').reset_index(drop=True).values
for i in range(0,arr_order_sku_pivot.shape[0]):
    for j in range(0,arr_order_sku_pivot.shape[1]):
        if arr_order_sku_pivot[i][j] &gt; 0:
            arr_order_sku_pivot[i][j] = 1
        else:
            arr_order_sku_pivot[i][j] = 0
</code></pre>

<p>There is too much happening on the first line. Since you are just pulling the values out of the dataframe there isn't much point here resetting the index.</p>

<pre><code>arr_order_sku_pivot = pd.pivot_table(df_ord, values='QTY', index='ORD_KEY', columns='SKU_KEY')
</code></pre>

<p>The loops lead me on to my bit of advice with pandas (and numpy). If you can do it with the library rather than with python, it is usually much better. So try every function you can find before resorting to manually coding whatever it is you are doing. The intuition behind it is that every time you move from one to the other, you have to spend a whole bunch of time converting the data back and forth. </p>

<p>So lets try re-doing these loops in pandas. From a high level, the loop goes through the df, and puts 1 anywhere there was a positive number. Everywhere else gets a 0. To save brain overhead lets just call arr_order_sku_pivot df for now.</p>

<pre><code>(df &gt; 0)
</code></pre>

<p>Ok, that now has a True everwhere that was greater than 0, and False everywhere else (including the nans). We want them to be 1s and 0s though.</p>

<pre><code>(df &gt; 0).astype(int)
</code></pre>

<p>There, that is almost everthing. To keep from modifying code further down we can now pull the values out too.</p>

<pre><code>(df &gt; 0).astype(int).values
</code></pre>

<p>Done. We are down to two lines, which should be much easier to comment.</p>

<pre><code>arr_order_sku_pivot = pd.pivot_table(df_ord, values='QTY', index='ORD_KEY', columns='SKU_KEY')
arr_order_sku_pivot = (arr_order_sku_pivot &gt; 0).astype(int).values
# Make a 2d array where each row is an order, and each column is the sku.
# A 1 in a column indicates the sku was part of the order.
</code></pre>

<hr>

<pre><code>if TotalOrders % OrdersPerBatch == 0: 
    Batches = TotalOrders//OrdersPerBatch 
else: 
    Batches = TotalOrders//OrdersPerBatch + 1
</code></pre>

<p>This is doing division and rounding up. To get the number of batches you could also use</p>

<pre><code>batches = int(np.ceil(float(TotalOrders) / OrdersPerBatch))
</code></pre>

<p>Some small points here, you can use np.ceil over math.ceil since it is already imported. If you ever transition to python3 (which is a good thing to think about doing) you wont even need to cast TotalOrders to a float, as the single slash is a floating point division.</p>

<hr>

<pre><code>o_min = b*OrdersPerBatch #Starting order number for (b+1)th batch
o_max = min((b+1)*OrdersPerBatch-1, TotalOrders-1) #Ending order number for (b+1)th batch
for o in range(o_min,o_max+1):
    ...
</code></pre>

<p>Nitpick: Why subtract 1 from each term of the min? You can just move it outside the min function.</p>

<pre><code>min(a - 1, b - 1) == min(a, b) - 1
</code></pre>

<p>You then go on to add 1 back to it for the for the loop.</p>

<pre><code>range(start, min(a, b) - 1 + 1) = range(start, min(a, b))
</code></pre>

<p>So hopefully that makes things a little easier to read.</p>

<pre><code>arr_sum = np.sum(arr_order_sku_pivot[o_min:o+1], axis = 0)
for s in range(0,distinct_skus):
    if arr_sum[s] != 1: arr_sum[s] = 0
arr_curr_order = arr_order_sku_pivot[o]
arr_dot = np.dot(arr_sum, arr_curr_order)

oskupicks_matrix[OrdersPerBatch-1][o] = arr_dot
</code></pre>

<p>This is probably the bit that slows down everything. This is in a third nested loop, which then goes into a forth nested loop. If you can move these loops into numpy or pandas you should get a decent speed up. The other place here I believe is causing a slowdown is the condition. Lets try and rewrite this bit, keeping in mind that numpy should be doing all the work.</p>

<p>My proposal is to keep an array of all the SKUs we haven't seen, and use that to work out the unique ones. Then we can use the nice trick of getting the dot product between the array of unseen SKUs and the current row to get the number of unique SKUs. There is a little house keeping to do, like to mark off SKUs as seen, we invert the current row and bitwise and it to mark them off. This could be done other ways, but the implementation is below. Do note that to do the invert the row trick we has to set the elements to be ints rather than floats. This is fine as they were set to ints earlier.</p>

<pre><code>for b in range(batches):
    batch_start = b * orders_per_batch
    batch_end = min(batch_start + orders_per_batch, TOTAL_ORDERS)

    unseen = 1 - arr_order_sku_pivot[batch_start]
    # 1 - a is a trick to flip all the 1s and 0s in an array
    # NOTE: This assumes there is at least one order per batch
    unique_SKUs = arr_order_sku_pivot[batch_start].sum()
    oskupicks_matrix[OrdersPerBatch-1][batch_start] = unique_SKUs

    for i in range(batch_start + 1, batch_end):
        unique_SKUs = np.dot(unseen, arr_order_sku_pivot[i])
        unseen &amp;= 1 - arr_order_sku_pivot[i]
        oskupicks_matrix[OrdersPerBatch-1][i] = unique_SKUs
</code></pre>

<p>I've made a few minor changes like o -&gt; i as i is a far more common name for a throwaway variable in a loop. I've also changed how the ending index of a batch is calculated, checking if you can move by the batch size makes more sense to me.</p>

<hr>

<p>Some closing remarks, this is definitely not even close to perfect. There are a couple of loops that could be changed to functions which are then <a href="https://stackoverflow.com/questions/35215161/most-efficient-way-to-map-function-over-numpy-array">apply</a>-ied for more parallelism. The main matrix we are working with is converted from floats to bools to ints, but it probably could have stayed as bools.</p>

<p>I hope there is enough in this that you can actually work on and improve upon yourself, good luck and please post a follow up question!</p>
    </div>