<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Your escaping for the search term is not sufficient. Other characters than spaces might be in the user entered string, which also need to be escaped. Luckily, <code>requests</code> can do it all for you:</p>

<pre><code>def rechercher_google(search_term, number_results, language_code):
    '''
    input: Nom de l'entreprise Ã  siretiser, le nombre de page et la langue
    output: La page resultat dde google en html stocker au format raw html
    '''
    assert isinstance(search_term, str), 'Il doit etre en string'
    assert isinstance(number_results, int), 'DOit etre en chiffre'

    g_url = 'https://www.google.fr/search'
    params = {"q": search_term, "num": number_results, "hl": language_code}
    response = requests.get(g_url, params=params, headers=USER_AGENT)
    response.raise_for_status()
    return response.text, search_term
</code></pre>

<p>Note that I also followed Python's official style-guide, <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a>, and did not use spaces around the <code>=</code> for keyword arguments.</p>

<p>But the obvious improvement is not to parse the Google search results at all, but directly query the website you are interested in. If I understand it correctly, what you actually want to parse is:</p>

<pre><code>url = "https://www.infogreffe.fr/recherche-entreprise-dirigeants/resultats-entreprise-dirigeants.html"
params = {"ga_cat": "globale", "ga_q"=search_term}
response = requests.get(url, params=params, header=USER_AGENT)
</code></pre>

<p>That website is not particularly fast either (some pages take 5s to load). But they will probably have worse bot protection than Google, which is a bit evil, but if your scraping is evil, you should not be doing it in the first place. Always read the terms &amp; conditions of websites you want to scrape, so at least you know what you are doing. The Wikipedia page <a href="https://en.wikipedia.org/wiki/Search_engine_scraping" rel="nofollow noreferrer">Search engine scraping</a> has quite a lot of information about what Google is doing to prevent you from scraping their search result page too aggressively. In the same vein, you could try optimizing the wait time between the queries, which is currently 11 seconds. With some trial &amp; error you might find a shorter time that also works.</p>
    </div>