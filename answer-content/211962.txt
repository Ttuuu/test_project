<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h3>General Observations</h3>

<ul>
<li><p>instead of manually looking for a tag a desired position and handling <code>pos</code> increment in the loop, I think you could just simply get the value by index:</p>

<pre><code>curpos = tags[int(pos_1) - 1].get('href', None)
</code></pre></li>
<li><p><code>count = count - 1</code> could be simplified as <code>count -= 1</code></p></li>
<li>follow the <a href="https://www.python.org/dev/peps/pep-0008/#id36" rel="nofollow noreferrer">PEP8 <code>lower_case_with_underscores</code> variable naming guideline</a></li>
<li>what if you prefix the variable names containing user-defined values with <code>input_</code> (see below)? </li>
<li><p>and, I think a "for" loop with a <em>negative step</em> would be a simpler solution that the while loop here:</p>

<pre><code>for count in range(int(Count_) + 1, 1, -1):
    # ...
</code></pre></li>
<li>Or, to bring it one step further, what if we apply a generally easier to follow recursive flow instead of the iterative approach you currently have. The base condition for the recursion could be the input count reaching 1. And, we'll improve on <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself" rel="nofollow noreferrer">DRY</a> with that function as well. </li>
</ul>

<h3>Web-Scraping</h3>

<ul>
<li><p>you don't have to call <code>.read()</code> on the result of <code>.urlopen()</code> as <code>BeautifulSoup</code> also accepts file-like objects:</p>

<pre><code>soup = BeautifulSoup(ur.urlopen(url), "html.parser")
</code></pre></li>
<li><p>switching from <code>html.parser</code> to <code>lxml</code> may help drastically improve HTML-parsing performance</p></li>
<li>instead of using <code>urllib()</code>, you could <a href="http://docs.python-requests.org/en/master/user/advanced/#session-objects" rel="nofollow noreferrer">switch to <code>requests</code> and re-use a session</a> which would help avoid an overhead of re-establishing network connection to the host on every request</li>
<li>you could use <a href="https://beautiful-soup-4.readthedocs.io/en/latest/#parsing-only-part-of-a-document" rel="nofollow noreferrer"><code>SoupStrainer</code></a> to let <code>BeautifulSoup</code> parse only the <code>a</code> elements</li>
<li>you should also account for relative links and use <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urljoin" rel="nofollow noreferrer"><code>urljoin()</code></a> to combine base urls and relative links</li>
</ul>

<hr>

<p>The code with the above and other improvements applied:</p>

<pre><code>from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup, SoupStrainer


only_links = SoupStrainer('a')


def follow_link(session, url, position, count):
    """Follows a link at a given "position" "count" number of times."""
    if count &lt;= 1:
        return

    print('Retrieving: ', url)
    response = session.get(url)

    soup = BeautifulSoup(response.content, "lxml", parse_only=only_links)
    links = soup('a')
    next_url = links[position - 1].get('href', None)

    return follow_link(session, urljoin(url, next_url), position, count - 1)


if __name__ == '__main__':
    input_url = str(input('Enter URL- '))
    input_count = int(input('Enter count: '))
    input_position = int(input('Enter position: '))

    with requests.Session() as session:
        follow_link(session, input_url, input_position, input_count)
</code></pre>

<hr>

<h3>Afterthoughts</h3>

<ul>
<li>what if there is no link at the desired position available on some page?</li>
<li>if we once get a link which links itself, this code in this state would get stuck on this page alone until the <code>count</code> is exchausted </li>
</ul>

<hr>

<blockquote>
  <p>The goal is to have cleaner code, with a #comment on each line (unless extremely basic) so as to improve my annotation habits.</p>
</blockquote>

<p>Comments on each line could overall decrease readability of the code and they are, in essence, extra information and weight you need to make sure stay <em>up to date with the actual code</em>. <em>Self-documented code</em> is something you should strive to achieve, using comments as an extra measure used to explain the "why" some decisions were made and not the "how". </p>
    </div>