<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I don't know anything about mysql, so I'm ignoring that part of your question.</p>

<p>For SQL Server, if you're trying to make an insert go faster you're going to want to:</p>

<ol>
<li>Do it in bulk</li>
<li>Do it in parallel</li>
<li>Make it minimally logged</li>
<li>Do it in batches</li>
</ol>

<p>There are some things you can do that will handle all of this for you, which I list below, otherwise you'll have to write something yourself.</p>

<h2><a href="https://blogs.msdn.microsoft.com/sqlserverstorageengine/2008/02/04/what-are-the-bulk-import-optimizations/" rel="nofollow noreferrer">Bulk operations</a></h2>

<p>Bulk operations ultimately boil down to trying to do as much work as possible in a single operation, in a way that doesn't tank performance (transaction logging is the most common thing this helps with, but there are some more). The link mentions a few benefits, the main ones I'm highlighting here are:</p>

<ol>
<li>Minimal logging</li>
<li>Better locking (<a href="https://docs.microsoft.com/en-us/sql/relational-databases/sql-server-transaction-locking-and-row-versioning-guide?view=sql-server-2017" rel="nofollow noreferrer">BU locks</a>)</li>
<li>Batching</li>
<li>Optional triggers/constraints</li>
</ol>

<p>If you were inserting directly from a file, then <a href="https://docs.microsoft.com/en-us/sql/t-sql/statements/bulk-insert-transact-sql?view=sql-server-2017" rel="nofollow noreferrer"><code>BULK INSERT</code></a> is your friend. It will handle pretty much all of the considerations above for you (besides parallelism, which is outside of <code>BULK INSERT</code>'s control.</p>

<p>Inserting from C#, however would be better suited to use <a href="https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient.sqlbulkcopy?view=netframework-4.8" rel="nofollow noreferrer"><code>SqlBulkCopy</code></a>. This lets you perform bulk insert operations into a table, and can <a href="https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient.sqlbulkcopyoptions?view=netframework-4.8" rel="nofollow noreferrer">be configured</a> to ignore constraints, triggers, identity columns, etc. </p>

<h2><a href="https://www.sqlshack.com/use-parallel-insert-sql-server-2016-improve-query-performance/" rel="nofollow noreferrer">Parallel Inserts</a></h2>

<p>Parallel inserts are what allow SQL to insert multiple rows into a table at once instead of doing row-by-row operations. This generally requires a few things:</p>

<ol>
<li>A heap</li>
<li>No <code>IDENTITY</code> columns</li>
<li>The right kind of <a href="https://docs.microsoft.com/en-us/sql/relational-databases/sql-server-transaction-locking-and-row-versioning-guide?view=sql-server-2017" rel="nofollow noreferrer">lock</a> on the table</li>
</ol>

<p>If you don't have a heap (e.g. there are indices), then the index maintenance prohibits the parallel insert, and it will do the insert serially. For large-scale ETL workloads, this is a good use-case for a "staging" database/table that has none of these things and as such can get the best performing insert. <a href="https://www.brentozar.com/archive/2016/03/minimal-logging-when-you-cant-change-the-code/" rel="nofollow noreferrer">Brent Ozar</a> has a good post that touches on this a bit as well.</p>

<p><code>IDENTITY</code> columns also prevent parallel inserts, as maintaining the order of the inserts is required for it to work correctly.</p>

<p>If you don't have the right locks on the table (BU locks work, as does the <code>TABLOCK(X)</code> hint(s)) then SQL Server has to consider that another session could be modifying the table as well, which also prevents parallelism.</p>

<p>If you are able to meet all of these requirements, however, then your operations (whether using built-in bulk operations as above, or rolling your own as below) will be able to run faster by taking advantage of the additional cores SQL Server has.</p>

<h2><a href="https://blogs.msdn.microsoft.com/sqlserverstorageengine/2008/02/04/bulk-import-optimizations-minimal-logging/" rel="nofollow noreferrer">Minimal</a> <a href="https://www.brentozar.com/archive/2016/03/minimal-logging-when-you-cant-change-the-code/" rel="nofollow noreferrer">logging</a></h2>

<p>Minimal logging is the method by which you prevent the transaction log from overflowing. Some operations can be rolled back more easily than others or require less transaction log space than others. Maintaining the transaction log isn't free/cheap, so reducing how much of it is necessary also helps performance. In general, if you <a href="https://docs.microsoft.com/en-us/previous-versions/sql/sql-server-2008/dd425070(v=sql.100)" rel="nofollow noreferrer">follow the rules</a> you should be able to achieve minimal logging. At a high level, the following are minimally logged:</p>

<ol>
<li>An insert into a heap (i.e. a table without a clustered index) that has no non-clustered indexes, using a TABLOCK hint, having a high enough cardinality estimate (&gt; ~1000 rows)</li>
<li>An insert into a table with a clustered index that has no non-clustered indexes, without TABLOCK, having a high enough cardinality estimate (&gt; ~1000 rows)</li>
<li>Adding an index to a table, even if that table already has data.</li>
</ol>

<h2>Batches</h2>

<p>Lastly, you can break a large chunk of work up into smaller batches. This can be useful if transaction logging is the main concern as each batch becomes its own transaction.</p>

<p>This is tricky to implement generically, and can be unpleasant to do yourself. Another major concern is with correctness of the data; if another user hits the database while you're not done with your batches, then they may get inconsistent results. This is a good use-case for doing the work in another table, then swapping tables out, as well as for <a href="https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/snapshot-isolation-in-sql-server" rel="nofollow noreferrer">snapshot isolation</a>.</p>
    </div>