<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I'd read a select amount of the file at a time. Split it into characters, and then split on each empty space. This is better than splitting on each new line as the file may be one line.</p>

<p>To do the former in Python 3 is fairly simple:</p>

<pre><code>def read_chunks(file, chunk_size):
    while True:
        chunk = file.read(chunk_size)
        if not chunk:
            break
        yield from chunk
</code></pre>

<p>This has \$O(\text{chunk_size})\$ memory usage, which is \$O(1)\$ as it's a constant. It also correctly ends the iterator, when the file ends.</p>

<p>After this, you want to split the words up. Since we're using <a href="https://docs.python.org/3/library/stdtypes.html#str.split" rel="nofollow noreferrer"><code>str.split</code></a> without any arguments, we should write just that method of splitting. We can use a fairly simple algorithm:</p>

<pre><code>from string import whitespace

def split_whitespace(it):
    chunk = []
    for char in it:
        if char not in whitespace:
            chunk.append(char)
        elif chunk:
            yield tuple(chunk)
            chunk = []
    if chunk:
        yield tuple(chunk)
</code></pre>

<p>This has \$O(k)\$ memory, where \$k\$ is the size of the largest word. What we'd expect of a splitting function.</p>

<p>Finally we'd change from tuples to strings, using <code>''.join</code>, and then use the <code>collections.Counter</code>. And split the word reading, and finding the most common into two different functions.</p>

<p>And so for an \$O(k)\$ memory usage version of your code, I'd use:</p>

<pre><code>import sys
from collections import Counter
from string import whitespace


def read_chunks(file, chunk_size):
    while True:
        chunk = file.read(chunk_size)
        if not chunk:
            break
        yield from chunk


def split_whitespace(it):
    chunk = []
    for char in it:
        if char not in whitespace:
            chunk.append(char)
        elif chunk:
            yield tuple(chunk)
            chunk = []
    if chunk:
        yield tuple(chunk)


def read_words(path, chunk_size=1024):
    with open(path) as f:
        chars = read_chunks(f, chunk_size)
        tuple_words = split_whitespace(chars)
        yield from map(''.join, tuple_words)


def most_common_words(words, top=10):
    return dict(Counter(words).most_common(top))


if __name__ == '__main__':
    words = read_words(sys.argv[1])
    top_five_words = most_common_words(words, 5)
</code></pre>
    </div>