<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>Review</h1>

<p>all in all, this code is rather clean. I would use a generator comprehension and <code>itertools.chain</code> in <code>fake_disrete_data</code> instead of the nested for-loop, but that is a matter of taste</p>

<h2>linewraps</h2>

<p>I prefer to wrap lines after the <code>(</code> instead of the first argument. Here I follow the same rules as <a href="https://black.readthedocs.io/en/stable/the_black_code_style.html#how-black-wraps-lines" rel="nofollow noreferrer">black</a>. This leads to lesser indents, but slightly longer code, for example:</p>

<pre><code>dfs.append(
    pd.pivot_table(
        fake_disc,
        index=fake_disc.index.date,
        columns=fake_disc.index.hour,
        values=col,
        aggfunc=np.mean,
    )
)
</code></pre>

<h2>list comprehension</h2>

<p>instead of the appending, you can do </p>

<pre><code>dfs = [
    pd.pivot_table(
        fake_disc,
        index=fake_disc.index.date,
        columns=fake_disc.index.hour,
        values=col,
        aggfunc=np.mean,
    )
    for col in columns
]
</code></pre>

<p>or even better, feed a dict to <code>pd.concat</code>, so you don't have to specify the <code>keys</code> argument</p>

<pre><code>dfs = {
    col: pd.pivot_table(
        fake_disc,
        index=fake_disc.index.date,
        columns=fake_disc.index.hour,
        values=col,
        aggfunc='mean',
    )
    for col in fake_disc.columns
}
pd.concat(dfs, axis=1)
</code></pre>

<p>I also changed the <code>np.mean</code> to <code>'mean'</code>, so you don't have to specifically import np for this, and avoided having to create the <code>columns</code> list</p>

<h1>Alternative approach</h1>

<p><code>pd.pivot</code> is a wrapper around <code>unstack</code>, <code>groupby</code> and <code>stack</code>. If you want to do something more complicated, you can do those operations by hand</p>

<pre><code>fake_disc = fake_disrete_data()
fake_disc.columns = fake_disc.columns.set_names('variable')
df = fake_disc.stack().to_frame().rename(columns={0: 'value'})
df['hour'] = df.index.get_level_values('time').hour
</code></pre>

<p>this creates an intermediary <code>DataFrame</code></p>

<pre><code>time                variable    value   hour
2016-06-11 00:00:00 mag_sig     0.0     0
2016-06-11 00:00:00 bias        0.5     0
2016-06-11 00:15:00 mag_sig     0.0     0
2016-06-11 00:15:00 bias        0.5     0
2016-06-11 00:30:00 mag_sig     0.0     0
...
</code></pre>

<p>This you can group. To group the time per hour, you can use <code>pd.Grouper</code></p>

<pre><code>pivot = (
    df.groupby([pd.Grouper(level="time", freq="d"), "hour", "variable"])
    .mean()
    .unstack(["variable", "hour"])
    .sort_index(axis="columns", level=["variable", "hour"])
)
</code></pre>

<blockquote>
<pre><code>  value
variable  bias    ...     mag_sig
hour  0   1   2   3   4   5   6   7   8   9   ...     14  15  16  17  18  19  20  21  22  23
time                                                                                  
2016-06-11    0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.5     ...     14.0    15.0    16.0    17.0    18.0    19.0    20.0    21.0    22.0    23.0
2016-06-12    0.7     0.7     0.7     0.7     0.7     0.7     0.7     0.7     0.7     0.7     ...     14.0    15.0    16.0    17.0    18.0    19.0    20.0    21.0    22.0    23.0
2016-06-13    1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     ...     14.0    15.0    16.0    17.0    18.0    19.0    20.0    21.0    22.0    23.0
</code></pre>
</blockquote>

<h2>performance</h2>

<p>according to the <code>%%timeit</code> cell magic in Jupyterlab,
the first approach (with the dict and concat) takes about 23ms, the second approach about 10ms. Depending on your usecase, this difference might be important. If it is not, pick the method which is most readable to your future self</p>
    </div>