<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<h1>Style</h1>
<p>Please read <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a> and use a consistent style throughout your code:</p>
<ul>
<li>put a space after comas;</li>
<li>use a linebreak after colons;</li>
<li>use UPPERCASE names for constants…</li>
</ul>
<h1>Using locks</h1>
<p>First off, <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Lock" rel="nofollow noreferrer">locks support the context manager protocol</a> and you can thus simplify your <code>printer</code> to:</p>
<pre><code>def printer(lock, data):
    with lock:
        print(data)
</code></pre>
<p>which may not warant a method on its own.</p>
<p>But most importantly, you say that</p>
<blockquote>
<p>I've used locking within it to prevent two processes from changing its internal state.</p>
</blockquote>
<p>but you're not changing any shared state at all. All you are doing with this lock is preventing outputs to be mismatched on the screen. Let's take a look at a modified version of your script: I’ve stored the process started so I can <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.join" rel="nofollow noreferrer"><code>join</code></a> them and I print <code>itemstorage</code> after all computation is done.</p>
<pre><code>if __name__ == '__main__':
    lock = Lock()
    processes = [
        Process(target=get_info, args=(link.format(page), lock, itemstorage))
        for page in range(1, 15)
    ]
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    print('itemstorage is', itemstorage)
</code></pre>
<p>This prints</p>
<pre><code>[…actual results snipped…]
itemstorage is []
</code></pre>
<p>This is because each process is operating on its own copy of <code>itemstorage</code> and nothing is done to retrieve data afterward. Instead, you should have your processes <code>return</code> the result and store them in <code>itemstorage</code> yourself. In fact, this very process is already implemented using <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map" rel="nofollow noreferrer"><code>multiprocessing.Pool.map</code></a>.</p>
<h1>Simplifying element retrieval</h1>
<p>Since you extract text from the dom 3 times per <code>title</code>, you can extract an helper function to simplify that task. Doing so, it will be even easier to build the return list using a list-comprehension:</p>
<pre><code>def extract(element, descriptor, default=None):
    try:
        return element.cssselect(descriptor)[0].text
    except IndexError:
        if default is None:
            raise
        return default


def get_info(url):
    response = requests.get(url).text
    tree = fromstring(response)
    return [(
        extract(title, "a.business-name span"),
        extract(title, "span.street-address", ""),
        extract(title, "div[class^=phones]", ""),
    ) for title in tree.cssselect("div.info")]
</code></pre>
<p>This changes a bit the structure but I believe it is an improvement to better access the information. You can still use <a href="https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable" rel="nofollow noreferrer"><code>itertools.chain.from_iterable</code></a> if need be to flatten the returned list.</p>
<h1>Proposed improvements</h1>
<pre><code>import itertools
from multiprocessing import Pool

import requests
from lxml.html import fromstring


LINK = "https://www.yellowpages.com/search?search_terms=coffee&amp;geo_location_terms=Los%20Angeles%2C%20CA&amp;page={}"


def extract(element, descriptor, default=None):
    try:
        return element.cssselect(descriptor)[0].text
    except IndexError:
        if default is None:
            raise
        return default


def get_info(url):
    response = requests.get(url)
    tree = fromstring(response.content)
    return [(
        extract(title, "a.business-name span"),
        extract(title, "span.street-address", ""),
        extract(title, "div[class^=phones]", ""),
    ) for title in tree.cssselect("div.info")]


if __name__ == '__main__':
    pages_count = 14
    with Pool(processes=pages_count) as pool:
        urls = [LINK.format(page) for page in range(1, pages_count + 1)]
        itemstorage = pool.map(get_info, urls)
    for result in itertools.chain.from_iterable(itemstorage):
        print(result)
</code></pre>
<p>Note that I also changed the document parsing part. For one <code>lxml</code> is perfectly capable of handling <code>bytes</code> so you don't have to perform decoding yourself; for two decoding into a string blindly can lead to using an improper charset, which <code>lxml</code> can handle by looking into the appropriate <code>meta</code> tag.</p>
    </div>