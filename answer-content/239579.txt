<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>You can save a little bit of time by not re-running <code>str.maketrans</code> for each token, since it's always going to produce the same result:</p>

<pre><code>import nltk
from statistics import mean
import string
import time
from typing import List


def normalize_text3(text: str) -&gt; List[str]:
    output: List[str] = []
    punctuation_filter = str.maketrans('', '', string.punctuation)
    for token in nltk.word_tokenize(text):
        token = token.translate(punctuation_filter)
        if not token:
            continue
        output.append(token.lower())
    return output
</code></pre>

<p>tested with:</p>

<pre><code>for func in [normalize_text, normalize_text2, normalize_text3]:
    times = []
    for _ in range(1000):
        start = time.time()
        tokens = normalize_text(t)
        end = time.time()
        times.append(end - start)
    print(f"{func.__name__.rjust(15)}: {mean(times)}")
</code></pre>

<p>gets me:</p>

<pre><code>dog runs
 normalize_text: 0.003226396322250366
normalize_text2: 0.0032752704620361327
normalize_text3: 0.0030987038612365725
</code></pre>

<p>If you want to lower memory consumption, you might consider having this function return a generator rather than a list...</p>
    </div>