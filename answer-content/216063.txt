<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Currently you only get one new name per page request. However, the page contains all people known by that person. So I would implement a queue of yet to be visited people and a set of people already visited. If there are no more people left to visit, you have found all people (assuming there are no disjoint sets of people and that this is your actual goal).</p>

<p>In addition, using <a href="http://docs.python-requests.org/en/master/" rel="nofollow noreferrer"><code>requests</code></a> is usually a bit more user-friendly than using <code>urllib</code> directly.</p>

<pre><code>import requests
from bs4 import BeautifulSoup, SoupStrainer
import re

STRAINER = SoupStrainer("a")

def get_name(url):
    match = re.match(r"http://py4e-data.dr-chuck.net/known_by_(.*).html", url)
    if match is not None:
        return match.groups()[0]

def find_all_people(start_url):
    with requests.Session() as session:
        queue = set([start_url])
        visited = set()
        while queue:
            url = queue.pop()
            visited.add(url)
            print(len(visited), "/", len(visited) + len(queue), url)
            response = session.get(url)
            soup = BeautifulSoup(response.text, "lxml", parse_only=STRAINER)
            queue.update(a["href"]
                         for a in soup.select("a")
                         if a["href"] not in visited)
        return list(map(get_name, visited))

if __name__ == "__main__":
    url = "http://py4e-data.dr-chuck.net/known_by_Kory.html"
    people = find_all_people(url)
    print(len(people))
</code></pre>

<p>This uses a <a href="http://docs.python-requests.org/en/master/user/advanced/#session-objects" rel="nofollow noreferrer"><code>request.Session</code></a> to keep the connection alive, speeding it up a tiny bit. It also has a <a href="http://stackoverflow.com/questions/419163/what-does-if-name-main-do"><code>if __name__ == "__main__":</code></a> guard to allow importing from this script from another script without the code running, a <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#soupstrainer" rel="nofollow noreferrer"><code>bs4.SoupStrainer</code></a> to only parse the parts of the page needed and it uses the faster <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use" rel="nofollow noreferrer"><code>lxml</code></a> parser.</p>

<p>It still takes quite some time to find all people. Finding that there are <em>probably</em> 5754 people takes only a few seconds.</p>
    </div>