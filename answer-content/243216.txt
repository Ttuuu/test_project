<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>Please consider below as opinions, not the source of truth. I write what 'should' be but read it as 'I think it should...'</p>

<p>As for your questions:</p>

<p>1) 
It is not a good idea. For me, <code>parametrize</code> decorator means 'those are the inputs to the function you are testing' not 'this is the function that you are testing'.</p>

<p>2) 
I think it is a bad practice. Unit tests should be designed to be not dependend on anything else except fixture (or any other setup). I've seen E2E tests being done in the way that you desceibe and it always lead to cascading tests which slowed down pipelines for no reason.</p>

<p>Also, by doing dependency like this you are violating an important rule: 'UT should break for one reason', it should not break because some other test broke. </p>

<p>Lastly, you are preventing yourself from running those concurrently which is very important should your codebase ever become very big. </p>

<p>3) I agree it is not convinient but not impossible. For most of the tests you can simply mock this method to return what you want it to return. However, I can imagine that this might be too time consuming and maybe hard to maintain (?). I would let it slide, I don't think it would provide much gain vs cost. </p>

<p>4) I personally would use inheritance to pass the values around, global variables take away a freedom of modyfying input to test one specific thing.
However, I think it is personal choice, if you would be working with a team you would probably have some guidelines about that. </p>

<p>5)</p>

<p>a)
As I expressed in 1), I would not utilize your approach. I would rather create a base class for all the tests and create one test class per class tested. There are multiple reasons for that however, the most important one is that the classes might diverge in the future and you would have to rewrite your suite. I don't mind duplication a long as it is justified. </p>

<p>b)
In general, I would prefer to use <code>self.assert*</code> instead of <code>assert x == y</code> (see <a href="https://docs.python.org/3/library/unittest.html" rel="nofollow noreferrer">unittest.TestCase</a>). It gives much more information than just simple True/False.</p>

<p>c)
I would not add any randomness to UT. From my experience, it only provides confusion and <a href="https://en.wikipedia.org/wiki/Heisenbug" rel="nofollow noreferrer">heisenbugs</a>. Imagine that you have a pipeline with tests, one test failes, you rerun the pipeline and the test passes. Now, you can do two things:
1. Say it was a transient issue so you will not look into it, maybe some build problems, maybe one of the test servers failed - who knows.
2. Spend time to rerun the test X times until the random generator creates a failing test case. </p>

<p>However, if you would create non-random tests, you <em>could</em> detect the problem locally (you might as well not detect it as well). I prefer reproducibility. Furthermore, it might be the case that you will never randomise a failing sequence because your local setup has a different random sequences than the ones on the server. My opinion on this is strictly for unit tests. For random tests I would use <a href="https://en.wikipedia.org/wiki/Fuzzing" rel="nofollow noreferrer">fuzzy testing</a> approach and make it in a different test suite.
See <a href="https://stackoverflow.com/q/32458/3809977">this SO question</a> to choose what is the best for you as it all depends. </p>
    </div>