<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>What I like:</p>

<ul>
<li>usage of f-strings, but you are not using them everywhere eg: <code>URL = 'https://remote.co/remote-jobs/search/?search_keywords='+pos.replace(' ', '+')</code></li>
<li>usage of <code>if __name__ == '__main__':</code></li>
<li>code is fairly easy to grasp</li>
<li>effort to provide a decent working script with a minimum of code (70 lines)</li>
</ul>

<p>What I like less:</p>

<ul>
<li>usage of exception handling: I would be more specific and not catch any type of exception, only handle those that are relevant to the operation being performed in the try/catch block (<code>selenium.common.exceptions</code>)</li>
<li>lack of <strong>global exception handling</strong> in the rest of the code</li>
<li>also think about <strong>logging</strong> full exception details to a file so you don't have to guess what has gone wrong</li>
<li>I would also avoid nesting of try/catch blocks, try to separate each operation from each other (see below)</li>
<li>mixing lower case and upper case in variable names: remember that variable names are case-sensitive in Python. <code>jobPD</code> and <code>jobpd</code> are two different variables that can get assigned different values so this could be a nasty source of bugs</li>
<li><strong>variable names</strong> should be more descriptive and meaningful: <code>jobPD</code> does not give a clear hint about what it represents. More descriptive names would be <code>job_title</code>, <code>job_posted_time</code> etc</li>
</ul>

<hr>

<p>Regarding the scraping process, make sure that the DOM elements your are expecting are really present: websites change their layout more or less often and you must spot changes that you could break your application. You can either check with Selenium or BS4 if you have already retrieved the HTML. But it seems logical to use Selenium. If you use BS, note the behavior of the different functions:</p>

<p>From the BS4 <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find" rel="nofollow noreferrer">doc</a> (emphasis is mine):</p>

<blockquote>
  <p>If find_all() can’t find anything, it returns an <strong>empty list</strong>. If find()
  can’t find anything, it returns <strong>None</strong></p>
</blockquote>

<hr>

<p>You have this block (the nested try/catch block):</p>

<pre><code>    try: # can't locate element - click the close on the popup add
        WebDriverWait(driver, 5).until(
            ec.presence_of_element_located((By.CLASS_NAME, 'portstlucie-CloseButton'))
            )
        addClose = driver.find_element_by_xpath('//*[@id="om-oqulaezshgjig4mgnmcn-optin"]/div/button')
        addClose.click()
    except: # Timeout / can't locate add - break
        break
</code></pre>

<p>Is is better to anticipate and avoid exceptions, rather than handling them. So it seems to me that you should verify the existence of the element if possible, rather than trigger an exception.</p>

<p>Instead, you could use the more generic <code>findElements</code> function. Note that <code>findElement</code> is different than <code>findElements</code>. The difference:</p>

<blockquote>
  <p>findElements will return an empty list if no matching elements are
  found instead of an exception (<code>NoSuchElementException</code>)</p>
</blockquote>

<p>Reference: <a href="https://www.guru99.com/find-element-selenium.html" rel="nofollow noreferrer">Find Element and FindElements in Selenium WebDriver</a></p>

<p>However, if you stick to the current approach, you should not blindly catch <strong>all exceptions</strong>: in this context the one relevant exception that may occur is: <code>NoSuchElementException</code>.</p>

<hr>

<p>There is one thing that is not okay: you are using the <code>requests</code> module in parallel to Selenium. That is unnecessary since you already have an instance of Selenium that you can use. To fetch the whole HTML just use:</p>

<pre><code>html = driver.page_source
</code></pre>

<p>then feed it to BS</p>

<p>Final thought: have you thought about logging the results to a file, a table or CSV perhaps ? The console buffer may be too small if you retrieve lots of results.</p>
    </div>