<div class="s-prose s-prose__disable-spoiler-hover js-post-body" itemprop="text">
<p>I can't say I understand exactly what your algorithm does. Even when looking at Wikipedia it is hard to see. So, why don't you just use the reference implementation from there? It has functions with nice names and everything (well, not quite <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a> compatible, but that could be changed).</p>
<p>Alternatively, once you have vectors of numbers and want to perform fast calculations on them, you probably want to use <code>numpy</code>, which allows you to easily perform some operation on the whole vector, like taking the difference between two vectors, scaling a vector by a scalar, taking the sum, etc.</p>
<pre><code>import numpy as np

MAGIC_CUTOFF = 0.4375

class WrongFaceException(Exception):
    pass

def norm(x):
    return np.sqrt((x**2).sum())

def update(base_encoding, new_face_encoding, v, n):
    delta1 = new_face_encoding - base_encoding
    if norm(delta1) &gt; MAGIC_CUTOFF and n &gt; 1:
        raise WrongFaceException(f"norm(delta1) = {norm(delta1)} &gt; {MAGIC_CUTOFF}")
    new_encoding = base_encoding + delta1 / n
    delta2 = delta1 - new_encoding
    v = v * (n - 1) / n + norm(delta1) * norm(delta2) / n
    return new_encoding, v, n + 1

if __name__ == "__main__":
    new_face_encoding = np.array((0.2, 0.25, 0.4, 0.5) * 32)
    base_encoding = np.array((0.2, 0.3, 0.4, 0.5) * 32)
    v = 0.01
    n = 3
    
    updated_encoding, v, n = update(base_encoding, new_face_encoding, v, n)
    print(updated_encoding, v, n)
</code></pre>
<p>In addition to using <code>numpy</code>, I expanded some of the names so it is clearer what they are, I made the cutoff value a global constant (you should give it a meaningful name), added a custom exception instead of just dying (the <code>pass</code> after it was unneeded and unreachable BTW), which makes it more clear what happened, wrapped the calling code under a <code>if __name__ == "__main__":</code> guard to allow importing from this script without running it and followed Python's official style-guide, <a href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow noreferrer">PEP8</a>, by having operators surrounded by one space.</p>
<p>Instead of this <code>norm</code> function, you can also use <code>scipy.linalg.norm</code>, which might be even faster.</p>
<hr>
<p>To answer if you used the math correctly, I would say partially yes. It looks like you implemented the explicit formula given for the sample variance:</p>
<p><span class="math-container">\$\sigma^2_n = \frac{(n - 1)\sigma^2_{n-1} + (x_n - \bar{x}_{n-1})(x_n - \bar{x}_n)}{n}\$</span></p>
<p>However, note that Wikipedia also mentions that this formula suffers from numerical instabilities, since you "repeatedly subtract a small number from a big number which scales with <span class="math-container">\$n\$</span>".</p>
<p>Instead you want to keep the sum of the squared differences <span class="math-container">\$M_{2,n} = \sum_{i=1}^n (x_i - \bar{x}_n)^2\$</span> around and update that:</p>
<p><span class="math-container">\$M_{2,n} = M_{2,n-1} + (x_n - \bar{x}_{n-1})(x_n - \bar{x}_n)\$</span></p>
<p>with</p>
<p><span class="math-container">\$\bar{x}_n = \bar{x}_{n -1} + \frac{x_n - \bar{x}_{n-1}}{n}\$</span></p>
<p>Then the new population variance is given simply by:</p>
<p><span class="math-container">\$\sigma^2_n = \frac{M_{2,n}}{n - 1}\$</span></p>
<p>This is a bit tricky to implement, since your <span class="math-container">\$x_i\$</span> are actually vectors of numbers, so you would need to find out how to properly reduce it in dimension (in your previous formula you used the norm for that).</p>
    </div>